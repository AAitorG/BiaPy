{"cells":[{"cell_type":"markdown","metadata":{"id":"kcAryclxsQJ5"},"source":["# **3D Detection pipeline**\n","___  \n","  \n","In this notebook, we demonstrate the use of the [BiaPy](https://biapy.readthedocs.io/en/latest/) pipeline for **3D detection** of microscopy data.\n","\n","<figure>\n","<center>\n","<img src='https://biapy.readthedocs.io/en/latest/_images/detection_image_input.png' width='300px'/>\n","<img src='https://biapy.readthedocs.io/en/latest/_images/detection_csv_input.svg' width='300px'/>\n","<figcaption><b>Figure 1</b>: Example of a 3D detection problem. From left to right: 3D brainbow image and its corresponding CSV file with the coordinates of the center of each cell. </figcaption></center>\n","</figure>\n","\n","Without any coding, we'll guide you step-by-step through the process to:\n","1. **Upload a set of training and test images** along with their corresponding instance label images.\n","2. **Train a Deep Neural Network (DNN)** model using the training set.\n","3. **Apply the model** to the test images.\n","4. **Download the segmentation results** to your local machine.\n","\n","**Disclaimer:** The structure of the notebook is heavily inspired by the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n","\n","**Contact:** This notebook was created by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus) and [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org). For suggestions, comments, or issues, please reach out to us via email or [create an issue in BiaPy's repository](https://github.com/BiaPyX/BiaPy/issues). Thank you!"]},{"cell_type":"markdown","metadata":{"id":"hG5ClE_HHQaE"},"source":["## **Expected Inputs and Outputs**\n","___\n","\n","### **Inputs**\n","\n","This notebook requires the following five input folders:\n","\n","- **Training Raw Images**: Consisting of the unprocessed 3D images intended for training.\n","- **Training CSV Files**: Providing the coordinates for the center of each cell for model training. The number and size of these files should align with the training raw images.\n","- **Test Raw Images**: Houses the 3D images on which the model will be tested.\n","- **Test CSV Files**: Contains the coordinates of the centers of the cells for testing. Ensure that their number and sizes correspond to the test raw images.\n","- **Output Folder**: A designated directory where segmentation results will be saved.\n","\n","### **Outputs**\n","\n","On successful execution, an output folder will emerge, containing a **CSV file** and a **TIFF image** for every test image. The CSV files list the coordinates of each cell's center, while the result images depict these central points as deduced by our pipeline.\n","\n","<font color='red'><b>Note:</b></font> For testing purposes, you can utilize the **example datasets provided under 'Manage File(s) Source > Option 3'**.\n","\n","**Data structure**\n","\n","To ensure the proper operation of the library the data directory tree should be something like this:\n","\n","```\n","dataset/\n","├── train\n","│   ├── x\n","│   │   ├── training-0001.tif\n","│   │   ├── training-0002.tif\n","│   │   ├── . . .\n","│   │   ├── training-9999.tif\n","│   └── y\n","│       ├── training_groundtruth-0001.csv\n","│       ├── training_groundtruth-0002.csv\n","│       ├── . . .\n","│       ├── training_groundtruth-9999.csv\n","└── test\n","    ├── x\n","    │   ├── testing-0001.tif\n","    │   ├── testing-0002.tif\n","    │   ├── . . .\n","    │   ├── testing-9999.tif\n","    └── y\n","        ├── testing_groundtruth-0001.csv\n","        ├── testing_groundtruth-0002.csv\n","        ├── . . .\n","        ├── testing_groundtruth-9999.csv\n","```\n","\n","**⚠️ Warning:** Ensure that images and their corresponding CSV files are sorted in the same way. A common approach is to fill with zeros the image number added to the filenames (as in the example).\n","\n","**Input Format Support**\n","\n","This notebook is compatible with a range of input formats. You can use the following file extensions: `.tif`, `.npy` (every extension for 3D images supported by [scikit-image](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread)).\n"]},{"cell_type":"markdown","metadata":{"id":"xGSj0DrpUJoY"},"source":["## **Prepare the environment**\n","___\n","\n","Establish connection with Google services. You **must be logged in to Google** to continue.\n","Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal.\n"]},{"cell_type":"markdown","metadata":{"id":"4bj_sbDFTiZ7"},"source":["## **Check for GPU Access**\n","---\n","\n","By default, the session is configured to use Python 3 with GPU acceleration. However, it's a good practice to double-check these settings:\n","\n","1. Navigate to **Runtime** in the top menu and select **Change the Runtime type**.\n","2. Ensure the following settings:\n","   - **Runtime type:** Python 3 (This program is written in the Python 3 programming language.)\n","   - **Accelerator:** GPU (Graphics Processing Unit)\n","\n","This will ensure that you're using Python 3 and taking advantage of GPU acceleration."]},{"cell_type":"markdown","metadata":{"id":"XZmI9c09OhSo"},"source":["## **Manage File(s) Source**\n","---\n","\n","The input folder can be provided using three different options:\n","1. **Direct Upload**: Directly upload the desired folder.\n","2. **Google Drive**: Use a folder stored in your Google Drive.\n","3. **Sample Data**: Use a sample dataset provided by us.\n","\n","The steps you'll need to follow vary depending on your chosen option. These steps are detailed in the subsequent sections."]},{"cell_type":"markdown","metadata":{"id":"GPksHcHLO0SU"},"source":["### **Option 1: Upload Local Files to the Notebook**\n","---\n","You will be prompted to upload your files to Colab and they will be stored under `/content/input/`."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"xGS5LCaHPWR8"},"outputs":[],"source":["#@markdown ##Play the cell to upload local files (train raw images)\n","from google.colab import files\n","!mkdir -p /content/input/train/x\n","%cd /content/input/train/x\n","uploaded = files.upload()\n","%cd /content"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"qyvRptgjXMMN"},"outputs":[],"source":["#@markdown ##Play the cell to upload csv files (instance coordinates)\n","\n","from google.colab import files\n","!mkdir -p /content/input/train/y\n","%cd /content/input/train/y\n","uploaded = files.upload()\n","%cd /content"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"PafWC0U3XYjd"},"outputs":[],"source":["#@markdown ##Play the cell to upload local files (test raw images)\n","\n","from google.colab import files\n","!mkdir -p /content/input/test/x\n","%cd /content/input/test/x\n","uploaded = files.upload()\n","%cd /content"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Tl1qtfeJXYp1"},"outputs":[],"source":["#@markdown ##Play the cell to upload csv files (instance coordinates)\n","\n","from google.colab import files\n","!mkdir -p /content/input/test/y\n","%cd /content/input/test/y\n","uploaded = files.upload()\n","%cd /content"]},{"cell_type":"markdown","metadata":{"id":"nLXGd55gUYjK"},"source":["### **Option 2: Mount Your Google Drive**\n","---\n","\n","If you wish to use this notebook with data from your Google Drive, you'll first need to mount the drive to this notebook.\n","\n","Execute the cell below to initiate the Google Drive mounting process. A link will be displayed click on it. In the new browser window that opens, choose your drive and click 'Allow'. Copy the code that appears, return to this notebook, paste the code into the cell, and press 'Enter'. This action grants Colab access to your Google Drive data.\n","\n","After this process, you can access your data via the **Files** tab, located on the top left of this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"h-yXrZLdUk3Z"},"outputs":[],"source":["#@markdown ##Play the cell to connect your Google Drive to Colab\n","\n","#@markdown * Click on the URL.\n","\n","#@markdown * Sign in your Google Account.\n","\n","#@markdown * Copy the authorization code.\n","\n","#@markdown * Enter the authorization code.\n","\n","#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n","\n","# mount user's Google Drive to Google Colab.\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"u9FcxFB3H7az"},"source":["### **Option 3: Download an Example Dataset**\n","---\n","Don't have data readily available but still want to test the notebook? No problem! Simply execute the following cell to download a sample dataset.\n","\n","Specifically, we'll use the  [NucMM-Z](https://arxiv.org/abs/2107.05840) which is publicly available online. While this dataset is tailored for instance segmentation, we'll generate a CSV file detailing the center of each instance, making it compatible with our workflow."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5311,"status":"ok","timestamp":1696928453152,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"pD3aoo-ZUtW4","outputId":"5f4fbb9f-5cbc-4367-b1fb-e897f9664dbd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset downloaded and unzipped under /content/data\n"]}],"source":["#@markdown ##Play to download an example dataset\n","!pip install gdown==4.7.3 --quiet\n","import gdown\n","import os\n","\n","os.chdir('/content/')\n","gdown.download(\"https://drive.google.com/uc?id=19P4AcvBPJXeW7QRj92Jh1keunGa5fi8d\", \"NucMM-Z_training.zip\", quiet=True)\n","!unzip -q NucMM-Z_training.zip\n","!rm NucMM-Z_training.zip\n","\n","print( 'Dataset downloaded and unzipped under /content/data')\n"]},{"cell_type":"markdown","metadata":{"id":"FEv7FBXFQvjv"},"source":["## **Paths for Input Images and Output Files**\n","___\n","\n","Depending on the option you chose for managing file sources, you'll set your paths differently:\n","\n","- **Option 1 (Upload from Local Machine)**:\n","  - Set `train_data_path` to `/content/input/train/x`\n","  - Set `train_csv_path` to `/content/input/train/y`\n","  - Set `test_data_path` to `/content/input/test/x`\n","  - Set `test_csv_path` to `/content/input/test/y`\n","  - Set `output_path` to `/content/out`\n","  \n","- **Option 2 (Use Google Drive Data)**:\n","  - Insert the paths to your input files and your desired output directory here, i.e., `/content/gdrive/MyDrive/...`.\n","  \n","- **Option 3 (Use Our Sample Data)**:\n","  - Set `train_data_path` to `/content/data/train/x`\n","  - Set `train_csv_path` to `/content/data/train/y`\n","  - Set `test_data_path` to `/content/data/test/x`\n","  - Set `test_csv_path` to `/content/data/test/y`\n","  - Set `output_path` to `/content/out`\n","\n","  **Note**: Ensure you download your results from the `/content/out` directory after the process!\n","\n","**Helpful Tip**: If you're unsure about the paths to your folders, look at the top left of this notebook for a small folder icon. Navigate through the directories until you locate your desired folder. Right-click on it and select \"Copy Path\" to copy the folder's path."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"vl4e0UIGYZcx"},"outputs":[],"source":["#@markdown #####Path to train images\n","train_data_path = '/content/data/train/x' #@param {type:\"string\"}\n","#@markdown #####Path to train CSV files\n","train_csv_path = '/content/data/train/y' #@param {type:\"string\"}\n","#@markdown #####Path to test images\n","test_data_path = '/content/data/test/x' #@param {type:\"string\"}\n","#@markdown #####Path to test CSV files\n","test_csv_path = '/content/data/test/y' #@param {type:\"string\"}\n","#@markdown #####Path to store the resulting images (it'll be created if not existing):\n","output_path = '/content/output' #@param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"jLYsqrDALpVN"},"source":["## **Install BiaPy library**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23629,"status":"ok","timestamp":1696928477564,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"p33UIUUWLm3V","outputId":"a6947da5-b92f-437e-d936-fc681366fd49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'BiaPy'...\n","remote: Enumerating objects: 150, done.\u001b[K\n","remote: Counting objects: 100% (150/150), done.\u001b[K\n","remote: Compressing objects: 100% (133/133), done.\u001b[K\n","remote: Total 150 (delta 40), reused 53 (delta 14), pack-reused 0\u001b[K\n","Receiving objects: 100% (150/150), 26.36 MiB | 20.01 MiB/s, done.\n","Resolving deltas: 100% (40/40), done.\n","Obtaining file:///content/BiaPy\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from biapy==3.0) (0.4.0)\n","Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from biapy==3.0) (3.7.1)\n","Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from biapy==3.0) (1.2.2)\n","Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from biapy==3.0) (1.4.2)\n","Collecting yacs>=0.1.8 (from biapy==3.0)\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from biapy==3.0) (4.66.1)\n","Collecting scikit-image>=0.21.0 (from biapy==3.0)\n","  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting edt>=2.3.1 (from biapy==3.0)\n","  Downloading edt-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fill-voids>=2.0.5 (from biapy==3.0)\n","  Downloading fill_voids-2.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from biapy==3.0) (4.8.0.76)\n","Collecting torchinfo>=1.8.0 (from biapy==3.0)\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Collecting torchmetrics>=1.0.3 (from biapy==3.0)\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboardX>=2.6.2.2 (from biapy==3.0)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting timm>=0.9.5 (from biapy==3.0)\n","  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from edt>=2.3.1->biapy==3.0) (1.23.5)\n","Collecting fastremap (from fill-voids>=2.0.5->biapy==3.0)\n","  Downloading fastremap-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->biapy==3.0) (1.16.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->biapy==3.0) (1.11.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->biapy==3.0) (9.4.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->biapy==3.0) (2.31.5)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->biapy==3.0) (2.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->biapy==3.0) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->biapy==3.0) (0.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->biapy==3.0) (4.43.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->biapy==3.0) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->biapy==3.0) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->biapy==3.0) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->biapy==3.0) (2.8.2)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->biapy==3.0) (3.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->biapy==3.0) (2023.9.26)\n","Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->biapy==3.0) (0.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->biapy==3.0) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->biapy==3.0) (3.2.0)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6.2.2->biapy==3.0) (3.20.3)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.5->biapy==3.0) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.5->biapy==3.0) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.5->biapy==3.0) (6.0.1)\n","Collecting huggingface-hub (from timm>=0.9.5->biapy==3.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm>=0.9.5->biapy==3.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lightning-utilities>=0.8.0 (from torchmetrics>=1.0.3->biapy==3.0)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics>=1.0.3->biapy==3.0) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm>=0.9.5->biapy==3.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm>=0.9.5->biapy==3.0) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm>=0.9.5->biapy==3.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm>=0.9.5->biapy==3.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm>=0.9.5->biapy==3.0) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm>=0.9.5->biapy==3.0) (17.0.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm>=0.9.5->biapy==3.0) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm>=0.9.5->biapy==3.0) (2.31.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm>=0.9.5->biapy==3.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm>=0.9.5->biapy==3.0) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm>=0.9.5->biapy==3.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm>=0.9.5->biapy==3.0) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm>=0.9.5->biapy==3.0) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm>=0.9.5->biapy==3.0) (1.3.0)\n","Installing collected packages: yacs, torchinfo, tensorboardX, safetensors, lightning-utilities, fastremap, edt, scikit-image, huggingface-hub, fill-voids, torchmetrics, timm, biapy\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","  Running setup.py develop for biapy\n","Successfully installed biapy-3.0 edt-2.3.1 fastremap-1.14.0 fill-voids-2.0.5 huggingface-hub-0.17.3 lightning-utilities-0.9.0 safetensors-0.4.0 scikit-image-0.22.0 tensorboardX-2.6.2.2 timm-0.9.7 torchinfo-1.8.0 torchmetrics-1.2.0 yacs-0.1.8\n"]}],"source":["#@markdown ##Play to install BiaPy and its dependences\n","\n","import os\n","import sys\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from skimage.io import imread\n","import ipywidgets as widgets\n","from ipywidgets import Output\n","\n","!pip install biapy==3.3.2\n","from biapy import BiaPy\n","\n","changed_source = False"]},{"cell_type":"markdown","metadata":{"id":"9ZwoZC20rK42"},"source":["## **Configure and Train the DNN Model**\n","---\n","\n","Within this workflow, [BiaPy](https://biapy.readthedocs.io/en/latest/) aims to localize objects in the input image by pinpointing individual central points at their center of mass, as described by [Zhou et. al](https://arxiv.org/abs/1904.07850). To achieve this, we generate a mask utilizing the points listed in the CSV to train the network. The **central_point_dilation** variable determines the size of these central points. In case of 3D images, only in the middle slice of the object is considered to be the central point.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6854e995efba4ee59a4f7394e274974f","version_major":2,"version_minor":0},"text/plain":["ToggleButtons(description='Source:', options=('BiaPy', 'Torchvision', 'BioImage Model Zoo'), tooltips=('Models…"]},"metadata":{},"output_type":"display_data"}],"source":["#@markdown ###Play to select the source to build the model (BiaPy, Torchvision or BioImage Model Zoo) { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","changed_source = True\n","exists_tv = False\n","exists_bmz = False\n","# create widgets\n","source = widgets.ToggleButtons(\n","    options=['BiaPy', 'Torchvision', 'BioImage Model Zoo'],\n","    description='Source:',\n","    disabled=False,\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    tooltips=['Models created during this workflow', 'Torchvision model', 'BioImage Model Zoo model'],\n","#     icons=['check'] * 3\n",")\n","\n","t_vision = widgets.Dropdown(\n","    options=['fasterrcnn_mobilenet_v3_large_320_fpn', 'fasterrcnn_mobilenet_v3_large_fpn', 'fasterrcnn_resnet50_fpn', \n","             'fasterrcnn_resnet50_fpn_v2', 'fcos_resnet50_fpn', 'ssd300_vgg16', 'ssdlite320_mobilenet_v3_large',\n","             'retinanet_resnet50_fpn', 'retinanet_resnet50_fpn_v2',],\n","    value='fasterrcnn_mobilenet_v3_large_320_fpn',\n","    description='Supported:',\n","    disabled=False,\n",")\n","\n","\n","bmz = widgets.Text(\n","    # value='10.5281/zenodo.5764892',\n","    placeholder='DOI of BMZ model',\n","    description='DOI:',\n","    disabled=False\n",")\n","\n","# display the first widget\n","display(source)\n","\n","# intialize the output - second widget\n","out = Output()\n","\n","def changed(change):\n","    '''\n","    Monitor change in the first widget\n","    '''\n","    global out\n","    global exists_bmz\n","    global exists_tv\n","    if source.value == 'BiaPy':\n","        bmz.layout.display = 'none'\n","        t_vision.layout.display = 'none'\n","        out.clear_output() #clear output\n","        out = Output() # redefine output\n","    else:\n","        if source.value == 'Torchvision':\n","          bmz.layout.display = 'none'\n","          t_vision.layout.display = 'none'\n","          t_vision.layout.display = 'flex'\n","          if not exists_tv:\n","            out.append_display_data(t_vision)\n","            display(out)\n","          exists_tv = True\n","        else:\n","          t_vision.layout.display = 'none'\n","          bmz.layout.display = 'none'\n","          bmz.layout.display = 'flex'\n","          if not exists_bmz:\n","            out.append_display_data(bmz)\n","            display(out)\n","          exists_bmz = True\n","\n","# monitor the source widget for changes\n","source.observe(changed, 'value')"]},{"cell_type":"markdown","metadata":{"id":"4gNxwa6KaWYn"},"source":["### **Select your parameters**\n","---\n","#### **Name of the model**\n","* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n","\n","#### **Data management**\n","* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n","\n","* **`test_ground_truth`:** Select to use test data ground truth to measure the performance of the model's result. If selected, **test_data_gt_path** variable path set above will be used. **Default value: True**\n","\n","#### **Basic training parameters**\n","* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. For the example dataset, preliminary results can already be observed after 50 epochs, but better results are obtained when running the model longer. **Default value: 100**\n","\n","* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 20**\n","\n","#### **Advanced Parameters - experienced users only**\n","* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: U-Net, Residual U-Net, Attention U-Net, SEUNet, MultiResUNet, ResUNet++ (see [Franco-Barranco et al., 2021](https://link.springer.com/article/10.1007/s12021-021-09556-1)), UNETR-Mini, UNETR-Small and UNETR-Base. **Default value: Residual U-Net**\n","\n","* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 8**\n","\n","* **`patch_size_xy`:** Input the XY size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 64**\n","\n","* **`patch_size_z`:** Input the Z size of the patches use to train your model (length in pixels in Z). The value should be smaller or equal to the dimensions of the image. **Default value: 64**\n","\n","* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 1**\n","\n","* **`anisotropic_data`:** Select if your image data is anisotropic (lower resolution in Z with respect to XY). The model downsampling step size will be set accordingly. **Default value: False**\n","\n","* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, ADAMW, Stochastic Gradient Descent (SGD). ADAM usually converges faster, while ADAMW provides a balance between fast convergence and better handling of weight decay regularization. SGD is known for better generalization. **Default value: ADAMW**\n","\n","* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer, this value should be around 10e-4. **Default value: 0.0001**\n","\n","* **`test_time_augmentation`:** Select to apply augmentation (flips and rotations) at test time. It usually provides more robust results but uses more time to produce each result. **Default value: False**\n","\n","* **`min_value_to_be_peak`:** Minimun value to consider a point as a peak. This value needs to between 0 and 1. **Default value: 0.2**\n","\n","* **`resolution_xy`:** Data resolution in for y and x axis. **Default value: 0.51**\n","\n","* **`resolution_z`:** Data resolution in for z axis. **Default value: 0.48**\n","\n","#### **Advanced Parameters of Detection - experienced users only**\n","\n","* **`central_point_dilation`:** Size of the disk that will be used to dilate the central point created from the CSV file to train the network. Set it to 0 to not dilate and only create a 3x3 square. Normally it is set to 3 but here we set it to 0 because the nuclei of this dataset are very small. **Default value: 0**\n","\n","* **`tolerance`:** Maximum distance far away from a GT point to consider a point as a true positive. **Default value: 3**\n","\n","* **`remove_close_points`:** Distance between points to be considered the same so only one will be kept. **Default value: True**\n","\n","* **`remove_close_points_radius`:** Maximum distance far away from a GT point to consider a point as a true positive. **Default value: 3**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"RLdMygZVT5aH"},"outputs":[],"source":["#@markdown ###Name of the model:\n","model_name = \"my_3d_detection\" #@param {type:\"string\"}\n","\n","#@markdown ### Data management:\n","test_ground_truth = True #@param {type:\"boolean\"}\n","percentage_validation =  10 #@param {type:\"number\"}\n","\n","#@markdown ### Basic training parameters:\n","number_of_epochs =  100#@param {type:\"number\"}\n","patience =  20#@param {type:\"number\"}\n","\n","#@markdown ### Advanced training parameters:\n","\n","model_architecture = \"Residual U-Net\" #@param [\"U-Net\", \"Residual U-Net\", \"Attention U-Net\", 'MultiResUNet', 'SEUNet', 'ResUNet++', \"UNETR-Mini\",\"UNETR-Small\", \"UNETR-Base\"]\n","\n","batch_size =  8#@param {type:\"number\"}\n","patch_size_xy = 64 #@param {type:\"number\"}\n","patch_size_z = 64 #@param {type:\"number\"}\n","resolution_xy = 0.51 #@param {type:\"number\"}\n","resolution_z = 0.48 #@param {type:\"number\"}\n","\n","input_channels = 1 #@param {type:\"number\"}\n","anisotropic_data = False #@param {type:\"boolean\"}\n","\n","optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\",\"ADAMW\"]\n","initial_learning_rate = 0.0001 #@param {type:\"number\"}\n","\n","test_time_augmentation = False #@param {type:\"boolean\"}\n","\n","#@markdown ### Advanced Parameters of Detection:\n","central_point_dilation = 0 #@param {type:\"number\"}\n","min_value_to_be_peak = 0.2 #@param {type:\"number\"}\n","tolerance = 3 #@param {type:\"number\"}\n","remove_close_points = True #@param {type:\"boolean\"}\n","remove_close_points_radius= 3 #@param {type:\"number\"}\n","\n","checkpoint_path = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"iZ_TuIVZXGGM"},"outputs":[],"source":["#@markdown ##OPTIONAL: Play the cell to upload initial model weights\n","#@markdown Use this option to start the training from a **pre-trained model** if you have one. Otherwise, skip this cell.\n","\n","#@markdown **Important**: remember the weights must correspond to the selected architecture, patch size and number of input channels. Otherwise, an error will be shown when training.\n","from google.colab import files\n","\n","#s.chdir('/content/')\n","\n","uploaded = files.upload()\n","\n","checkpoint_path = '/content/' + list(uploaded.keys())[0]\n","\n","# open previously configured file, if exists\n","job_name = model_name\n","yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n","\n","# edit previous configuration file if it exists to load the checkpoint model\n","if os.path.exists( yaml_file ):\n","    import yaml\n","    with open( yaml_file, 'r') as stream:\n","        try:\n","            biapy_config = yaml.safe_load(stream)\n","        except yaml.YAMLError as exc:\n","            print(exc)\n","    biapy_config['PATHS'] = {}\n","    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n","    biapy_config['MODEL'] = {}\n","    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n","\n","    # save file\n","    with open( yaml_file, 'w') as outfile:\n","        yaml.dump(biapy_config, outfile, default_flow_style=False)\n","\n","print( \"Pre-trained model loaded and ready to re-train.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1696928477943,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"kAMzWWGuhHcv","outputId":"0fc363f3-117b-415e-e63e-e6d66d9c8b8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training configuration finished.\n"]}],"source":["#@markdown ##Play to download the YAML configuration file and update it to train the model\n","import errno\n","\n","os.chdir('/content/')\n","\n","job_name = model_name\n","yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n","\n","# remove previous configuration file if it exists with the same name\n","if os.path.exists( yaml_file ):\n","    os.remove( yaml_file )\n","\n","# remove template file it is exists\n","template_file = '3d_detection.yaml'\n","if os.path.exists( template_file ):\n","    os.remove( template_file )\n","\n","# Download template file\n","!wget https://raw.githubusercontent.com/BiaPyX/BiaPy/master/templates/detection/3d_detection.yaml &> /dev/null\n","\n","# Check folders before modifying the .yaml file\n","if not os.path.exists(train_data_path):\n","    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n","ids = sorted(next(os.walk(train_data_path))[2])\n","if len(ids) == 0:\n","    raise ValueError(\"No csv files in dir {}\".format(train_data_path))\n","if not os.path.exists(train_csv_path):\n","    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_csv_path)\n","ids = sorted(next(os.walk(train_csv_path))[2])\n","if len(ids) == 0:\n","    raise ValueError(\"No images found in dir {}\".format(train_csv_path))\n","\n","# Check folders before modifying the .yaml file\n","if not os.path.exists(test_data_path):\n","    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n","ids = sorted(next(os.walk(test_data_path))[2])\n","if len(ids) == 0:\n","    raise ValueError(\"No images found in dir {}\".format(test_data_path))\n","if test_ground_truth:\n","    if not os.path.exists(test_csv_path):\n","        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_csv_path)\n","    ids = sorted(next(os.walk(test_csv_path))[2])\n","    if len(ids) == 0:\n","        raise ValueError(\"No csv files in dir {}\".format(test_csv_path))\n","\n","\n","# open template configuration file\n","import yaml\n","with open( template_file, 'r') as stream:\n","    try:\n","        biapy_config = yaml.safe_load(stream)\n","    except yaml.YAMLError as exc:\n","        print(exc)\n","\n","biapy_config['SYSTEM']['NUM_CPUS'] = -1\n","biapy_config['PROBLEM']['DETECTION'] = {}\n","biapy_config['PROBLEM']['DETECTION']['CENTRAL_POINT_DILATION'] = central_point_dilation\n","\n","# update paths to data\n","biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n","biapy_config['DATA']['TRAIN']['GT_PATH'] = train_csv_path\n","biapy_config['DATA']['TEST']['PATH'] = test_data_path\n","biapy_config['DATA']['TEST']['GT_PATH'] = test_csv_path\n","\n","# update data patch size\n","biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size_z)+', '+ str(patch_size_xy)+', '+ str(patch_size_xy)+ ', ' + str(input_channels)+')'\n","# adjust test padding accordingly\n","padding_xy = patch_size_xy // 8\n","padding_z = patch_size_z // 8\n","biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding_z)+', '+ str(padding_xy)+', '+ str(padding_xy)+')'\n","biapy_config['DATA']['TEST']['RESOLUTION'] = '('+str(resolution_z)+', '+ str(resolution_xy)+', ' + str(resolution_xy)+')'\n","\n","# update training parameters\n","biapy_config['DATA']['VAL']['FROM_TRAIN'] = True\n","biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n","biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n","biapy_config['TRAIN']['PATIENCE'] = patience\n","biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n","biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n","biapy_config['TRAIN']['LR'] = initial_learning_rate\n","\n","# change source to build model - biapy, torchvision or bmz\n","if changed_source:\n","    if source.value == \"BiaPy\":\n","        biapy_config['MODEL']['SOURCE'] = \"biapy\"\n","    elif source.value == 'Torchvision':\n","        biapy_config['MODEL']['SOURCE'] = \"torchvision\"\n","        biapy_config['MODEL']['TORCHVISION_MODEL_NAME'] = t_vision.value\n","    elif source.value == 'BioImage Model Zoo':\n","        biapy_config['MODEL']['SOURCE'] = \"bmz\"\n","        biapy_config['MODEL']['BMZ'] = {}\n","        biapy_config['MODEL']['BMZ']['SOURCE_MODEL_DOI'] = bmz.value\n","else:\n","    biapy_config['MODEL']['SOURCE'] = \"biapy\"\n","\n","\n","# Transcribe model architecture\n","# Available models: \"U-Net\", \"Residual U-Net\", \"Attention U-Net\",\n","# 'MultiResUNet', 'SEUNet', 'ResUNet++', \"UNETR-Mini\",\"UNETR-Small\"\n","# \"UNETR-Base\"architecture = 'unet'\n","if model_architecture == \"U-Net\":\n","    architecture = 'unet'\n","elif model_architecture == \"Residual U-Net\":\n","    architecture = 'resunet'\n","elif model_architecture == \"Attention U-Net\":\n","    architecture = 'attention_unet'\n","elif model_architecture == \"MultiResUNet\":\n","    architecture = 'multiresunet'\n","elif model_architecture == \"SEUNet\":\n","    architecture = 'seunet'\n","elif model_architecture == \"ResUNet++\":\n","    architecture = 'resunet++'\n","elif model_architecture == \"UNETR-Mini\":\n","    architecture = 'unetr'\n","    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n","    biapy_config['MODEL']['VIT_EMBED_DIM'] = 64\n","    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 4\n","    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4. # to get 256\n","    biapy_config['MODEL']['VIT_NUM_HEADS'] = 4\n","    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 1\n","elif model_architecture == \"UNETR-Small\":\n","    architecture = 'unetr'\n","    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n","    biapy_config['MODEL']['VIT_EMBED_DIM'] = 128\n","    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 8\n","    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4. # to get 512\n","    biapy_config['MODEL']['VIT_NUM_HEADS'] = 8\n","    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 2\n","else: # UNETR-Base\n","    architecture = 'unetr'\n","    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n","    biapy_config['MODEL']['VIT_EMBED_DIM'] = 256\n","    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 12\n","    biapy_config['MODEL']['VIT_MLP_RATIO'] = 3. # to get 768\n","    biapy_config['MODEL']['VIT_NUM_HEADS'] = 12\n","    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 3\n","\n","\n","biapy_config['MODEL']['ARCHITECTURE'] = architecture\n","\n","# update test parameters\n","biapy_config['TEST']['STATS'] = {}\n","biapy_config['TEST']['STATS']['PER_PATCH']=True\n","biapy_config['TEST']['STATS']['MERGE_PATCHES']=True\n","biapy_config['TEST']['STATS']['FULL_IMG']=False\n","biapy_config['TEST']['AUGMENTATION'] = test_time_augmentation\n","biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n","biapy_config['TEST']['ENABLE'] = True\n","biapy_config['TEST']['REDUCE_MEMORY'] = True\n","\n","# Detection parameters\n","biapy_config['TEST']['DET_MIN_TH_TO_BE_PEAK'] = [min_value_to_be_peak]\n","biapy_config['TEST']['DET_TOLERANCE'] = [tolerance]\n","biapy_config['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS'] = remove_close_points\n","biapy_config['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS_RADIUS'] = [remove_close_points_radius]\n","\n","# model weights\n","if checkpoint_path != '':\n","    biapy_config['PATHS'] = {}\n","    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n","    biapy_config['MODEL'] = {}\n","    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n","\n","# save file\n","with open( yaml_file, 'w') as outfile:\n","    yaml.dump(biapy_config, outfile, default_flow_style=False)\n","\n","print( \"Training configuration finished.\")"]},{"cell_type":"markdown","metadata":{"id":"S8kLFc8_ajHD"},"source":["### **Train the model**\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":559058,"status":"ok","timestamp":1696930843219,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"CZKK9EoVmH-Y","outputId":"ae9f4a54-51c9-43bf-d196-be843a61d6f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Date: 2023-10-10 09:31:28\n","Arguments: Namespace(config='/content/my_3d_detection.yaml', result_dir='/content/output', name='my_3d_detection', run_id=1, gpu='0', world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n","Job: my_3d_detection_1\n","Python       : 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","PyTorch:  2.0.1+cu118\n","Not using distributed mode\n","[09:31:28.428617] Configuration details:\n","[09:31:28.428670] AUGMENTOR:\n","  AFFINE_MODE: constant\n","  AUG_NUM_SAMPLES: 10\n","  AUG_SAMPLES: True\n","  BRIGHTNESS: False\n","  BRIGHTNESS_EM: False\n","  BRIGHTNESS_EM_FACTOR: (-0.1, 0.1)\n","  BRIGHTNESS_EM_MODE: 3D\n","  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n","  BRIGHTNESS_MODE: 3D\n","  CBLUR_DOWN_RANGE: (2, 8)\n","  CBLUR_INSIDE: True\n","  CBLUR_SIZE: (0.2, 0.4)\n","  CHANNEL_SHUFFLE: False\n","  CMIX_SIZE: (0.2, 0.4)\n","  CNOISE_NB_ITERATIONS: (1, 3)\n","  CNOISE_SCALE: (0.05, 0.1)\n","  CNOISE_SIZE: (0.2, 0.4)\n","  CONTRAST: False\n","  CONTRAST_EM: False\n","  CONTRAST_EM_FACTOR: (-0.1, 0.1)\n","  CONTRAST_EM_MODE: 3D\n","  CONTRAST_FACTOR: (-0.1, 0.1)\n","  CONTRAST_MODE: 3D\n","  COUT_APPLY_TO_MASK: False\n","  COUT_CVAL: 0.0\n","  COUT_NB_ITERATIONS: (1, 3)\n","  COUT_SIZE: (0.05, 0.3)\n","  CUTBLUR: False\n","  CUTMIX: False\n","  CUTNOISE: False\n","  CUTOUT: False\n","  DA_PROB: 0.5\n","  DRAW_GRID: True\n","  DROPOUT: False\n","  DROP_RANGE: (0, 0.2)\n","  ELASTIC: False\n","  ENABLE: True\n","  E_ALPHA: (12, 16)\n","  E_MODE: constant\n","  E_SIGMA: 4\n","  GAMMA_CONTRAST: False\n","  GAUSSIAN_NOISE: False\n","  GAUSSIAN_NOISE_MEAN: 0.0\n","  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n","  GAUSSIAN_NOISE_VAR: 0.05\n","  GC_GAMMA: (1.25, 1.75)\n","  GRAYSCALE: False\n","  GRIDMASK: False\n","  GRID_D_RANGE: (0.4, 1)\n","  GRID_INVERT: False\n","  GRID_RATIO: 0.6\n","  GRID_ROTATE: 1.0\n","  G_BLUR: False\n","  G_SIGMA: (1.0, 2.0)\n","  HFLIP: True\n","  MB_KERNEL: (3, 7)\n","  MEDIAN_BLUR: False\n","  MISALIGNMENT: False\n","  MISSING_SECTIONS: False\n","  MISSP_ITERATIONS: (10, 30)\n","  MOTB_K_RANGE: (8, 12)\n","  MOTION_BLUR: False\n","  MS_DISPLACEMENT: 16\n","  MS_ROTATE_RATIO: 0.5\n","  PEPPER: False\n","  PEPPER_AMOUNT: 0.05\n","  POISSON_NOISE: False\n","  RANDOM_ROT: False\n","  RANDOM_ROT_RANGE: (-180, 180)\n","  ROT90: False\n","  SALT: False\n","  SALT_AMOUNT: 0.05\n","  SALT_AND_PEPPER: False\n","  SALT_AND_PEPPER_AMOUNT: 0.05\n","  SALT_AND_PEPPER_PROP: 0.5\n","  SHEAR: False\n","  SHEAR_RANGE: (-20, 20)\n","  SHIFT: False\n","  SHIFT_RANGE: (0.1, 0.2)\n","  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n","  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n","  VFLIP: True\n","  ZFLIP: True\n","  ZOOM: False\n","  ZOOM_RANGE: (0.8, 1.2)\n","DATA:\n","  CHECK_GENERATORS: False\n","  EXTRACT_RANDOM_PATCH: False\n","  NORMALIZATION:\n","    CUSTOM_MEAN: -1.0\n","    CUSTOM_STD: -1.0\n","    TYPE: div\n","  PATCH_SIZE: (64, 64, 64, 1)\n","  PROBABILITY_MAP: False\n","  REFLECT_TO_COMPLETE_SHAPE: False\n","  TEST:\n","    ARGMAX_TO_OUTPUT: False\n","    BINARY_MASKS: /content/data/test/x/../bin_mask\n","    CHECK_DATA: True\n","    DETECTION_MASK_DIR: /content/data/test/y_detection_masks\n","    GT_PATH: /content/data/test/y\n","    INSTANCE_CHANNELS_DIR: /content/data/test/x_BC_thick\n","    INSTANCE_CHANNELS_MASK_DIR: /content/data/test/y_BC_thick\n","    IN_MEMORY: True\n","    LOAD_GT: True\n","    MEDIAN_PADDING: False\n","    OVERLAP: (0, 0, 0)\n","    PADDING: (8, 8, 8)\n","    PATH: /content/data/test/x\n","    RESOLUTION: (0.48, 0.51, 0.51)\n","    SSL_SOURCE_DIR: /content/data/test/x_ssl_source\n","    USE_VAL_AS_TEST: False\n","  TRAIN:\n","    CHECK_DATA: True\n","    DETECTION_MASK_DIR: /content/data/train/y_detection_masks\n","    GT_PATH: /content/data/train/y\n","    INSTANCE_CHANNELS_DIR: /content/data/train/x_BC_thick\n","    INSTANCE_CHANNELS_MASK_DIR: /content/data/train/y_BC_thick\n","    IN_MEMORY: True\n","    MINIMUM_FOREGROUND_PER: -1.0\n","    OVERLAP: (0, 0, 0)\n","    PADDING: (0, 0, 0)\n","    PATH: /content/data/train/x\n","    REPLICATE: 0\n","    RESOLUTION: (1, 1, 1)\n","    SSL_SOURCE_DIR: /content/data/train/x_ssl_source\n","  VAL:\n","    BINARY_MASKS: user_data/val/x/../bin_mask\n","    CROSS_VAL: False\n","    CROSS_VAL_FOLD: 1\n","    CROSS_VAL_NFOLD: 5\n","    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n","    DIST_EVAL: True\n","    FROM_TRAIN: True\n","    GT_PATH: user_data/val/y\n","    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n","    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n","    IN_MEMORY: True\n","    OVERLAP: (0, 0, 0)\n","    PADDING: (0, 0, 0)\n","    PATH: user_data/val/x\n","    RANDOM: True\n","    RESOLUTION: (1, 1, 1)\n","    SPLIT_TRAIN: 0.1\n","    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n","  W_BACKGROUND: 0.06\n","  W_FOREGROUND: 0.94\n","LOG:\n","  CHART_CREATION_FREQ: 5\n","  LOG_DIR: /content/output/my_3d_detection/train_logs\n","  LOG_FILE_PREFIX: my_3d_detection_1\n","  TENSORBOARD_LOG_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/tensorboard\n","LOSS:\n","  TYPE: CE\n","MODEL:\n","  ACTIVATION: ELU\n","  ARCHITECTURE: resunet\n","  BATCH_NORMALIZATION: True\n","  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0]\n","  FEATURE_MAPS: [18, 36, 48, 64]\n","  KERNEL_SIZE: 3\n","  LAST_ACTIVATION: sigmoid\n","  LOAD_CHECKPOINT: False\n","  LOAD_CHECKPOINT_EPOCH: best_on_val\n","  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n","  MAE_DEC_HIDDEN_SIZE: 512\n","  MAE_DEC_MLP_DIMS: 2048\n","  MAE_DEC_NUM_HEADS: 16\n","  MAE_DEC_NUM_LAYERS: 8\n","  N_CLASSES: 2\n","  SAVE_CKPT_FREQ: -1\n","  UNETR_DEC_ACTIVATION: relu\n","  UNETR_VIT_HIDD_MULT: 3\n","  UNETR_VIT_NUM_FILTERS: 16\n","  UNET_SR_UPSAMPLE_POSITION: pre\n","  UPSAMPLE_LAYER: convtranspose\n","  VIT_EMBED_DIM: 768\n","  VIT_MLP_RATIO: 4.0\n","  VIT_MODEL: custom\n","  VIT_NORM_EPS: 1e-06\n","  VIT_NUM_HEADS: 12\n","  VIT_NUM_LAYERS: 12\n","  VIT_TOKEN_SIZE: 16\n","  Z_DOWN: [2, 2, 2]\n","PATHS:\n","  CHARTS: /content/output/my_3d_detection/results/my_3d_detection_1/charts\n","  CHECKPOINT: /content/output/my_3d_detection/checkpoints\n","  CHECKPOINT_FILE: \n","  DA_SAMPLES: /content/output/my_3d_detection/results/my_3d_detection_1/aug\n","  GEN_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_check\n","  GEN_MASK_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_mask_check\n","  MAE_CALLBACK_OUT_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/MAE_checks\n","  MEAN_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_mean_value.npy\n","  PROB_MAP_DIR: /content/output/my_3d_detection/prob_map\n","  PROB_MAP_FILENAME: prob_map.npy\n","  PROFILER: /content/output/my_3d_detection/results/my_3d_detection_1/profiler\n","  RESULT_DIR:\n","    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack_post_processing\n","    DET_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","    FULL_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/full_image\n","    FULL_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_binarized\n","    INST_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/instance_associations\n","    PATH: /content/output/my_3d_detection/results/my_3d_detection_1\n","    PER_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","    PER_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_binarized\n","    PER_IMAGE_INSTANCES: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_instances\n","    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_post_processing\n","  STD_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_std_value.npy\n","  TEST_FULL_GT_H5: /content/data/test/y/h5\n","  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/test_BC_instance_channels\n","  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/train_BC_instance_channels\n","  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/val_BC_instance_channels\n","  WATERSHED_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/watershed\n","PROBLEM:\n","  DENOISING:\n","    N2V_MANIPULATOR: uniform_withCP\n","    N2V_NEIGHBORHOOD_RADIUS: 5\n","    N2V_PERC_PIX: 0.198\n","    N2V_STRUCTMASK: False\n","  DETECTION:\n","    CENTRAL_POINT_DILATION: 0\n","    CHECK_POINTS_CREATED: True\n","    DATA_CHECK_MW: True\n","  INSTANCE_SEG:\n","    DATA_CHANNELS: BC\n","    DATA_CHANNEL_WEIGHTS: (1, 1)\n","    DATA_CHECK_MW: True\n","    DATA_CONTOUR_MODE: thick\n","    DATA_MW_TH_BINARY_MASK: 0.5\n","    DATA_MW_TH_CONTOUR: 0.1\n","    DATA_MW_TH_DISTANCE: 1.0\n","    DATA_MW_TH_FOREGROUND: 0.3\n","    DATA_MW_TH_POINTS: 0.5\n","    DATA_MW_TH_TYPE: auto\n","    DATA_REMOVE_AFTER_MW: False\n","    DATA_REMOVE_BEFORE_MW: False\n","    DATA_REMOVE_SMALL_OBJ_AFTER: 100\n","    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n","    DISTANCE_CHANNEL_MASK: True\n","    ERODE_AND_DILATE_FOREGROUND: False\n","    FORE_DILATION_RADIUS: 5\n","    FORE_EROSION_RADIUS: 5\n","    SEED_MORPH_RADIUS: []\n","    SEED_MORPH_SEQUENCE: []\n","  NDIM: 3D\n","  SELF_SUPERVISED:\n","    NOISE: 0.2\n","    PRETEXT_TASK: crappify\n","    RESIZING_FACTOR: 4\n","  SEMANTIC_SEG:\n","    IGNORE_CLASS_ID: 0\n","  SUPER_RESOLUTION:\n","    UPSCALING: 1\n","  TYPE: DETECTION\n","SYSTEM:\n","  NUM_CPUS: 2\n","  NUM_GPUS: 1\n","  PIN_MEM: True\n","  SEED: 0\n","TEST:\n","  ANALIZE_2D_IMGS_AS_3D_STACK: False\n","  AUGMENTATION: False\n","  DET_LOCAL_MAX_COORDS: True\n","  DET_MIN_TH_TO_BE_PEAK: [0.2]\n","  DET_TOLERANCE: [3]\n","  ENABLE: True\n","  EVALUATE: True\n","  MATCHING_SEGCOMPARE: False\n","  MATCHING_STATS: True\n","  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n","  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n","  POST_PROCESSING:\n","    APPLY_MASK: False\n","    CLEAR_BORDER: False\n","    DET_WATERSHED: False\n","    DET_WATERSHED_DONUTS_CLASSES: [-1]\n","    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n","    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n","    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n","    REMOVE_CLOSE_POINTS: True\n","    REMOVE_CLOSE_POINTS_RADIUS: [3]\n","    REPARE_LARGE_BLOBS_SIZE: -1\n","    VORONOI_ON_MASK: False\n","    VORONOI_TH: 0.0\n","    WATERSHED_CIRCULARITY: -1.0\n","    YZ_FILTERING: False\n","    YZ_FILTERING_SIZE: 5\n","    Z_FILTERING: False\n","    Z_FILTERING_SIZE: 5\n","  REDUCE_MEMORY: True\n","  STATS:\n","    FULL_IMG: False\n","    MERGE_PATCHES: True\n","    PER_PATCH: True\n","  VERBOSE: True\n","TRAIN:\n","  ACCUM_ITER: 1\n","  BATCH_SIZE: 8\n","  CHECKPOINT_MONITOR: val_loss\n","  ENABLE: True\n","  EPOCHS: 100\n","  LR: 0.0001\n","  LR_SCHEDULER:\n","    MIN_LR: -1.0\n","    NAME: \n","    REDUCEONPLATEAU_FACTOR: 0.5\n","    REDUCEONPLATEAU_PATIENCE: -1\n","    WARMUP_COSINE_DECAY_EPOCHS: -1\n","  OPTIMIZER: ADAMW\n","  PATIENCE: 20\n","  W_DECAY: 0.05\n","[09:31:28.797325] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n","[09:31:28.797380] Initializing Detection_Workflow\n","[09:31:28.797396] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n","\n","[09:31:28.797558] ####################\n","#  PRE-PROCESSING  #\n","####################\n","\n","[09:31:28.797582] ############################\n","[09:31:28.797594] #  PREPARE DETECTION DATA  #\n","[09:31:28.797606] ############################\n","[09:31:28.797857] DATA.TRAIN.GT_PATH changed from /content/data/train/y to /content/data/train/y_detection_masks\n","[09:31:28.797896] DATA.TEST.GT_PATH changed from /content/data/test/y to /content/data/test/y_detection_masks\n","[09:31:28.798133] ##########################\n","[09:31:28.798175] #   LOAD TRAINING DATA   #\n","[09:31:28.798188] ##########################\n","[09:31:28.798257] ### LOAD ###\n","[09:31:28.798275] 0) Loading train images . . .\n","[09:31:28.798293] Loading data from /content/data/train/x\n","100% 27/27 [00:00<00:00, 1108.45it/s]\n","[09:31:28.827776] *** Loaded data shape is (27, 64, 64, 64, 1)\n","[09:31:28.827827] 1) Loading train GT . . .\n","[09:31:28.827850] Loading data from /content/data/train/y_detection_masks\n","100% 27/27 [00:00<00:00, 223.63it/s]\n","[09:31:28.951840] *** Loaded data shape is (27, 64, 64, 64, 1)\n","[09:31:28.951886] Creating validation data\n","[09:31:28.957534] *** Loaded train data shape is: (24, 64, 64, 64, 1)\n","[09:31:28.957582] *** Loaded train GT shape is: (24, 64, 64, 64, 1)\n","[09:31:28.957595] *** Loaded validation data shape is: (3, 64, 64, 64, 1)\n","[09:31:28.957613] *** Loaded validation GT shape is: (3, 64, 64, 64, 1)\n","[09:31:28.957667] ##############################\n","[09:31:28.957684] #  PREPARE TRAIN GENERATORS  #\n","[09:31:28.957695] ##############################\n","[09:31:28.957904] Initializing train data generator . . .\n","[09:31:28.970524] Normalization config used for X: {'type': 'div', 'orig_dtype': dtype('uint8'), 'div_255': 1}\n","[09:31:28.970561] Normalization config used for Y: as_mask\n","[09:31:28.971656] Initializing val data generator . . .\n","[09:31:28.973702] Normalization config used for X: {'type': 'div', 'orig_dtype': dtype('uint8'), 'div_255': 1}\n","[09:31:28.973740] Normalization config used for Y: as_mask\n","[09:31:28.973902] Creating generator samples . . .\n","[09:31:28.973941] 0) Creating samples of data augmentation . . .\n","  0% 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n"," 90% 9/10 [00:00<00:00, 82.94it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","                         \u001b[A\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","100% 10/10 [00:00<00:00, 81.41it/s]\n","[09:31:29.097611] Accumulate grad iterations: 1\n","[09:31:29.097645] Effective batch size: 8\n","[09:31:29.097679] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f24d7f86830>\n","[09:31:29.097986] #######################\n","[09:31:29.098010] # Prepare loggin tool #\n","[09:31:29.098030] #######################\n","[09:31:29.099124] ###############\n","[09:31:29.099157] # Build model #\n","[09:31:29.099169] ###############\n","[09:31:33.046380] ==================================================================================================================================\n","Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #\n","==================================================================================================================================\n","ResUNet                                                 [1, 1, 64, 64, 64]        [1, 1, 64, 64, 64]        --\n","├─ModuleList: 1-1                                       --                        --                        --\n","│    └─ResConvBlock: 2-1                                [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    └─Sequential: 3-1                             [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    └─ConvBlock: 4-1                         [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─Sequential: 5-1                   [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Conv3d: 6-1                  [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       504\n","│    │    │    │    │    └─BatchNorm3d: 6-2             [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       36\n","│    │    │    │    │    └─ELU: 6-3                     [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    └─ConvBlock: 4-2                         [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─Sequential: 5-2                   [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Conv3d: 6-4                  [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       8,766\n","│    │    └─Sequential: 3-2                             [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    └─Conv3d: 4-3                            [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       36\n","│    └─ResConvBlock: 2-2                                [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    └─Sequential: 3-3                             [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─BatchNorm3d: 4-4                       [1, 18, 32, 32, 32]       [1, 18, 32, 32, 32]       36\n","│    │    │    └─ELU: 4-5                               [1, 18, 32, 32, 32]       [1, 18, 32, 32, 32]       --\n","│    │    │    └─ConvBlock: 4-6                         [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─Sequential: 5-3                   [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Conv3d: 6-5                  [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       17,532\n","│    │    │    │    │    └─BatchNorm3d: 6-6             [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       72\n","│    │    │    │    │    └─ELU: 6-7                     [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─ConvBlock: 4-7                         [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─Sequential: 5-4                   [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Conv3d: 6-8                  [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       35,028\n","│    │    └─Sequential: 3-4                             [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─Conv3d: 4-8                            [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       684\n","│    └─ResConvBlock: 2-3                                [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    └─Sequential: 3-5                             [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    └─BatchNorm3d: 4-9                       [1, 36, 16, 16, 16]       [1, 36, 16, 16, 16]       72\n","│    │    │    └─ELU: 4-10                              [1, 36, 16, 16, 16]       [1, 36, 16, 16, 16]       --\n","│    │    │    └─ConvBlock: 4-11                        [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─Sequential: 5-5                   [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Conv3d: 6-9                  [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       46,704\n","│    │    │    │    │    └─BatchNorm3d: 6-10            [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       96\n","│    │    │    │    │    └─ELU: 6-11                    [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    └─ConvBlock: 4-12                        [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─Sequential: 5-6                   [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Conv3d: 6-12                 [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       62,256\n","│    │    └─Sequential: 3-6                             [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    └─Conv3d: 4-13                           [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       1,776\n","├─ResConvBlock: 1-2                                     [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    └─Sequential: 2-4                                  [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    └─BatchNorm3d: 3-7                            [1, 48, 8, 8, 8]          [1, 48, 8, 8, 8]          96\n","│    │    └─ELU: 3-8                                    [1, 48, 8, 8, 8]          [1, 48, 8, 8, 8]          --\n","│    │    └─ConvBlock: 3-9                              [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    └─Sequential: 4-14                       [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    │    └─Conv3d: 5-7                       [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          83,008\n","│    │    │    │    └─BatchNorm3d: 5-8                  [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          128\n","│    │    │    │    └─ELU: 5-9                          [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    └─ConvBlock: 3-10                             [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    └─Sequential: 4-15                       [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    │    └─Conv3d: 5-10                      [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          110,656\n","│    └─Sequential: 2-5                                  [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    └─Conv3d: 3-11                                [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          3,136\n","├─ModuleList: 1-3                                       --                        --                        --\n","│    └─ResUpBlock: 2-6                                  [1, 64, 8, 8, 8]          [1, 48, 16, 16, 16]       --\n","│    │    └─ConvTranspose3d: 3-12                       [1, 64, 8, 8, 8]          [1, 64, 16, 16, 16]       32,832\n","│    │    └─ResConvBlock: 3-13                          [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    └─Sequential: 4-16                       [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─BatchNorm3d: 5-11                 [1, 112, 16, 16, 16]      [1, 112, 16, 16, 16]      224\n","│    │    │    │    └─ELU: 5-12                         [1, 112, 16, 16, 16]      [1, 112, 16, 16, 16]      --\n","│    │    │    │    └─ConvBlock: 5-13                   [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Sequential: 6-13             [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    │    └─Conv3d: 7-1             [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       145,200\n","│    │    │    │    │    │    └─BatchNorm3d: 7-2        [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       96\n","│    │    │    │    │    │    └─ELU: 7-3                [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─ConvBlock: 5-14                   [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Sequential: 6-14             [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    │    └─Conv3d: 7-4             [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       62,256\n","│    │    │    └─Sequential: 4-17                       [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─Conv3d: 5-15                      [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       5,424\n","│    └─ResUpBlock: 2-7                                  [1, 48, 16, 16, 16]       [1, 36, 32, 32, 32]       --\n","│    │    └─ConvTranspose3d: 3-14                       [1, 48, 16, 16, 16]       [1, 48, 32, 32, 32]       18,480\n","│    │    └─ResConvBlock: 3-15                          [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─Sequential: 4-18                       [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─BatchNorm3d: 5-16                 [1, 84, 32, 32, 32]       [1, 84, 32, 32, 32]       168\n","│    │    │    │    └─ELU: 5-17                         [1, 84, 32, 32, 32]       [1, 84, 32, 32, 32]       --\n","│    │    │    │    └─ConvBlock: 5-18                   [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Sequential: 6-15             [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    │    └─Conv3d: 7-5             [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       81,684\n","│    │    │    │    │    │    └─BatchNorm3d: 7-6        [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       72\n","│    │    │    │    │    │    └─ELU: 7-7                [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─ConvBlock: 5-19                   [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Sequential: 6-16             [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    │    └─Conv3d: 7-8             [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       35,028\n","│    │    │    └─Sequential: 4-19                       [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─Conv3d: 5-20                      [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       3,060\n","│    └─ResUpBlock: 2-8                                  [1, 36, 32, 32, 32]       [1, 18, 64, 64, 64]       --\n","│    │    └─ConvTranspose3d: 3-16                       [1, 36, 32, 32, 32]       [1, 36, 64, 64, 64]       10,404\n","│    │    └─ResConvBlock: 3-17                          [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    └─Sequential: 4-20                       [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─BatchNorm3d: 5-21                 [1, 54, 64, 64, 64]       [1, 54, 64, 64, 64]       108\n","│    │    │    │    └─ELU: 5-22                         [1, 54, 64, 64, 64]       [1, 54, 64, 64, 64]       --\n","│    │    │    │    └─ConvBlock: 5-23                   [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Sequential: 6-17             [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    │    └─Conv3d: 7-9             [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       26,262\n","│    │    │    │    │    │    └─BatchNorm3d: 7-10       [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       36\n","│    │    │    │    │    │    └─ELU: 7-11               [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─ConvBlock: 5-24                   [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Sequential: 6-18             [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    │    └─Conv3d: 7-12            [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       8,766\n","│    │    │    └─Sequential: 4-21                       [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─Conv3d: 5-25                      [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       990\n","├─Conv3d: 1-4                                           [1, 18, 64, 64, 64]       [1, 1, 64, 64, 64]        19\n","==================================================================================================================================\n","Total params: 801,731\n","Trainable params: 801,731\n","Non-trainable params: 0\n","Total mult-adds (G): 22.45\n","==================================================================================================================================\n","Input size (MB): 1.05\n","Forward/backward pass size (MB): 628.42\n","Params size (MB): 3.21\n","Estimated Total Size (MB): 632.68\n","==================================================================================================================================\n","[09:31:33.098131] AdamW (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.0001\n","    maximize: False\n","    weight_decay: 0.0\n","\n","Parameter Group 1\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.0001\n","    maximize: False\n","    weight_decay: 0.05\n",")\n","[09:31:33.098314] #####################\n","[09:31:33.098347] #  TRAIN THE MODEL  #\n","[09:31:33.098362] #####################\n","[09:31:33.098388] Start training in epoch 1 - Total: 100\n","[09:31:33.098435] ~~~ Epoch 1/100 ~~~\n","\n","[09:35:21.545623] Epoch: [1]  [0/3]  eta: 0:11:25  lr: 0.000100  jaccard_index: 0.0171 (0.0171)  loss: 0.8929 (0.8929)  weight_decay: 0.0500 (0.0500)  iter-time: 228.4450  max mem: 4442MB\n","[09:35:23.091925] Epoch: [1]  [2/3]  eta: 0:01:16  lr: 0.000100  jaccard_index: 0.0188 (0.0192)  loss: 0.7924 (0.8117)  weight_decay: 0.0500 (0.0500)  iter-time: 76.6632  max mem: 4442MB\n","[09:35:23.152587] Epoch: [1] Total time: 0:03:50 (76.6844 s / it)\n","[09:35:23.152700] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0188 (0.0192)  loss: 0.7924 (0.8117)  weight_decay: 0.0500 (0.0500)\n","[09:35:31.313085] Epoch: [1]  [0/1]  eta: 0:00:08  jaccard_index: 0.0006 (0.0006)  loss: 0.6311 (0.6311)  iter-time: 8.1585  max mem: 4442MB\n","[09:35:31.366286] Epoch: [1] Total time: 0:00:08 (8.2125 s / it)\n","[09:35:31.366483] [Val] averaged stats: jaccard_index: 0.0006 (0.0006)  loss: 0.6311 (0.6311)\n","[09:35:31.366929] Val loss improved from inf to 0.6311298608779907, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:31.407347] [Val] best loss: 0.6311 best  jaccard_index: 0.0006 \n","[09:35:31.408919] [Time] 4.0m 4.0m/6.7h\n","\n","[09:35:31.408959] ~~~ Epoch 2/100 ~~~\n","\n","[09:35:32.313977] Epoch: [2]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0136 (0.0136)  loss: 0.6892 (0.6892)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9019  max mem: 4442MB\n","[09:35:33.867286] Epoch: [2]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0140 (0.0156)  loss: 0.6304 (0.6431)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8178  max mem: 4442MB\n","[09:35:33.964729] Epoch: [2] Total time: 0:00:02 (0.8516 s / it)\n","[09:35:33.964847] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0140 (0.0156)  loss: 0.6304 (0.6431)  weight_decay: 0.0500 (0.0500)\n","[09:35:34.154433] Epoch: [2]  [0/1]  eta: 0:00:00  jaccard_index: 0.0002 (0.0002)  loss: 0.5835 (0.5835)  iter-time: 0.1871  max mem: 4442MB\n","[09:35:34.246699] Epoch: [2] Total time: 0:00:00 (0.2804 s / it)\n","[09:35:34.247008] [Val] averaged stats: jaccard_index: 0.0002 (0.0002)  loss: 0.5835 (0.5835)\n","[09:35:34.247532] Val loss improved from 0.6311298608779907 to 0.583529531955719, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:34.306068] [Val] best loss: 0.5835 best  jaccard_index: 0.0002 \n","[09:35:34.307770] [Time] 2.9s 4.0m/8.8m\n","\n","[09:35:34.307824] ~~~ Epoch 3/100 ~~~\n","\n","[09:35:35.344183] Epoch: [3]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0105 (0.0105)  loss: 0.5645 (0.5645)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0333  max mem: 4442MB\n","[09:35:36.917238] Epoch: [3]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0123 (0.0138)  loss: 0.5155 (0.5261)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8682  max mem: 4442MB\n","[09:35:36.974453] Epoch: [3] Total time: 0:00:02 (0.8885 s / it)\n","[09:35:36.974700] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0123 (0.0138)  loss: 0.5155 (0.5261)  weight_decay: 0.0500 (0.0500)\n","[09:35:37.140688] Epoch: [3]  [0/1]  eta: 0:00:00  jaccard_index: 0.0001 (0.0001)  loss: 0.5447 (0.5447)  iter-time: 0.1641  max mem: 4442MB\n","[09:35:37.194161] Epoch: [3] Total time: 0:00:00 (0.2184 s / it)\n","[09:35:37.194393] [Val] averaged stats: jaccard_index: 0.0001 (0.0001)  loss: 0.5447 (0.5447)\n","[09:35:37.194775] Val loss improved from 0.583529531955719 to 0.544653594493866, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:37.240727] [Val] best loss: 0.5447 best  jaccard_index: 0.0001 \n","[09:35:37.242106] [Time] 2.9s 4.1m/8.9m\n","\n","[09:35:37.242150] ~~~ Epoch 4/100 ~~~\n","\n","[09:35:38.161445] Epoch: [4]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0110 (0.0110)  loss: 0.4596 (0.4596)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9166  max mem: 4442MB\n","[09:35:39.735060] Epoch: [4]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0155 (0.0162)  loss: 0.4209 (0.4272)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8296  max mem: 4442MB\n","[09:35:39.792246] Epoch: [4] Total time: 0:00:02 (0.8498 s / it)\n","[09:35:39.792350] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0155 (0.0162)  loss: 0.4209 (0.4272)  weight_decay: 0.0500 (0.0500)\n","[09:35:39.959776] Epoch: [4]  [0/1]  eta: 0:00:00  jaccard_index: 0.0001 (0.0001)  loss: 0.4963 (0.4963)  iter-time: 0.1656  max mem: 4442MB\n","[09:35:40.021305] Epoch: [4] Total time: 0:00:00 (0.2279 s / it)\n","[09:35:40.021358] [Val] averaged stats: jaccard_index: 0.0001 (0.0001)  loss: 0.4963 (0.4963)\n","[09:35:40.021791] Val loss improved from 0.544653594493866 to 0.4962783455848694, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:40.060898] [Val] best loss: 0.4963 best  jaccard_index: 0.0001 \n","[09:35:40.062228] [Time] 2.8s 4.1m/8.7m\n","\n","[09:35:40.062269] ~~~ Epoch 5/100 ~~~\n","\n","[09:35:40.987449] Epoch: [5]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0160 (0.0160)  loss: 0.3700 (0.3700)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9226  max mem: 4442MB\n","[09:35:42.567529] Epoch: [5]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0204 (0.0210)  loss: 0.3515 (0.3481)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8337  max mem: 4442MB\n","[09:35:42.635238] Epoch: [5] Total time: 0:00:02 (0.8574 s / it)\n","[09:35:42.635455] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0204 (0.0210)  loss: 0.3515 (0.3481)  weight_decay: 0.0500 (0.0500)\n","[09:35:42.802040] Epoch: [5]  [0/1]  eta: 0:00:00  jaccard_index: 0.0004 (0.0004)  loss: 0.4318 (0.4318)  iter-time: 0.1644  max mem: 4442MB\n","[09:35:42.873936] Epoch: [5] Total time: 0:00:00 (0.2374 s / it)\n","[09:35:42.874101] [Val] averaged stats: jaccard_index: 0.0004 (0.0004)  loss: 0.4318 (0.4318)\n","[09:35:42.874604] Val loss improved from 0.4962783455848694 to 0.4317844808101654, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:42.915387] [Val] best loss: 0.4318 best  jaccard_index: 0.0004 \n","[09:35:42.916739] Creating training plots . . .\n","[09:35:43.438062] [Time] 3.4s 4.2m/9.6m\n","\n","[09:35:43.438112] ~~~ Epoch 6/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:35:44.380766] Epoch: [6]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0206 (0.0206)  loss: 0.2983 (0.2983)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9399  max mem: 4442MB\n","[09:35:45.957395] Epoch: [6]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0206 (0.0220)  loss: 0.2941 (0.2848)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8382  max mem: 4442MB\n","[09:35:46.033748] Epoch: [6] Total time: 0:00:02 (0.8650 s / it)\n","[09:35:46.034066] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0206 (0.0220)  loss: 0.2941 (0.2848)  weight_decay: 0.0500 (0.0500)\n","[09:35:46.232029] Epoch: [6]  [0/1]  eta: 0:00:00  jaccard_index: 0.0007 (0.0007)  loss: 0.3620 (0.3620)  iter-time: 0.1953  max mem: 4442MB\n","[09:35:46.328751] Epoch: [6] Total time: 0:00:00 (0.2932 s / it)\n","[09:35:46.329000] [Val] averaged stats: jaccard_index: 0.0007 (0.0007)  loss: 0.3620 (0.3620)\n","[09:35:46.329557] Val loss improved from 0.4317844808101654 to 0.3620304465293884, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:46.618424] [Val] best loss: 0.3620 best  jaccard_index: 0.0007 \n","[09:35:46.620234] [Time] 3.2s 4.2m/9.3m\n","\n","[09:35:46.620287] ~~~ Epoch 7/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:35:47.646529] Epoch: [7]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0183 (0.0183)  loss: 0.2413 (0.2413)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0229  max mem: 4442MB\n","[09:35:49.231485] Epoch: [7]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0183 (0.0182)  loss: 0.2412 (0.2323)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8688  max mem: 4442MB\n","[09:35:49.287758] Epoch: [7] Total time: 0:00:02 (0.8888 s / it)\n","[09:35:49.287883] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0183 (0.0182)  loss: 0.2412 (0.2323)  weight_decay: 0.0500 (0.0500)\n","[09:35:49.456613] Epoch: [7]  [0/1]  eta: 0:00:00  jaccard_index: 0.0006 (0.0006)  loss: 0.2942 (0.2942)  iter-time: 0.1667  max mem: 4442MB\n","[09:35:49.511105] Epoch: [7] Total time: 0:00:00 (0.2221 s / it)\n","[09:35:49.511174] [Val] averaged stats: jaccard_index: 0.0006 (0.0006)  loss: 0.2942 (0.2942)\n","[09:35:49.511653] Val loss improved from 0.3620304465293884 to 0.2941923141479492, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:49.553848] [Val] best loss: 0.2942 best  jaccard_index: 0.0006 \n","[09:35:49.555140] [Time] 2.9s 4.3m/8.9m\n","\n","[09:35:49.555179] ~~~ Epoch 8/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:35:50.488556] Epoch: [8]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0102 (0.0102)  loss: 0.1987 (0.1987)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9306  max mem: 4442MB\n","[09:35:52.072453] Epoch: [8]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0102 (0.0109)  loss: 0.1987 (0.1920)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8376  max mem: 4442MB\n","[09:35:52.130307] Epoch: [8] Total time: 0:00:02 (0.8581 s / it)\n","[09:35:52.130545] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0102 (0.0109)  loss: 0.1987 (0.1920)  weight_decay: 0.0500 (0.0500)\n","[09:35:52.300897] Epoch: [8]  [0/1]  eta: 0:00:00  jaccard_index: 0.0004 (0.0004)  loss: 0.2248 (0.2248)  iter-time: 0.1683  max mem: 4442MB\n","[09:35:52.358204] Epoch: [8] Total time: 0:00:00 (0.2266 s / it)\n","[09:35:52.358429] [Val] averaged stats: jaccard_index: 0.0004 (0.0004)  loss: 0.2248 (0.2248)\n","[09:35:52.359190] Val loss improved from 0.2941923141479492 to 0.2247868776321411, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:52.398160] [Val] best loss: 0.2248 best  jaccard_index: 0.0004 \n","[09:35:52.399759] [Time] 2.8s 4.3m/8.7m\n","\n","[09:35:52.399798] ~~~ Epoch 9/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:35:53.330638] Epoch: [9]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0048 (0.0048)  loss: 0.1643 (0.1643)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9281  max mem: 4442MB\n","[09:35:54.913520] Epoch: [9]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0048 (0.0056)  loss: 0.1643 (0.1602)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8365  max mem: 4442MB\n","[09:35:54.970164] Epoch: [9] Total time: 0:00:02 (0.8566 s / it)\n","[09:35:54.970270] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0048 (0.0056)  loss: 0.1643 (0.1602)  weight_decay: 0.0500 (0.0500)\n","[09:35:55.136380] Epoch: [9]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.1586 (0.1586)  iter-time: 0.1642  max mem: 4442MB\n","[09:35:55.192840] Epoch: [9] Total time: 0:00:00 (0.2215 s / it)\n","[09:35:55.192896] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.1586 (0.1586)\n","[09:35:55.193327] Val loss improved from 0.2247868776321411 to 0.15862829983234406, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:55.235754] [Val] best loss: 0.1586 best  jaccard_index: 0.0000 \n","[09:35:55.237183] [Time] 2.8s 4.4m/8.7m\n","\n","[09:35:55.237223] ~~~ Epoch 10/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:35:56.164196] Epoch: [10]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0026 (0.0026)  loss: 0.1354 (0.1354)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9245  max mem: 4442MB\n","[09:35:57.748579] Epoch: [10]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0026 (0.0028)  loss: 0.1354 (0.1350)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8357  max mem: 4442MB\n","[09:35:57.804966] Epoch: [10] Total time: 0:00:02 (0.8557 s / it)\n","[09:35:57.805071] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0026 (0.0028)  loss: 0.1354 (0.1350)  weight_decay: 0.0500 (0.0500)\n","[09:35:57.972773] Epoch: [10]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.1078 (0.1078)  iter-time: 0.1654  max mem: 4442MB\n","[09:35:58.027539] Epoch: [10] Total time: 0:00:00 (0.2214 s / it)\n","[09:35:58.027600] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.1078 (0.1078)\n","[09:35:58.028183] Val loss improved from 0.15862829983234406 to 0.10776582360267639, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:35:58.067835] [Val] best loss: 0.1078 best  jaccard_index: 0.0000 \n","[09:35:58.069209] Creating training plots . . .\n","[09:35:58.352903] [Time] 3.1s 4.4m/9.1m\n","\n","[09:35:58.352956] ~~~ Epoch 11/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:35:59.285111] Epoch: [11]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0007 (0.0007)  loss: 0.1129 (0.1129)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9298  max mem: 4442MB\n","[09:36:00.867677] Epoch: [11]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0013 (0.0012)  loss: 0.1129 (0.1163)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8368  max mem: 4442MB\n","[09:36:00.958918] Epoch: [11] Total time: 0:00:02 (0.8684 s / it)\n","[09:36:00.959216] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0013 (0.0012)  loss: 0.1129 (0.1163)  weight_decay: 0.0500 (0.0500)\n","[09:36:01.154618] Epoch: [11]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0759 (0.0759)  iter-time: 0.1928  max mem: 4442MB\n","[09:36:01.243155] Epoch: [11] Total time: 0:00:00 (0.2824 s / it)\n","[09:36:01.243408] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0759 (0.0759)\n","[09:36:01.243960] Val loss improved from 0.10776582360267639 to 0.07585117220878601, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:01.303878] [Val] best loss: 0.0759 best  jaccard_index: 0.0000 \n","[09:36:01.305458] [Time] 3.0s 4.5m/8.9m\n","\n","[09:36:01.305528] ~~~ Epoch 12/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:02.303582] Epoch: [12]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0003 (0.0003)  loss: 0.0970 (0.0970)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9945  max mem: 4442MB\n","[09:36:03.884571] Epoch: [12]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0006 (0.0005)  loss: 0.0970 (0.1020)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8579  max mem: 4442MB\n","[09:36:03.941606] Epoch: [12] Total time: 0:00:02 (0.8783 s / it)\n","[09:36:03.941927] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0006 (0.0005)  loss: 0.0970 (0.1020)  weight_decay: 0.0500 (0.0500)\n","[09:36:04.110698] Epoch: [12]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0574 (0.0574)  iter-time: 0.1668  max mem: 4442MB\n","[09:36:04.163896] Epoch: [12] Total time: 0:00:00 (0.2209 s / it)\n","[09:36:04.164075] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0574 (0.0574)\n","[09:36:04.164488] Val loss improved from 0.07585117220878601 to 0.05739182233810425, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:04.212046] [Val] best loss: 0.0574 best  jaccard_index: 0.0000 \n","[09:36:04.213944] [Time] 2.9s 4.5m/8.8m\n","\n","[09:36:04.213995] ~~~ Epoch 13/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:05.156543] Epoch: [13]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0001 (0.0001)  loss: 0.0852 (0.0852)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9393  max mem: 4442MB\n","[09:36:06.739710] Epoch: [13]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0002 (0.0002)  loss: 0.0852 (0.0914)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8403  max mem: 4442MB\n","[09:36:06.795769] Epoch: [13] Total time: 0:00:02 (0.8602 s / it)\n","[09:36:06.795873] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0002 (0.0002)  loss: 0.0852 (0.0914)  weight_decay: 0.0500 (0.0500)\n","[09:36:06.963621] Epoch: [13]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0460 (0.0460)  iter-time: 0.1659  max mem: 4442MB\n","[09:36:07.023048] Epoch: [13] Total time: 0:00:00 (0.2262 s / it)\n","[09:36:07.023211] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0460 (0.0460)\n","[09:36:07.023787] Val loss improved from 0.05739182233810425 to 0.04604498669505119, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:07.064733] [Val] best loss: 0.0460 best  jaccard_index: 0.0000 \n","[09:36:07.065701] [Time] 2.9s 4.6m/8.7m\n","\n","[09:36:07.065742] ~~~ Epoch 14/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:08.030252] Epoch: [14]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0766 (0.0766)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9615  max mem: 4442MB\n","[09:36:09.615404] Epoch: [14]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0781 (0.0836)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8483  max mem: 4442MB\n","[09:36:09.674763] Epoch: [14] Total time: 0:00:02 (0.8693 s / it)\n","[09:36:09.674883] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0781 (0.0836)  weight_decay: 0.0500 (0.0500)\n","[09:36:09.847271] Epoch: [14]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0380 (0.0380)  iter-time: 0.1702  max mem: 4442MB\n","[09:36:09.901539] Epoch: [14] Total time: 0:00:00 (0.2255 s / it)\n","[09:36:09.901812] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0380 (0.0380)\n","[09:36:09.902243] Val loss improved from 0.04604498669505119 to 0.03800160437822342, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:09.942626] [Val] best loss: 0.0380 best  jaccard_index: 0.0000 \n","[09:36:09.944086] [Time] 2.9s 4.6m/8.8m\n","\n","[09:36:09.944124] ~~~ Epoch 15/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:10.889462] Epoch: [15]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0696 (0.0696)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9425  max mem: 4442MB\n","[09:36:12.471160] Epoch: [15]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0725 (0.0777)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8409  max mem: 4442MB\n","[09:36:12.527595] Epoch: [15] Total time: 0:00:02 (0.8609 s / it)\n","[09:36:12.527878] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0725 (0.0777)  weight_decay: 0.0500 (0.0500)\n","[09:36:12.713167] Epoch: [15]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0318 (0.0318)  iter-time: 0.1830  max mem: 4442MB\n","[09:36:12.799427] Epoch: [15] Total time: 0:00:00 (0.2704 s / it)\n","[09:36:12.799728] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0318 (0.0318)\n","[09:36:12.800285] Val loss improved from 0.03800160437822342 to 0.031823545694351196, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:12.862507] [Val] best loss: 0.0318 best  jaccard_index: 0.0000 \n","[09:36:12.863994] Creating training plots . . .\n","[09:36:13.358326] [Time] 3.4s 4.7m/9.6m\n","\n","[09:36:13.358411] ~~~ Epoch 16/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:14.387928] Epoch: [16]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0001 (0.0001)  loss: 0.0644 (0.0644)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0262  max mem: 4442MB\n","[09:36:15.968358] Epoch: [16]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0001 (0.0000)  loss: 0.0682 (0.0732)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8683  max mem: 4442MB\n","[09:36:16.023415] Epoch: [16] Total time: 0:00:02 (0.8879 s / it)\n","[09:36:16.023648] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0001 (0.0000)  loss: 0.0682 (0.0732)  weight_decay: 0.0500 (0.0500)\n","[09:36:16.189888] Epoch: [16]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0274 (0.0274)  iter-time: 0.1644  max mem: 4442MB\n","[09:36:16.247925] Epoch: [16] Total time: 0:00:00 (0.2232 s / it)\n","[09:36:16.247989] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0274 (0.0274)\n","[09:36:16.248540] Val loss improved from 0.031823545694351196 to 0.027403976768255234, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:16.287931] [Val] best loss: 0.0274 best  jaccard_index: 0.0000 \n","[09:36:16.289433] [Time] 2.9s 4.7m/8.9m\n","\n","[09:36:16.289481] ~~~ Epoch 17/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:17.220314] Epoch: [17]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0601 (0.0601)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9282  max mem: 4442MB\n","[09:36:18.804629] Epoch: [17]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0649 (0.0697)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8370  max mem: 4442MB\n","[09:36:18.862064] Epoch: [17] Total time: 0:00:02 (0.8573 s / it)\n","[09:36:18.862343] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0649 (0.0697)  weight_decay: 0.0500 (0.0500)\n","[09:36:19.033448] Epoch: [17]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0245 (0.0245)  iter-time: 0.1690  max mem: 4442MB\n","[09:36:19.090977] Epoch: [17] Total time: 0:00:00 (0.2275 s / it)\n","[09:36:19.091270] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0245 (0.0245)\n","[09:36:19.091778] Val loss improved from 0.027403976768255234 to 0.024530714377760887, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:19.130041] [Val] best loss: 0.0245 best  jaccard_index: 0.0000 \n","[09:36:19.131567] [Time] 2.8s 4.8m/8.7m\n","\n","[09:36:19.131606] ~~~ Epoch 18/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:20.060780] Epoch: [18]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0569 (0.0569)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9266  max mem: 4442MB\n","[09:36:21.643136] Epoch: [18]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0624 (0.0670)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8358  max mem: 4442MB\n","[09:36:21.699056] Epoch: [18] Total time: 0:00:02 (0.8556 s / it)\n","[09:36:21.699281] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0624 (0.0670)  weight_decay: 0.0500 (0.0500)\n","[09:36:21.867387] Epoch: [18]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0227 (0.0227)  iter-time: 0.1657  max mem: 4442MB\n","[09:36:21.925252] Epoch: [18] Total time: 0:00:00 (0.2248 s / it)\n","[09:36:21.925313] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0227 (0.0227)\n","[09:36:21.925821] Val loss improved from 0.024530714377760887 to 0.02266746759414673, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:21.965126] [Val] best loss: 0.0227 best  jaccard_index: 0.0000 \n","[09:36:21.966733] [Time] 2.8s 4.8m/8.7m\n","\n","[09:36:21.966783] ~~~ Epoch 19/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:22.909503] Epoch: [19]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0544 (0.0544)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9398  max mem: 4442MB\n","[09:36:24.497691] Epoch: [19]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0605 (0.0649)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8422  max mem: 4442MB\n","[09:36:24.555441] Epoch: [19] Total time: 0:00:02 (0.8626 s / it)\n","[09:36:24.555575] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0605 (0.0649)  weight_decay: 0.0500 (0.0500)\n","[09:36:24.723334] Epoch: [19]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0213 (0.0213)  iter-time: 0.1658  max mem: 4442MB\n","[09:36:24.776860] Epoch: [19] Total time: 0:00:00 (0.2202 s / it)\n","[09:36:24.776914] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0213 (0.0213)\n","[09:36:24.777370] Val loss improved from 0.02266746759414673 to 0.021282531321048737, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:24.818752] [Val] best loss: 0.0213 best  jaccard_index: 0.0000 \n","[09:36:24.820186] [Time] 2.9s 4.9m/8.8m\n","\n","[09:36:24.820224] ~~~ Epoch 20/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:25.749925] Epoch: [20]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0522 (0.0522)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9270  max mem: 4442MB\n","[09:36:27.336323] Epoch: [20]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0589 (0.0631)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8373  max mem: 4442MB\n","[09:36:27.448141] Epoch: [20] Total time: 0:00:02 (0.8757 s / it)\n","[09:36:27.448495] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0000 (0.0000)  loss: 0.0589 (0.0631)  weight_decay: 0.0500 (0.0500)\n","[09:36:27.647651] Epoch: [20]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0200 (0.0200)  iter-time: 0.1964  max mem: 4442MB\n","[09:36:27.743893] Epoch: [20] Total time: 0:00:00 (0.2939 s / it)\n","[09:36:27.744129] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0200 (0.0200)\n","[09:36:27.744798] Val loss improved from 0.021282531321048737 to 0.020021885633468628, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:27.825317] [Val] best loss: 0.0200 best  jaccard_index: 0.0000 \n","[09:36:27.826976] Creating training plots . . .\n","[09:36:28.344709] [Time] 3.5s 4.9m/9.7m\n","\n","[09:36:28.344768] ~~~ Epoch 21/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:29.298792] Epoch: [21]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0001 (0.0001)  loss: 0.0508 (0.0508)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9509  max mem: 4442MB\n","[09:36:30.879611] Epoch: [21]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0001 (0.0001)  loss: 0.0575 (0.0617)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8433  max mem: 4442MB\n","[09:36:30.936129] Epoch: [21] Total time: 0:00:02 (0.8634 s / it)\n","[09:36:30.936523] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0001 (0.0001)  loss: 0.0575 (0.0617)  weight_decay: 0.0500 (0.0500)\n","[09:36:31.104195] Epoch: [21]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0188 (0.0188)  iter-time: 0.1655  max mem: 4442MB\n","[09:36:31.163434] Epoch: [21] Total time: 0:00:00 (0.2258 s / it)\n","[09:36:31.163673] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0188 (0.0188)\n","[09:36:31.164142] Val loss improved from 0.020021885633468628 to 0.01879413053393364, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:31.204936] [Val] best loss: 0.0188 best  jaccard_index: 0.0000 \n","[09:36:31.206131] [Time] 2.9s 5.0m/8.8m\n","\n","[09:36:31.206168] ~~~ Epoch 22/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:32.145840] Epoch: [22]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0001 (0.0001)  loss: 0.0492 (0.0492)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9367  max mem: 4442MB\n","[09:36:33.729604] Epoch: [22]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0001 (0.0002)  loss: 0.0563 (0.0603)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8396  max mem: 4442MB\n","[09:36:33.784842] Epoch: [22] Total time: 0:00:02 (0.8592 s / it)\n","[09:36:33.784956] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0001 (0.0002)  loss: 0.0563 (0.0603)  weight_decay: 0.0500 (0.0500)\n","[09:36:33.957610] Epoch: [22]  [0/1]  eta: 0:00:00  jaccard_index: 0.0000 (0.0000)  loss: 0.0177 (0.0177)  iter-time: 0.1707  max mem: 4442MB\n","[09:36:34.016021] Epoch: [22] Total time: 0:00:00 (0.2300 s / it)\n","[09:36:34.016076] [Val] averaged stats: jaccard_index: 0.0000 (0.0000)  loss: 0.0177 (0.0177)\n","[09:36:34.016531] Val loss improved from 0.01879413053393364 to 0.0177390705794096, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:34.054894] [Val] best loss: 0.0177 best  jaccard_index: 0.0000 \n","[09:36:34.056328] [Time] 2.9s 5.0m/8.8m\n","\n","[09:36:34.056371] ~~~ Epoch 23/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:34.984483] Epoch: [23]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0003 (0.0003)  loss: 0.0481 (0.0481)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9255  max mem: 4442MB\n","[09:36:36.567126] Epoch: [23]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0003 (0.0003)  loss: 0.0554 (0.0593)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8355  max mem: 4442MB\n","[09:36:36.623147] Epoch: [23] Total time: 0:00:02 (0.8554 s / it)\n","[09:36:36.623440] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0003 (0.0003)  loss: 0.0554 (0.0593)  weight_decay: 0.0500 (0.0500)\n","[09:36:36.789838] Epoch: [23]  [0/1]  eta: 0:00:00  jaccard_index: 0.0005 (0.0005)  loss: 0.0169 (0.0169)  iter-time: 0.1645  max mem: 4442MB\n","[09:36:36.847965] Epoch: [23] Total time: 0:00:00 (0.2235 s / it)\n","[09:36:36.848020] [Val] averaged stats: jaccard_index: 0.0005 (0.0005)  loss: 0.0169 (0.0169)\n","[09:36:36.848416] Val loss improved from 0.0177390705794096 to 0.01693812385201454, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:36.888041] [Val] best loss: 0.0169 best  jaccard_index: 0.0005 \n","[09:36:36.889496] [Time] 2.8s 5.1m/8.7m\n","\n","[09:36:36.889534] ~~~ Epoch 24/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:37.824628] Epoch: [24]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0006 (0.0006)  loss: 0.0471 (0.0471)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9323  max mem: 4442MB\n","[09:36:39.405455] Epoch: [24]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0005 (0.0005)  loss: 0.0546 (0.0584)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8370  max mem: 4442MB\n","[09:36:39.491159] Epoch: [24] Total time: 0:00:02 (0.8670 s / it)\n","[09:36:39.491514] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0005 (0.0005)  loss: 0.0546 (0.0584)  weight_decay: 0.0500 (0.0500)\n","[09:36:39.684349] Epoch: [24]  [0/1]  eta: 0:00:00  jaccard_index: 0.0005 (0.0005)  loss: 0.0163 (0.0163)  iter-time: 0.1901  max mem: 4442MB\n","[09:36:39.773430] Epoch: [24] Total time: 0:00:00 (0.2804 s / it)\n","[09:36:39.773711] [Val] averaged stats: jaccard_index: 0.0005 (0.0005)  loss: 0.0163 (0.0163)\n","[09:36:39.774211] Val loss improved from 0.01693812385201454 to 0.016341432929039, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:39.833446] [Val] best loss: 0.0163 best  jaccard_index: 0.0005 \n","[09:36:39.834896] [Time] 2.9s 5.1m/8.9m\n","\n","[09:36:39.834945] ~~~ Epoch 25/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:40.829067] Epoch: [25]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0011 (0.0011)  loss: 0.0463 (0.0463)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9910  max mem: 4442MB\n","[09:36:42.418245] Epoch: [25]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0011 (0.0009)  loss: 0.0538 (0.0576)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8594  max mem: 4442MB\n","[09:36:42.495022] Epoch: [25] Total time: 0:00:02 (0.8863 s / it)\n","[09:36:42.495154] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0011 (0.0009)  loss: 0.0538 (0.0576)  weight_decay: 0.0500 (0.0500)\n","[09:36:42.671901] Epoch: [25]  [0/1]  eta: 0:00:00  jaccard_index: 0.0005 (0.0005)  loss: 0.0158 (0.0158)  iter-time: 0.1743  max mem: 4442MB\n","[09:36:42.725603] Epoch: [25] Total time: 0:00:00 (0.2289 s / it)\n","[09:36:42.725889] [Val] averaged stats: jaccard_index: 0.0005 (0.0005)  loss: 0.0158 (0.0158)\n","[09:36:42.726322] Val loss improved from 0.016341432929039 to 0.015839148312807083, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:42.765625] [Val] best loss: 0.0158 best  jaccard_index: 0.0005 \n","[09:36:42.767050] Creating training plots . . .\n","[09:36:43.060172] [Time] 3.2s 5.2m/9.3m\n","\n","[09:36:43.060222] ~~~ Epoch 26/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:43.990751] Epoch: [26]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0016 (0.0016)  loss: 0.0456 (0.0456)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9278  max mem: 4442MB\n","[09:36:45.577184] Epoch: [26]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0016 (0.0013)  loss: 0.0533 (0.0568)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8375  max mem: 4442MB\n","[09:36:45.634053] Epoch: [26] Total time: 0:00:02 (0.8577 s / it)\n","[09:36:45.634409] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0016 (0.0013)  loss: 0.0533 (0.0568)  weight_decay: 0.0500 (0.0500)\n","[09:36:45.802316] Epoch: [26]  [0/1]  eta: 0:00:00  jaccard_index: 0.0009 (0.0009)  loss: 0.0154 (0.0154)  iter-time: 0.1660  max mem: 4442MB\n","[09:36:45.854023] Epoch: [26] Total time: 0:00:00 (0.2185 s / it)\n","[09:36:45.854214] [Val] averaged stats: jaccard_index: 0.0009 (0.0009)  loss: 0.0154 (0.0154)\n","[09:36:45.854896] Val loss improved from 0.015839148312807083 to 0.015376048162579536, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:45.897995] [Val] best loss: 0.0154 best  jaccard_index: 0.0009 \n","[09:36:45.899539] [Time] 2.8s 5.2m/8.8m\n","\n","[09:36:45.899577] ~~~ Epoch 27/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:46.830147] Epoch: [27]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0022 (0.0022)  loss: 0.0449 (0.0449)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9277  max mem: 4442MB\n","[09:36:48.417300] Epoch: [27]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0020 (0.0017)  loss: 0.0527 (0.0562)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8377  max mem: 4442MB\n","[09:36:48.474568] Epoch: [27] Total time: 0:00:02 (0.8581 s / it)\n","[09:36:48.474763] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0020 (0.0017)  loss: 0.0527 (0.0562)  weight_decay: 0.0500 (0.0500)\n","[09:36:48.647250] Epoch: [27]  [0/1]  eta: 0:00:00  jaccard_index: 0.0009 (0.0009)  loss: 0.0150 (0.0150)  iter-time: 0.1702  max mem: 4442MB\n","[09:36:48.715155] Epoch: [27] Total time: 0:00:00 (0.2392 s / it)\n","[09:36:48.715230] [Val] averaged stats: jaccard_index: 0.0009 (0.0009)  loss: 0.0150 (0.0150)\n","[09:36:48.716052] Val loss improved from 0.015376048162579536 to 0.014958500862121582, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:48.759909] [Val] best loss: 0.0150 best  jaccard_index: 0.0009 \n","[09:36:48.761584] [Time] 2.9s 5.3m/8.8m\n","\n","[09:36:48.761632] ~~~ Epoch 28/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:49.712153] Epoch: [28]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0034 (0.0034)  loss: 0.0444 (0.0444)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9475  max mem: 4442MB\n","[09:36:51.299721] Epoch: [28]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0020 (0.0021)  loss: 0.0522 (0.0557)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8444  max mem: 4442MB\n","[09:36:51.355097] Epoch: [28] Total time: 0:00:02 (0.8642 s / it)\n","[09:36:51.355267] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0020 (0.0021)  loss: 0.0522 (0.0557)  weight_decay: 0.0500 (0.0500)\n","[09:36:51.523356] Epoch: [28]  [0/1]  eta: 0:00:00  jaccard_index: 0.0009 (0.0009)  loss: 0.0146 (0.0146)  iter-time: 0.1661  max mem: 4442MB\n","[09:36:51.578622] Epoch: [28] Total time: 0:00:00 (0.2223 s / it)\n","[09:36:51.578682] [Val] averaged stats: jaccard_index: 0.0009 (0.0009)  loss: 0.0146 (0.0146)\n","[09:36:51.579132] Val loss improved from 0.014958500862121582 to 0.014609592966735363, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:51.622270] [Val] best loss: 0.0146 best  jaccard_index: 0.0009 \n","[09:36:51.623773] [Time] 2.9s 5.3m/8.8m\n","\n","[09:36:51.623813] ~~~ Epoch 29/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:52.551663] Epoch: [29]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0046 (0.0046)  loss: 0.0439 (0.0439)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9250  max mem: 4442MB\n","[09:36:54.138435] Epoch: [29]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0024 (0.0027)  loss: 0.0517 (0.0551)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8366  max mem: 4442MB\n","[09:36:54.240956] Epoch: [29] Total time: 0:00:02 (0.8721 s / it)\n","[09:36:54.241255] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0024 (0.0027)  loss: 0.0517 (0.0551)  weight_decay: 0.0500 (0.0500)\n","[09:36:54.441715] Epoch: [29]  [0/1]  eta: 0:00:00  jaccard_index: 0.0009 (0.0009)  loss: 0.0144 (0.0144)  iter-time: 0.1979  max mem: 4442MB\n","[09:36:54.535107] Epoch: [29] Total time: 0:00:00 (0.2923 s / it)\n","[09:36:54.535400] [Val] averaged stats: jaccard_index: 0.0009 (0.0009)  loss: 0.0144 (0.0144)\n","[09:36:54.535960] Val loss improved from 0.014609592966735363 to 0.014378726482391357, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:54.597842] [Val] best loss: 0.0144 best  jaccard_index: 0.0009 \n","[09:36:54.599256] [Time] 3.0s 5.4m/8.9m\n","\n","[09:36:54.599301] ~~~ Epoch 30/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:55.627039] Epoch: [30]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0046 (0.0046)  loss: 0.0435 (0.0435)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0242  max mem: 4442MB\n","[09:36:57.212420] Epoch: [30]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0026 (0.0027)  loss: 0.0514 (0.0548)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8693  max mem: 4442MB\n","[09:36:57.272930] Epoch: [30] Total time: 0:00:02 (0.8909 s / it)\n","[09:36:57.273046] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0026 (0.0027)  loss: 0.0514 (0.0548)  weight_decay: 0.0500 (0.0500)\n","[09:36:57.441632] Epoch: [30]  [0/1]  eta: 0:00:00  jaccard_index: 0.0019 (0.0019)  loss: 0.0143 (0.0143)  iter-time: 0.1666  max mem: 4442MB\n","[09:36:57.505117] Epoch: [30] Total time: 0:00:00 (0.2310 s / it)\n","[09:36:57.505316] [Val] averaged stats: jaccard_index: 0.0019 (0.0019)  loss: 0.0143 (0.0143)\n","[09:36:57.505890] Val loss improved from 0.014378726482391357 to 0.014264730736613274, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:36:57.548274] [Val] best loss: 0.0143 best  jaccard_index: 0.0019 \n","[09:36:57.549629] Creating training plots . . .\n","[09:36:57.836258] [Time] 3.2s 5.4m/9.2m\n","\n","[09:36:57.836315] ~~~ Epoch 31/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:36:58.794311] Epoch: [31]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0053 (0.0053)  loss: 0.0431 (0.0431)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9551  max mem: 4442MB\n","[09:37:00.378213] Epoch: [31]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0024 (0.0030)  loss: 0.0509 (0.0543)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8458  max mem: 4442MB\n","[09:37:00.435406] Epoch: [31] Total time: 0:00:02 (0.8661 s / it)\n","[09:37:00.435611] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0024 (0.0030)  loss: 0.0509 (0.0543)  weight_decay: 0.0500 (0.0500)\n","[09:37:00.605361] Epoch: [31]  [0/1]  eta: 0:00:00  jaccard_index: 0.0032 (0.0032)  loss: 0.0141 (0.0141)  iter-time: 0.1674  max mem: 4442MB\n","[09:37:00.664805] Epoch: [31] Total time: 0:00:00 (0.2281 s / it)\n","[09:37:00.664863] [Val] averaged stats: jaccard_index: 0.0032 (0.0032)  loss: 0.0141 (0.0141)\n","[09:37:00.665329] Val loss improved from 0.014264730736613274 to 0.01411560457199812, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:00.705543] [Val] best loss: 0.0141 best  jaccard_index: 0.0032 \n","[09:37:00.707241] [Time] 2.9s 5.5m/8.8m\n","\n","[09:37:00.707290] ~~~ Epoch 32/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:01.649390] Epoch: [32]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0061 (0.0061)  loss: 0.0426 (0.0426)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9392  max mem: 4442MB\n","[09:37:03.233787] Epoch: [32]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0030 (0.0035)  loss: 0.0505 (0.0538)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8407  max mem: 4442MB\n","[09:37:03.293037] Epoch: [32] Total time: 0:00:02 (0.8617 s / it)\n","[09:37:03.293144] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0030 (0.0035)  loss: 0.0505 (0.0538)  weight_decay: 0.0500 (0.0500)\n","[09:37:03.461119] Epoch: [32]  [0/1]  eta: 0:00:00  jaccard_index: 0.0032 (0.0032)  loss: 0.0139 (0.0139)  iter-time: 0.1658  max mem: 4442MB\n","[09:37:03.514764] Epoch: [32] Total time: 0:00:00 (0.2205 s / it)\n","[09:37:03.514818] [Val] averaged stats: jaccard_index: 0.0032 (0.0032)  loss: 0.0139 (0.0139)\n","[09:37:03.515202] Val loss improved from 0.01411560457199812 to 0.013881548307836056, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:03.558652] [Val] best loss: 0.0139 best  jaccard_index: 0.0032 \n","[09:37:03.560023] [Time] 2.9s 5.5m/8.8m\n","\n","[09:37:03.560059] ~~~ Epoch 33/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:04.495415] Epoch: [33]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0071 (0.0071)  loss: 0.0422 (0.0422)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9329  max mem: 4442MB\n","[09:37:06.076105] Epoch: [33]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0038 (0.0041)  loss: 0.0500 (0.0534)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8373  max mem: 4442MB\n","[09:37:06.168181] Epoch: [33] Total time: 0:00:02 (0.8691 s / it)\n","[09:37:06.168521] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0038 (0.0041)  loss: 0.0500 (0.0534)  weight_decay: 0.0500 (0.0500)\n","[09:37:06.367395] Epoch: [33]  [0/1]  eta: 0:00:00  jaccard_index: 0.0046 (0.0046)  loss: 0.0137 (0.0137)  iter-time: 0.1963  max mem: 4442MB\n","[09:37:06.458834] Epoch: [33] Total time: 0:00:00 (0.2888 s / it)\n","[09:37:06.459104] [Val] averaged stats: jaccard_index: 0.0046 (0.0046)  loss: 0.0137 (0.0137)\n","[09:37:06.459659] Val loss improved from 0.013881548307836056 to 0.013663905672729015, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:06.521072] [Val] best loss: 0.0137 best  jaccard_index: 0.0046 \n","[09:37:06.522808] [Time] 3.0s 5.6m/8.9m\n","\n","[09:37:06.522860] ~~~ Epoch 34/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:07.571603] Epoch: [34]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0085 (0.0085)  loss: 0.0418 (0.0418)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0450  max mem: 4442MB\n","[09:37:09.152521] Epoch: [34]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0043 (0.0048)  loss: 0.0497 (0.0531)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8749  max mem: 4442MB\n","[09:37:09.226199] Epoch: [34] Total time: 0:00:02 (0.9007 s / it)\n","[09:37:09.226429] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0043 (0.0048)  loss: 0.0497 (0.0531)  weight_decay: 0.0500 (0.0500)\n","[09:37:09.396391] Epoch: [34]  [0/1]  eta: 0:00:00  jaccard_index: 0.0046 (0.0046)  loss: 0.0135 (0.0135)  iter-time: 0.1679  max mem: 4442MB\n","[09:37:09.456370] Epoch: [34] Total time: 0:00:00 (0.2288 s / it)\n","[09:37:09.456661] [Val] averaged stats: jaccard_index: 0.0046 (0.0046)  loss: 0.0135 (0.0135)\n","[09:37:09.457342] Val loss improved from 0.013663905672729015 to 0.013512298464775085, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:09.502351] [Val] best loss: 0.0135 best  jaccard_index: 0.0046 \n","[09:37:09.504098] [Time] 3.0s 5.6m/8.9m\n","\n","[09:37:09.504144] ~~~ Epoch 35/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:10.448793] Epoch: [35]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0093 (0.0093)  loss: 0.0416 (0.0416)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9416  max mem: 4442MB\n","[09:37:12.030409] Epoch: [35]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0048 (0.0053)  loss: 0.0494 (0.0527)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8406  max mem: 4442MB\n","[09:37:12.087320] Epoch: [35] Total time: 0:00:02 (0.8608 s / it)\n","[09:37:12.087562] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0048 (0.0053)  loss: 0.0494 (0.0527)  weight_decay: 0.0500 (0.0500)\n","[09:37:12.261290] Epoch: [35]  [0/1]  eta: 0:00:00  jaccard_index: 0.0046 (0.0046)  loss: 0.0134 (0.0134)  iter-time: 0.1714  max mem: 4442MB\n","[09:37:12.317823] Epoch: [35] Total time: 0:00:00 (0.2291 s / it)\n","[09:37:12.317883] [Val] averaged stats: jaccard_index: 0.0046 (0.0046)  loss: 0.0134 (0.0134)\n","[09:37:12.318341] Val loss improved from 0.013512298464775085 to 0.01335611380636692, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:12.358236] [Val] best loss: 0.0134 best  jaccard_index: 0.0046 \n","[09:37:12.359899] Creating training plots . . .\n","[09:37:12.661885] [Time] 3.2s 5.7m/9.1m\n","\n","[09:37:12.661938] ~~~ Epoch 36/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:13.585783] Epoch: [36]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0114 (0.0114)  loss: 0.0414 (0.0414)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9211  max mem: 4442MB\n","[09:37:15.165906] Epoch: [36]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0052 (0.0062)  loss: 0.0491 (0.0525)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8332  max mem: 4442MB\n","[09:37:15.222974] Epoch: [36] Total time: 0:00:02 (0.8534 s / it)\n","[09:37:15.223172] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0052 (0.0062)  loss: 0.0491 (0.0525)  weight_decay: 0.0500 (0.0500)\n","[09:37:15.391255] Epoch: [36]  [0/1]  eta: 0:00:00  jaccard_index: 0.0046 (0.0046)  loss: 0.0132 (0.0132)  iter-time: 0.1662  max mem: 4442MB\n","[09:37:15.446656] Epoch: [36] Total time: 0:00:00 (0.2225 s / it)\n","[09:37:15.446920] [Val] averaged stats: jaccard_index: 0.0046 (0.0046)  loss: 0.0132 (0.0132)\n","[09:37:15.447385] Val loss improved from 0.01335611380636692 to 0.013211328536272049, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:15.486053] [Val] best loss: 0.0132 best  jaccard_index: 0.0046 \n","[09:37:15.487699] [Time] 2.8s 5.7m/8.8m\n","\n","[09:37:15.487741] ~~~ Epoch 37/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:16.422238] Epoch: [37]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0123 (0.0123)  loss: 0.0410 (0.0410)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9319  max mem: 4442MB\n","[09:37:18.004478] Epoch: [37]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0065 (0.0071)  loss: 0.0489 (0.0521)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8375  max mem: 4442MB\n","[09:37:18.059375] Epoch: [37] Total time: 0:00:02 (0.8570 s / it)\n","[09:37:18.059602] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0065 (0.0071)  loss: 0.0489 (0.0521)  weight_decay: 0.0500 (0.0500)\n","[09:37:18.226846] Epoch: [37]  [0/1]  eta: 0:00:00  jaccard_index: 0.0051 (0.0051)  loss: 0.0131 (0.0131)  iter-time: 0.1653  max mem: 4442MB\n","[09:37:18.279617] Epoch: [37] Total time: 0:00:00 (0.2189 s / it)\n","[09:37:18.279670] [Val] averaged stats: jaccard_index: 0.0051 (0.0051)  loss: 0.0131 (0.0131)\n","[09:37:18.280040] Val loss improved from 0.013211328536272049 to 0.013068964704871178, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:18.324178] [Val] best loss: 0.0131 best  jaccard_index: 0.0051 \n","[09:37:18.325804] [Time] 2.8s 5.8m/8.8m\n","\n","[09:37:18.325847] ~~~ Epoch 38/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:19.259041] Epoch: [38]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0143 (0.0143)  loss: 0.0408 (0.0408)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9300  max mem: 4442MB\n","[09:37:20.843644] Epoch: [38]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0066 (0.0079)  loss: 0.0486 (0.0518)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8376  max mem: 4442MB\n","[09:37:20.934994] Epoch: [38] Total time: 0:00:02 (0.8694 s / it)\n","[09:37:20.935304] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0066 (0.0079)  loss: 0.0486 (0.0518)  weight_decay: 0.0500 (0.0500)\n","[09:37:21.137902] Epoch: [38]  [0/1]  eta: 0:00:00  jaccard_index: 0.0051 (0.0051)  loss: 0.0130 (0.0130)  iter-time: 0.1996  max mem: 4442MB\n","[09:37:21.228419] Epoch: [38] Total time: 0:00:00 (0.2916 s / it)\n","[09:37:21.228489] [Val] averaged stats: jaccard_index: 0.0051 (0.0051)  loss: 0.0130 (0.0130)\n","[09:37:21.228978] Val loss improved from 0.013068964704871178 to 0.012951679527759552, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:21.287958] [Val] best loss: 0.0130 best  jaccard_index: 0.0051 \n","[09:37:21.289459] [Time] 3.0s 5.8m/8.9m\n","\n","[09:37:21.289516] ~~~ Epoch 39/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:22.314413] Epoch: [39]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0156 (0.0156)  loss: 0.0404 (0.0404)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0215  max mem: 4442MB\n","[09:37:23.898638] Epoch: [39]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0080 (0.0087)  loss: 0.0484 (0.0516)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8680  max mem: 4442MB\n","[09:37:23.955033] Epoch: [39] Total time: 0:00:02 (0.8882 s / it)\n","[09:37:23.955283] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0080 (0.0087)  loss: 0.0484 (0.0516)  weight_decay: 0.0500 (0.0500)\n","[09:37:24.123381] Epoch: [39]  [0/1]  eta: 0:00:00  jaccard_index: 0.0055 (0.0055)  loss: 0.0128 (0.0128)  iter-time: 0.1661  max mem: 4442MB\n","[09:37:24.182256] Epoch: [39] Total time: 0:00:00 (0.2259 s / it)\n","[09:37:24.182328] [Val] averaged stats: jaccard_index: 0.0055 (0.0055)  loss: 0.0128 (0.0128)\n","[09:37:24.182896] Val loss improved from 0.012951679527759552 to 0.012836444191634655, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:24.226437] [Val] best loss: 0.0128 best  jaccard_index: 0.0055 \n","[09:37:24.227852] [Time] 2.9s 5.9m/8.9m\n","\n","[09:37:24.227896] ~~~ Epoch 40/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:25.157316] Epoch: [40]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0188 (0.0188)  loss: 0.0403 (0.0403)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9265  max mem: 4442MB\n","[09:37:26.736137] Epoch: [40]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0082 (0.0104)  loss: 0.0481 (0.0513)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8346  max mem: 4442MB\n","[09:37:26.792007] Epoch: [40] Total time: 0:00:02 (0.8545 s / it)\n","[09:37:26.792119] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0082 (0.0104)  loss: 0.0481 (0.0513)  weight_decay: 0.0500 (0.0500)\n","[09:37:26.959717] Epoch: [40]  [0/1]  eta: 0:00:00  jaccard_index: 0.0060 (0.0060)  loss: 0.0127 (0.0127)  iter-time: 0.1656  max mem: 4442MB\n","[09:37:27.012315] Epoch: [40] Total time: 0:00:00 (0.2191 s / it)\n","[09:37:27.012606] [Val] averaged stats: jaccard_index: 0.0060 (0.0060)  loss: 0.0127 (0.0127)\n","[09:37:27.012996] Val loss improved from 0.012836444191634655 to 0.012745046988129616, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:27.057629] [Val] best loss: 0.0127 best  jaccard_index: 0.0060 \n","[09:37:27.059096] Creating training plots . . .\n","[09:37:27.352605] [Time] 3.1s 5.9m/9.1m\n","\n","[09:37:27.352677] ~~~ Epoch 41/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:28.289801] Epoch: [41]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0197 (0.0197)  loss: 0.0400 (0.0400)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9342  max mem: 4442MB\n","[09:37:29.872500] Epoch: [41]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0094 (0.0111)  loss: 0.0480 (0.0511)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8384  max mem: 4442MB\n","[09:37:29.930140] Epoch: [41] Total time: 0:00:02 (0.8588 s / it)\n","[09:37:29.930246] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0094 (0.0111)  loss: 0.0480 (0.0511)  weight_decay: 0.0500 (0.0500)\n","[09:37:30.095562] Epoch: [41]  [0/1]  eta: 0:00:00  jaccard_index: 0.0060 (0.0060)  loss: 0.0126 (0.0126)  iter-time: 0.1634  max mem: 4442MB\n","[09:37:30.154531] Epoch: [41] Total time: 0:00:00 (0.2232 s / it)\n","[09:37:30.154658] [Val] averaged stats: jaccard_index: 0.0060 (0.0060)  loss: 0.0126 (0.0126)\n","[09:37:30.155228] Val loss improved from 0.012745046988129616 to 0.01260400377213955, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:30.194694] [Val] best loss: 0.0126 best  jaccard_index: 0.0060 \n","[09:37:30.196192] [Time] 2.8s 6.0m/8.8m\n","\n","[09:37:30.196232] ~~~ Epoch 42/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:31.130174] Epoch: [42]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0230 (0.0230)  loss: 0.0398 (0.0398)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9311  max mem: 4442MB\n","[09:37:32.709955] Epoch: [42]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0103 (0.0130)  loss: 0.0477 (0.0508)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8363  max mem: 4442MB\n","[09:37:32.819190] Epoch: [42] Total time: 0:00:02 (0.8741 s / it)\n","[09:37:32.819521] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0103 (0.0130)  loss: 0.0477 (0.0508)  weight_decay: 0.0500 (0.0500)\n","[09:37:33.012551] Epoch: [42]  [0/1]  eta: 0:00:00  jaccard_index: 0.0064 (0.0064)  loss: 0.0125 (0.0125)  iter-time: 0.1904  max mem: 4442MB\n","[09:37:33.112387] Epoch: [42] Total time: 0:00:00 (0.2914 s / it)\n","[09:37:33.112673] [Val] averaged stats: jaccard_index: 0.0064 (0.0064)  loss: 0.0125 (0.0125)\n","[09:37:33.113172] Val loss improved from 0.01260400377213955 to 0.012485602870583534, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:33.171660] [Val] best loss: 0.0125 best  jaccard_index: 0.0064 \n","[09:37:33.173554] [Time] 3.0s 6.0m/8.9m\n","\n","[09:37:33.173592] ~~~ Epoch 43/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:34.164928] Epoch: [43]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0248 (0.0248)  loss: 0.0397 (0.0397)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9878  max mem: 4442MB\n","[09:37:35.750743] Epoch: [43]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0117 (0.0136)  loss: 0.0475 (0.0506)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8572  max mem: 4442MB\n","[09:37:35.805567] Epoch: [43] Total time: 0:00:02 (0.8769 s / it)\n","[09:37:35.805781] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0117 (0.0136)  loss: 0.0475 (0.0506)  weight_decay: 0.0500 (0.0500)\n","[09:37:35.971747] Epoch: [43]  [0/1]  eta: 0:00:00  jaccard_index: 0.0074 (0.0074)  loss: 0.0124 (0.0124)  iter-time: 0.1640  max mem: 4442MB\n","[09:37:36.027161] Epoch: [43] Total time: 0:00:00 (0.2203 s / it)\n","[09:37:36.027225] [Val] averaged stats: jaccard_index: 0.0074 (0.0074)  loss: 0.0124 (0.0124)\n","[09:37:36.027705] Val loss improved from 0.012485602870583534 to 0.012419527396559715, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:36.070944] [Val] best loss: 0.0124 best  jaccard_index: 0.0074 \n","[09:37:36.072359] [Time] 2.9s 6.0m/8.9m\n","\n","[09:37:36.072398] ~~~ Epoch 44/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:37.000811] Epoch: [44]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0216 (0.0216)  loss: 0.0394 (0.0394)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9258  max mem: 4442MB\n","[09:37:38.581550] Epoch: [44]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0126 (0.0132)  loss: 0.0473 (0.0504)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8349  max mem: 4442MB\n","[09:37:38.638266] Epoch: [44] Total time: 0:00:02 (0.8551 s / it)\n","[09:37:38.638669] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0126 (0.0132)  loss: 0.0473 (0.0504)  weight_decay: 0.0500 (0.0500)\n","[09:37:38.809753] Epoch: [44]  [0/1]  eta: 0:00:00  jaccard_index: 0.0074 (0.0074)  loss: 0.0123 (0.0123)  iter-time: 0.1691  max mem: 4442MB\n","[09:37:38.862304] Epoch: [44] Total time: 0:00:00 (0.2226 s / it)\n","[09:37:38.862357] [Val] averaged stats: jaccard_index: 0.0074 (0.0074)  loss: 0.0123 (0.0123)\n","[09:37:38.862778] Val loss improved from 0.012419527396559715 to 0.012315335683524609, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:38.908063] [Val] best loss: 0.0123 best  jaccard_index: 0.0074 \n","[09:37:38.909594] [Time] 2.8s 6.1m/8.8m\n","\n","[09:37:38.909634] ~~~ Epoch 45/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:39.845893] Epoch: [45]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0256 (0.0256)  loss: 0.0392 (0.0392)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9340  max mem: 4442MB\n","[09:37:41.433179] Epoch: [45]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0128 (0.0149)  loss: 0.0471 (0.0502)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8382  max mem: 4442MB\n","[09:37:41.489863] Epoch: [45] Total time: 0:00:02 (0.8598 s / it)\n","[09:37:41.490071] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0128 (0.0149)  loss: 0.0471 (0.0502)  weight_decay: 0.0500 (0.0500)\n","[09:37:41.665759] Epoch: [45]  [0/1]  eta: 0:00:00  jaccard_index: 0.0074 (0.0074)  loss: 0.0122 (0.0122)  iter-time: 0.1737  max mem: 4442MB\n","[09:37:41.723778] Epoch: [45] Total time: 0:00:00 (0.2326 s / it)\n","[09:37:41.723839] [Val] averaged stats: jaccard_index: 0.0074 (0.0074)  loss: 0.0122 (0.0122)\n","[09:37:41.724287] Val loss improved from 0.012315335683524609 to 0.012213705107569695, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:41.764253] [Val] best loss: 0.0122 best  jaccard_index: 0.0074 \n","[09:37:41.765692] Creating training plots . . .\n","[09:37:42.037851] [Time] 3.1s 6.1m/9.1m\n","\n","[09:37:42.037905] ~~~ Epoch 46/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:42.971633] Epoch: [46]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0280 (0.0280)  loss: 0.0390 (0.0390)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9310  max mem: 4442MB\n","[09:37:44.554536] Epoch: [46]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0139 (0.0163)  loss: 0.0470 (0.0499)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8375  max mem: 4442MB\n","[09:37:44.615567] Epoch: [46] Total time: 0:00:02 (0.8590 s / it)\n","[09:37:44.615900] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0139 (0.0163)  loss: 0.0470 (0.0499)  weight_decay: 0.0500 (0.0500)\n","[09:37:44.788756] Epoch: [46]  [0/1]  eta: 0:00:00  jaccard_index: 0.0069 (0.0069)  loss: 0.0121 (0.0121)  iter-time: 0.1698  max mem: 4442MB\n","[09:37:44.844989] Epoch: [46] Total time: 0:00:00 (0.2276 s / it)\n","[09:37:44.845050] [Val] averaged stats: jaccard_index: 0.0069 (0.0069)  loss: 0.0121 (0.0121)\n","[09:37:44.845562] Val loss improved from 0.012213705107569695 to 0.012139914557337761, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:44.883902] [Val] best loss: 0.0121 best  jaccard_index: 0.0069 \n","[09:37:44.884959] [Time] 2.8s 6.2m/8.8m\n","\n","[09:37:44.884997] ~~~ Epoch 47/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:45.811813] Epoch: [47]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0319 (0.0319)  loss: 0.0389 (0.0389)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9234  max mem: 4442MB\n","[09:37:47.393866] Epoch: [47]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0145 (0.0179)  loss: 0.0468 (0.0497)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8346  max mem: 4442MB\n","[09:37:47.505795] Epoch: [47] Total time: 0:00:02 (0.8733 s / it)\n","[09:37:47.506097] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0145 (0.0179)  loss: 0.0468 (0.0497)  weight_decay: 0.0500 (0.0500)\n","[09:37:47.703327] Epoch: [47]  [0/1]  eta: 0:00:00  jaccard_index: 0.0078 (0.0078)  loss: 0.0121 (0.0121)  iter-time: 0.1948  max mem: 4442MB\n","[09:37:47.806559] Epoch: [47] Total time: 0:00:00 (0.2989 s / it)\n","[09:37:47.806851] [Val] averaged stats: jaccard_index: 0.0078 (0.0078)  loss: 0.0121 (0.0121)\n","[09:37:47.807424] Val loss improved from 0.012139914557337761 to 0.012077088467776775, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:47.868000] [Val] best loss: 0.0121 best  jaccard_index: 0.0078 \n","[09:37:47.869396] [Time] 3.0s 6.2m/8.9m\n","\n","[09:37:47.869446] ~~~ Epoch 48/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:48.882522] Epoch: [48]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0311 (0.0311)  loss: 0.0386 (0.0386)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0097  max mem: 4442MB\n","[09:37:50.466499] Epoch: [48]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0156 (0.0184)  loss: 0.0465 (0.0495)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8640  max mem: 4442MB\n","[09:37:50.523737] Epoch: [48] Total time: 0:00:02 (0.8844 s / it)\n","[09:37:50.523937] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0156 (0.0184)  loss: 0.0465 (0.0495)  weight_decay: 0.0500 (0.0500)\n","[09:37:50.691389] Epoch: [48]  [0/1]  eta: 0:00:00  jaccard_index: 0.0083 (0.0083)  loss: 0.0120 (0.0120)  iter-time: 0.1656  max mem: 4442MB\n","[09:37:50.750743] Epoch: [48] Total time: 0:00:00 (0.2257 s / it)\n","[09:37:50.750801] [Val] averaged stats: jaccard_index: 0.0083 (0.0083)  loss: 0.0120 (0.0120)\n","[09:37:50.751234] Val loss improved from 0.012077088467776775 to 0.011977240443229675, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:50.795583] [Val] best loss: 0.0120 best  jaccard_index: 0.0083 \n","[09:37:50.797063] [Time] 2.9s 6.3m/8.9m\n","\n","[09:37:50.797106] ~~~ Epoch 49/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:51.725781] Epoch: [49]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0326 (0.0326)  loss: 0.0385 (0.0385)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9258  max mem: 4442MB\n","[09:37:53.309299] Epoch: [49]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0178 (0.0199)  loss: 0.0463 (0.0493)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8359  max mem: 4442MB\n","[09:37:53.364878] Epoch: [49] Total time: 0:00:02 (0.8556 s / it)\n","[09:37:53.365166] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0178 (0.0199)  loss: 0.0463 (0.0493)  weight_decay: 0.0500 (0.0500)\n","[09:37:53.533334] Epoch: [49]  [0/1]  eta: 0:00:00  jaccard_index: 0.0097 (0.0097)  loss: 0.0119 (0.0119)  iter-time: 0.1659  max mem: 4442MB\n","[09:37:53.586777] Epoch: [49] Total time: 0:00:00 (0.2205 s / it)\n","[09:37:53.587062] [Val] averaged stats: jaccard_index: 0.0097 (0.0097)  loss: 0.0119 (0.0119)\n","[09:37:53.587521] Val loss improved from 0.011977240443229675 to 0.011898383498191833, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:53.628495] [Val] best loss: 0.0119 best  jaccard_index: 0.0097 \n","[09:37:53.630000] [Time] 2.8s 6.3m/8.8m\n","\n","[09:37:53.630055] ~~~ Epoch 50/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:54.560427] Epoch: [50]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0338 (0.0338)  loss: 0.0383 (0.0383)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9276  max mem: 4442MB\n","[09:37:56.146833] Epoch: [50]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0173 (0.0200)  loss: 0.0463 (0.0492)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8375  max mem: 4442MB\n","[09:37:56.206200] Epoch: [50] Total time: 0:00:02 (0.8585 s / it)\n","[09:37:56.206532] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0173 (0.0200)  loss: 0.0463 (0.0492)  weight_decay: 0.0500 (0.0500)\n","[09:37:56.376428] Epoch: [50]  [0/1]  eta: 0:00:00  jaccard_index: 0.0101 (0.0101)  loss: 0.0119 (0.0119)  iter-time: 0.1679  max mem: 4442MB\n","[09:37:56.433731] Epoch: [50] Total time: 0:00:00 (0.2261 s / it)\n","[09:37:56.434047] [Val] averaged stats: jaccard_index: 0.0101 (0.0101)  loss: 0.0119 (0.0119)\n","[09:37:56.434511] Val loss improved from 0.011898383498191833 to 0.011851302348077297, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:56.474117] [Val] best loss: 0.0119 best  jaccard_index: 0.0101 \n","[09:37:56.475572] Creating training plots . . .\n","[09:37:56.750090] [Time] 3.1s 6.4m/9.0m\n","\n","[09:37:56.750138] ~~~ Epoch 51/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:37:57.688466] Epoch: [51]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0369 (0.0369)  loss: 0.0382 (0.0382)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9355  max mem: 4442MB\n","[09:37:59.269803] Epoch: [51]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0190 (0.0222)  loss: 0.0460 (0.0489)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8384  max mem: 4442MB\n","[09:37:59.360425] Epoch: [51] Total time: 0:00:02 (0.8698 s / it)\n","[09:37:59.360759] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0190 (0.0222)  loss: 0.0460 (0.0489)  weight_decay: 0.0500 (0.0500)\n","[09:37:59.556267] Epoch: [51]  [0/1]  eta: 0:00:00  jaccard_index: 0.0096 (0.0096)  loss: 0.0118 (0.0118)  iter-time: 0.1929  max mem: 4442MB\n","[09:37:59.651562] Epoch: [51] Total time: 0:00:00 (0.2893 s / it)\n","[09:37:59.651620] [Val] averaged stats: jaccard_index: 0.0096 (0.0096)  loss: 0.0118 (0.0118)\n","[09:37:59.652072] Val loss improved from 0.011851302348077297 to 0.011803481727838516, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:37:59.712821] [Val] best loss: 0.0118 best  jaccard_index: 0.0096 \n","[09:37:59.714336] [Time] 3.0s 6.4m/8.9m\n","\n","[09:37:59.714375] ~~~ Epoch 52/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:00.725024] Epoch: [52]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0375 (0.0375)  loss: 0.0380 (0.0380)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0074  max mem: 4442MB\n","[09:38:02.313722] Epoch: [52]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0210 (0.0232)  loss: 0.0458 (0.0487)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8648  max mem: 4442MB\n","[09:38:02.370537] Epoch: [52] Total time: 0:00:02 (0.8850 s / it)\n","[09:38:02.370786] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0210 (0.0232)  loss: 0.0458 (0.0487)  weight_decay: 0.0500 (0.0500)\n","[09:38:02.539534] Epoch: [52]  [0/1]  eta: 0:00:00  jaccard_index: 0.0101 (0.0101)  loss: 0.0117 (0.0117)  iter-time: 0.1666  max mem: 4442MB\n","[09:38:02.597926] Epoch: [52] Total time: 0:00:00 (0.2260 s / it)\n","[09:38:02.598225] [Val] averaged stats: jaccard_index: 0.0101 (0.0101)  loss: 0.0117 (0.0117)\n","[09:38:02.598756] Val loss improved from 0.011803481727838516 to 0.011715283617377281, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:02.638685] [Val] best loss: 0.0117 best  jaccard_index: 0.0101 \n","[09:38:02.640168] [Time] 2.9s 6.5m/8.9m\n","\n","[09:38:02.640209] ~~~ Epoch 53/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:03.572434] Epoch: [53]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0430 (0.0430)  loss: 0.0378 (0.0378)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9292  max mem: 4442MB\n","[09:38:05.157136] Epoch: [53]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0224 (0.0264)  loss: 0.0457 (0.0486)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8374  max mem: 4442MB\n","[09:38:05.215300] Epoch: [53] Total time: 0:00:02 (0.8581 s / it)\n","[09:38:05.215567] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0224 (0.0264)  loss: 0.0457 (0.0486)  weight_decay: 0.0500 (0.0500)\n","[09:38:05.383249] Epoch: [53]  [0/1]  eta: 0:00:00  jaccard_index: 0.0105 (0.0105)  loss: 0.0117 (0.0117)  iter-time: 0.1655  max mem: 4442MB\n","[09:38:05.437372] Epoch: [53] Total time: 0:00:00 (0.2207 s / it)\n","[09:38:05.437426] [Val] averaged stats: jaccard_index: 0.0105 (0.0105)  loss: 0.0117 (0.0117)\n","[09:38:05.437949] Val loss improved from 0.011715283617377281 to 0.011692121624946594, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:05.481678] [Val] best loss: 0.0117 best  jaccard_index: 0.0105 \n","[09:38:05.483174] [Time] 2.8s 6.5m/8.8m\n","\n","[09:38:05.483216] ~~~ Epoch 54/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:06.414305] Epoch: [54]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0381 (0.0381)  loss: 0.0376 (0.0376)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9283  max mem: 4442MB\n","[09:38:07.996442] Epoch: [54]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0234 (0.0254)  loss: 0.0455 (0.0484)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8363  max mem: 4442MB\n","[09:38:08.052912] Epoch: [54] Total time: 0:00:02 (0.8563 s / it)\n","[09:38:08.053128] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0234 (0.0254)  loss: 0.0455 (0.0484)  weight_decay: 0.0500 (0.0500)\n","[09:38:08.222727] Epoch: [54]  [0/1]  eta: 0:00:00  jaccard_index: 0.0110 (0.0110)  loss: 0.0117 (0.0117)  iter-time: 0.1676  max mem: 4442MB\n","[09:38:08.284865] Epoch: [54] Total time: 0:00:00 (0.2307 s / it)\n","[09:38:08.285181] [Val] averaged stats: jaccard_index: 0.0110 (0.0110)  loss: 0.0117 (0.0117)\n","[09:38:08.285649] Val loss improved from 0.011692121624946594 to 0.011653859168291092, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:08.327448] [Val] best loss: 0.0117 best  jaccard_index: 0.0110 \n","[09:38:08.329207] [Time] 2.8s 6.6m/8.8m\n","\n","[09:38:08.329250] ~~~ Epoch 55/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:09.268941] Epoch: [55]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0413 (0.0413)  loss: 0.0375 (0.0375)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9369  max mem: 4442MB\n","[09:38:10.854232] Epoch: [55]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0234 (0.0269)  loss: 0.0455 (0.0483)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8402  max mem: 4442MB\n","[09:38:10.911535] Epoch: [55] Total time: 0:00:02 (0.8605 s / it)\n","[09:38:10.911776] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0234 (0.0269)  loss: 0.0455 (0.0483)  weight_decay: 0.0500 (0.0500)\n","[09:38:11.081401] Epoch: [55]  [0/1]  eta: 0:00:00  jaccard_index: 0.0110 (0.0110)  loss: 0.0116 (0.0116)  iter-time: 0.1676  max mem: 4442MB\n","[09:38:11.142830] Epoch: [55] Total time: 0:00:00 (0.2299 s / it)\n","[09:38:11.143126] [Val] averaged stats: jaccard_index: 0.0110 (0.0110)  loss: 0.0116 (0.0116)\n","[09:38:11.143617] Val loss improved from 0.011653859168291092 to 0.011608069762587547, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:11.183493] [Val] best loss: 0.0116 best  jaccard_index: 0.0110 \n","[09:38:11.184793] Creating training plots . . .\n","[09:38:11.497829] [Time] 3.2s 6.6m/9.1m\n","\n","[09:38:11.497885] ~~~ Epoch 56/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:12.444311] Epoch: [56]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0421 (0.0421)  loss: 0.0374 (0.0374)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9432  max mem: 4442MB\n","[09:38:14.030988] Epoch: [56]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0262 (0.0289)  loss: 0.0453 (0.0481)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8426  max mem: 4442MB\n","[09:38:14.123329] Epoch: [56] Total time: 0:00:02 (0.8749 s / it)\n","[09:38:14.123455] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0262 (0.0289)  loss: 0.0453 (0.0481)  weight_decay: 0.0500 (0.0500)\n","[09:38:14.326781] Epoch: [56]  [0/1]  eta: 0:00:00  jaccard_index: 0.0109 (0.0109)  loss: 0.0115 (0.0115)  iter-time: 0.2006  max mem: 4442MB\n","[09:38:14.412093] Epoch: [56] Total time: 0:00:00 (0.2871 s / it)\n","[09:38:14.412365] [Val] averaged stats: jaccard_index: 0.0109 (0.0109)  loss: 0.0115 (0.0115)\n","[09:38:14.413008] Val loss improved from 0.011608069762587547 to 0.011529652401804924, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:14.474929] [Val] best loss: 0.0115 best  jaccard_index: 0.0109 \n","[09:38:14.477034] [Time] 3.0s 6.7m/8.9m\n","\n","[09:38:14.477097] ~~~ Epoch 57/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:15.473512] Epoch: [57]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0496 (0.0496)  loss: 0.0372 (0.0372)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9928  max mem: 4442MB\n","[09:38:17.053520] Epoch: [57]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0255 (0.0311)  loss: 0.0452 (0.0479)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8571  max mem: 4442MB\n","[09:38:17.111600] Epoch: [57] Total time: 0:00:02 (0.8778 s / it)\n","[09:38:17.111720] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0255 (0.0311)  loss: 0.0452 (0.0479)  weight_decay: 0.0500 (0.0500)\n","[09:38:17.280136] Epoch: [57]  [0/1]  eta: 0:00:00  jaccard_index: 0.0118 (0.0118)  loss: 0.0115 (0.0115)  iter-time: 0.1663  max mem: 4442MB\n","[09:38:17.340263] Epoch: [57] Total time: 0:00:00 (0.2274 s / it)\n","[09:38:17.340321] [Val] averaged stats: jaccard_index: 0.0118 (0.0118)  loss: 0.0115 (0.0115)\n","[09:38:17.340873] Val loss improved from 0.011529652401804924 to 0.011527719907462597, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:17.388596] [Val] best loss: 0.0115 best  jaccard_index: 0.0118 \n","[09:38:17.390065] [Time] 2.9s 6.7m/8.9m\n","\n","[09:38:17.390106] ~~~ Epoch 58/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:18.332987] Epoch: [58]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0455 (0.0455)  loss: 0.0370 (0.0370)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9394  max mem: 4442MB\n","[09:38:19.916019] Epoch: [58]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0284 (0.0307)  loss: 0.0449 (0.0477)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8403  max mem: 4442MB\n","[09:38:19.972926] Epoch: [58] Total time: 0:00:02 (0.8607 s / it)\n","[09:38:19.973039] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0284 (0.0307)  loss: 0.0449 (0.0477)  weight_decay: 0.0500 (0.0500)\n","[09:38:20.138709] Epoch: [58]  [0/1]  eta: 0:00:00  jaccard_index: 0.0128 (0.0128)  loss: 0.0114 (0.0114)  iter-time: 0.1638  max mem: 4442MB\n","[09:38:20.191777] Epoch: [58] Total time: 0:00:00 (0.2176 s / it)\n","[09:38:20.191825] [Val] averaged stats: jaccard_index: 0.0128 (0.0128)  loss: 0.0114 (0.0114)\n","[09:38:20.192213] Val loss improved from 0.011527719907462597 to 0.011432275176048279, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:20.237456] [Val] best loss: 0.0114 best  jaccard_index: 0.0128 \n","[09:38:20.238968] [Time] 2.8s 6.8m/8.8m\n","\n","[09:38:20.239004] ~~~ Epoch 59/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:21.174838] Epoch: [59]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0523 (0.0523)  loss: 0.0370 (0.0370)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9332  max mem: 4442MB\n","[09:38:22.759157] Epoch: [59]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0289 (0.0337)  loss: 0.0448 (0.0476)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8387  max mem: 4442MB\n","[09:38:22.817579] Epoch: [59] Total time: 0:00:02 (0.8593 s / it)\n","[09:38:22.817682] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0289 (0.0337)  loss: 0.0448 (0.0476)  weight_decay: 0.0500 (0.0500)\n","[09:38:22.985290] Epoch: [59]  [0/1]  eta: 0:00:00  jaccard_index: 0.0132 (0.0132)  loss: 0.0114 (0.0114)  iter-time: 0.1656  max mem: 4442MB\n","[09:38:23.046820] Epoch: [59] Total time: 0:00:00 (0.2281 s / it)\n","[09:38:23.046876] [Val] averaged stats: jaccard_index: 0.0132 (0.0132)  loss: 0.0114 (0.0114)\n","[09:38:23.047286] Val loss improved from 0.011432275176048279 to 0.011404837481677532, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:23.086500] [Val] best loss: 0.0114 best  jaccard_index: 0.0132 \n","[09:38:23.087835] [Time] 2.8s 6.8m/8.8m\n","\n","[09:38:23.087875] ~~~ Epoch 60/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:24.018517] Epoch: [60]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0494 (0.0494)  loss: 0.0368 (0.0368)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9278  max mem: 4442MB\n","[09:38:25.596623] Epoch: [60]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0303 (0.0350)  loss: 0.0447 (0.0474)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8348  max mem: 4442MB\n","[09:38:25.654062] Epoch: [60] Total time: 0:00:02 (0.8552 s / it)\n","[09:38:25.654171] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0303 (0.0350)  loss: 0.0447 (0.0474)  weight_decay: 0.0500 (0.0500)\n","[09:38:25.823554] Epoch: [60]  [0/1]  eta: 0:00:00  jaccard_index: 0.0146 (0.0146)  loss: 0.0114 (0.0114)  iter-time: 0.1671  max mem: 4442MB\n","[09:38:25.919932] Epoch: [60] Total time: 0:00:00 (0.2647 s / it)\n","[09:38:25.919992] [Val] averaged stats: jaccard_index: 0.0146 (0.0146)  loss: 0.0114 (0.0114)\n","[09:38:25.920525] Val loss improved from 0.011404837481677532 to 0.011351327411830425, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:25.981555] [Val] best loss: 0.0114 best  jaccard_index: 0.0146 \n","[09:38:25.983137] Creating training plots . . .\n","[09:38:26.445118] [Time] 3.4s 6.9m/9.2m\n","\n","[09:38:26.445176] ~~~ Epoch 61/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:27.430667] Epoch: [61]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0510 (0.0510)  loss: 0.0367 (0.0367)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9819  max mem: 4442MB\n","[09:38:29.015018] Epoch: [61]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0327 (0.0363)  loss: 0.0446 (0.0472)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8548  max mem: 4442MB\n","[09:38:29.073139] Epoch: [61] Total time: 0:00:02 (0.8756 s / it)\n","[09:38:29.073496] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0327 (0.0363)  loss: 0.0446 (0.0472)  weight_decay: 0.0500 (0.0500)\n","[09:38:29.242923] Epoch: [61]  [0/1]  eta: 0:00:00  jaccard_index: 0.0159 (0.0159)  loss: 0.0113 (0.0113)  iter-time: 0.1675  max mem: 4442MB\n","[09:38:29.305151] Epoch: [61] Total time: 0:00:00 (0.2305 s / it)\n","[09:38:29.305210] [Val] averaged stats: jaccard_index: 0.0159 (0.0159)  loss: 0.0113 (0.0113)\n","[09:38:29.305691] Val loss improved from 0.011351327411830425 to 0.011287937872111797, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:29.345006] [Val] best loss: 0.0113 best  jaccard_index: 0.0159 \n","[09:38:29.346602] [Time] 2.9s 6.9m/8.9m\n","\n","[09:38:29.346641] ~~~ Epoch 62/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:30.283254] Epoch: [62]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0573 (0.0573)  loss: 0.0366 (0.0366)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9339  max mem: 4442MB\n","[09:38:31.864627] Epoch: [62]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0338 (0.0390)  loss: 0.0445 (0.0471)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8379  max mem: 4442MB\n","[09:38:31.928859] Epoch: [62] Total time: 0:00:02 (0.8605 s / it)\n","[09:38:31.928976] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0338 (0.0390)  loss: 0.0445 (0.0471)  weight_decay: 0.0500 (0.0500)\n","[09:38:32.104833] Epoch: [62]  [0/1]  eta: 0:00:00  jaccard_index: 0.0181 (0.0181)  loss: 0.0113 (0.0113)  iter-time: 0.1737  max mem: 4442MB\n","[09:38:32.161675] Epoch: [62] Total time: 0:00:00 (0.2316 s / it)\n","[09:38:32.161884] [Val] averaged stats: jaccard_index: 0.0181 (0.0181)  loss: 0.0113 (0.0113)\n","[09:38:32.162397] Val loss improved from 0.011287937872111797 to 0.011264617554843426, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:32.205551] [Val] best loss: 0.0113 best  jaccard_index: 0.0181 \n","[09:38:32.207173] [Time] 2.9s 7.0m/8.8m\n","\n","[09:38:32.207213] ~~~ Epoch 63/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:33.143100] Epoch: [63]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0564 (0.0564)  loss: 0.0364 (0.0364)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9331  max mem: 4442MB\n","[09:38:34.725876] Epoch: [63]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0364 (0.0392)  loss: 0.0442 (0.0470)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8381  max mem: 4442MB\n","[09:38:34.785258] Epoch: [63] Total time: 0:00:02 (0.8591 s / it)\n","[09:38:34.785552] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0364 (0.0392)  loss: 0.0442 (0.0470)  weight_decay: 0.0500 (0.0500)\n","[09:38:34.957668] Epoch: [63]  [0/1]  eta: 0:00:00  jaccard_index: 0.0186 (0.0186)  loss: 0.0112 (0.0112)  iter-time: 0.1697  max mem: 4442MB\n","[09:38:35.016003] Epoch: [63] Total time: 0:00:00 (0.2289 s / it)\n","[09:38:35.016066] [Val] averaged stats: jaccard_index: 0.0186 (0.0186)  loss: 0.0112 (0.0112)\n","[09:38:35.016571] Val loss improved from 0.011264617554843426 to 0.011207161471247673, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:35.057430] [Val] best loss: 0.0112 best  jaccard_index: 0.0186 \n","[09:38:35.059065] [Time] 2.9s 7.0m/8.8m\n","\n","[09:38:35.059108] ~~~ Epoch 64/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:35.993828] Epoch: [64]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0580 (0.0580)  loss: 0.0363 (0.0363)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9320  max mem: 4442MB\n","[09:38:37.578830] Epoch: [64]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0375 (0.0416)  loss: 0.0441 (0.0468)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8385  max mem: 4442MB\n","[09:38:37.638029] Epoch: [64] Total time: 0:00:02 (0.8594 s / it)\n","[09:38:37.638146] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0375 (0.0416)  loss: 0.0441 (0.0468)  weight_decay: 0.0500 (0.0500)\n","[09:38:37.809910] Epoch: [64]  [0/1]  eta: 0:00:00  jaccard_index: 0.0208 (0.0208)  loss: 0.0112 (0.0112)  iter-time: 0.1696  max mem: 4442MB\n","[09:38:37.875995] Epoch: [64] Total time: 0:00:00 (0.2367 s / it)\n","[09:38:37.876056] [Val] averaged stats: jaccard_index: 0.0208 (0.0208)  loss: 0.0112 (0.0112)\n","[09:38:37.876692] Val loss improved from 0.011207161471247673 to 0.011179919354617596, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:37.919356] [Val] best loss: 0.0112 best  jaccard_index: 0.0208 \n","[09:38:37.920796] [Time] 2.9s 7.1m/8.8m\n","\n","[09:38:37.920834] ~~~ Epoch 65/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:38.854957] Epoch: [65]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0553 (0.0553)  loss: 0.0362 (0.0362)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9314  max mem: 4442MB\n","[09:38:40.436443] Epoch: [65]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0395 (0.0415)  loss: 0.0440 (0.0467)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8371  max mem: 4442MB\n","[09:38:40.528685] Epoch: [65] Total time: 0:00:02 (0.8690 s / it)\n","[09:38:40.528999] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0395 (0.0415)  loss: 0.0440 (0.0467)  weight_decay: 0.0500 (0.0500)\n","[09:38:40.726752] Epoch: [65]  [0/1]  eta: 0:00:00  jaccard_index: 0.0235 (0.0235)  loss: 0.0111 (0.0111)  iter-time: 0.1951  max mem: 4442MB\n","[09:38:40.811549] Epoch: [65] Total time: 0:00:00 (0.2811 s / it)\n","[09:38:40.811885] [Val] averaged stats: jaccard_index: 0.0235 (0.0235)  loss: 0.0111 (0.0111)\n","[09:38:40.812390] Val loss improved from 0.011179919354617596 to 0.01113205961883068, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:40.874949] [Val] best loss: 0.0111 best  jaccard_index: 0.0235 \n","[09:38:40.877149] Creating training plots . . .\n","[09:38:41.383012] [Time] 3.5s 7.1m/9.2m\n","\n","[09:38:41.383078] ~~~ Epoch 66/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:42.355826] Epoch: [66]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0648 (0.0648)  loss: 0.0360 (0.0360)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9691  max mem: 4442MB\n","[09:38:43.936907] Epoch: [66]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0404 (0.0459)  loss: 0.0438 (0.0465)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8494  max mem: 4442MB\n","[09:38:43.992900] Epoch: [66] Total time: 0:00:02 (0.8696 s / it)\n","[09:38:43.993002] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0404 (0.0459)  loss: 0.0438 (0.0465)  weight_decay: 0.0500 (0.0500)\n","[09:38:44.162422] Epoch: [66]  [0/1]  eta: 0:00:00  jaccard_index: 0.0253 (0.0253)  loss: 0.0111 (0.0111)  iter-time: 0.1675  max mem: 4442MB\n","[09:38:44.226082] Epoch: [66] Total time: 0:00:00 (0.2321 s / it)\n","[09:38:44.226373] [Val] averaged stats: jaccard_index: 0.0253 (0.0253)  loss: 0.0111 (0.0111)\n","[09:38:44.226842] Val loss improved from 0.01113205961883068 to 0.011090818792581558, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:44.265993] [Val] best loss: 0.0111 best  jaccard_index: 0.0253 \n","[09:38:44.267405] [Time] 2.9s 7.2m/8.9m\n","\n","[09:38:44.267440] ~~~ Epoch 67/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:45.194509] Epoch: [67]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0593 (0.0593)  loss: 0.0359 (0.0359)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9243  max mem: 4442MB\n","[09:38:46.774394] Epoch: [67]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0445 (0.0461)  loss: 0.0438 (0.0463)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8342  max mem: 4442MB\n","[09:38:46.833847] Epoch: [67] Total time: 0:00:02 (0.8552 s / it)\n","[09:38:46.833957] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0445 (0.0461)  loss: 0.0438 (0.0463)  weight_decay: 0.0500 (0.0500)\n","[09:38:47.001585] Epoch: [67]  [0/1]  eta: 0:00:00  jaccard_index: 0.0261 (0.0261)  loss: 0.0111 (0.0111)  iter-time: 0.1656  max mem: 4442MB\n","[09:38:47.061895] Epoch: [67] Total time: 0:00:00 (0.2269 s / it)\n","[09:38:47.061951] [Val] averaged stats: jaccard_index: 0.0261 (0.0261)  loss: 0.0111 (0.0111)\n","[09:38:47.062363] Val loss improved from 0.011090818792581558 to 0.011052355170249939, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:47.101539] [Val] best loss: 0.0111 best  jaccard_index: 0.0261 \n","[09:38:47.102916] [Time] 2.8s 7.2m/8.8m\n","\n","[09:38:47.102954] ~~~ Epoch 68/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:48.036839] Epoch: [68]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0621 (0.0621)  loss: 0.0357 (0.0357)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9310  max mem: 4442MB\n","[09:38:49.611844] Epoch: [68]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0433 (0.0460)  loss: 0.0437 (0.0462)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8347  max mem: 4442MB\n","[09:38:49.667921] Epoch: [68] Total time: 0:00:02 (0.8547 s / it)\n","[09:38:49.668271] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0433 (0.0460)  loss: 0.0437 (0.0462)  weight_decay: 0.0500 (0.0500)\n","[09:38:49.838360] Epoch: [68]  [0/1]  eta: 0:00:00  jaccard_index: 0.0270 (0.0270)  loss: 0.0110 (0.0110)  iter-time: 0.1676  max mem: 4442MB\n","[09:38:49.897902] Epoch: [68] Total time: 0:00:00 (0.2285 s / it)\n","[09:38:49.897955] [Val] averaged stats: jaccard_index: 0.0270 (0.0270)  loss: 0.0110 (0.0110)\n","[09:38:49.898349] Val loss improved from 0.011052355170249939 to 0.011003709398210049, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:49.938817] [Val] best loss: 0.0110 best  jaccard_index: 0.0270 \n","[09:38:49.940119] [Time] 2.8s 7.3m/8.8m\n","\n","[09:38:49.940160] ~~~ Epoch 69/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:50.866676] Epoch: [69]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0691 (0.0691)  loss: 0.0358 (0.0358)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9237  max mem: 4442MB\n","[09:38:52.447511] Epoch: [69]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0439 (0.0508)  loss: 0.0435 (0.0461)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8343  max mem: 4442MB\n","[09:38:52.504055] Epoch: [69] Total time: 0:00:02 (0.8544 s / it)\n","[09:38:52.504158] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0439 (0.0508)  loss: 0.0435 (0.0461)  weight_decay: 0.0500 (0.0500)\n","[09:38:52.672491] Epoch: [69]  [0/1]  eta: 0:00:00  jaccard_index: 0.0293 (0.0293)  loss: 0.0110 (0.0110)  iter-time: 0.1661  max mem: 4442MB\n","[09:38:52.774601] Epoch: [69] Total time: 0:00:00 (0.2694 s / it)\n","[09:38:52.774860] [Val] averaged stats: jaccard_index: 0.0293 (0.0293)  loss: 0.0110 (0.0110)\n","[09:38:52.775377] Val loss improved from 0.011003709398210049 to 0.010995234362781048, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:52.836412] [Val] best loss: 0.0110 best  jaccard_index: 0.0293 \n","[09:38:52.837942] [Time] 2.9s 7.3m/8.9m\n","\n","[09:38:52.837989] ~~~ Epoch 70/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:53.807803] Epoch: [70]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0647 (0.0647)  loss: 0.0356 (0.0356)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9666  max mem: 4442MB\n","[09:38:55.386686] Epoch: [70]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0497 (0.0517)  loss: 0.0434 (0.0460)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8478  max mem: 4442MB\n","[09:38:55.471522] Epoch: [70] Total time: 0:00:02 (0.8775 s / it)\n","[09:38:55.471669] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0497 (0.0517)  loss: 0.0434 (0.0460)  weight_decay: 0.0500 (0.0500)\n","[09:38:55.667647] Epoch: [70]  [0/1]  eta: 0:00:00  jaccard_index: 0.0280 (0.0280)  loss: 0.0109 (0.0109)  iter-time: 0.1930  max mem: 4442MB\n","[09:38:55.765079] Epoch: [70] Total time: 0:00:00 (0.2918 s / it)\n","[09:38:55.765399] [Val] averaged stats: jaccard_index: 0.0280 (0.0280)  loss: 0.0109 (0.0109)\n","[09:38:55.766004] Val loss improved from 0.010995234362781048 to 0.01093610655516386, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:55.821288] [Val] best loss: 0.0109 best  jaccard_index: 0.0280 \n","[09:38:55.822731] Creating training plots . . .\n","[09:38:56.116074] [Time] 3.3s 7.4m/9.1m\n","\n","[09:38:56.116129] ~~~ Epoch 71/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:57.042829] Epoch: [71]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0640 (0.0640)  loss: 0.0354 (0.0354)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9238  max mem: 4442MB\n","[09:38:58.624432] Epoch: [71]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0493 (0.0508)  loss: 0.0433 (0.0458)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8346  max mem: 4442MB\n","[09:38:58.680361] Epoch: [71] Total time: 0:00:02 (0.8545 s / it)\n","[09:38:58.680672] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0493 (0.0508)  loss: 0.0433 (0.0458)  weight_decay: 0.0500 (0.0500)\n","[09:38:58.847685] Epoch: [71]  [0/1]  eta: 0:00:00  jaccard_index: 0.0258 (0.0258)  loss: 0.0109 (0.0109)  iter-time: 0.1652  max mem: 4442MB\n","[09:38:58.910077] Epoch: [71] Total time: 0:00:00 (0.2283 s / it)\n","[09:38:58.910128] [Val] averaged stats: jaccard_index: 0.0258 (0.0258)  loss: 0.0109 (0.0109)\n","[09:38:58.910600] Val loss improved from 0.01093610655516386 to 0.010895242914557457, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:38:58.952475] [Val] best loss: 0.0109 best  jaccard_index: 0.0258 \n","[09:38:58.954067] [Time] 2.8s 7.4m/8.8m\n","\n","[09:38:58.954106] ~~~ Epoch 72/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:38:59.880927] Epoch: [72]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0660 (0.0660)  loss: 0.0354 (0.0354)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9239  max mem: 4442MB\n","[09:39:01.462989] Epoch: [72]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0501 (0.0536)  loss: 0.0431 (0.0457)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8349  max mem: 4442MB\n","[09:39:01.526135] Epoch: [72] Total time: 0:00:02 (0.8571 s / it)\n","[09:39:01.526259] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0501 (0.0536)  loss: 0.0431 (0.0457)  weight_decay: 0.0500 (0.0500)\n","[09:39:01.694604] Epoch: [72]  [0/1]  eta: 0:00:00  jaccard_index: 0.0323 (0.0323)  loss: 0.0109 (0.0109)  iter-time: 0.1663  max mem: 4442MB\n","[09:39:01.748161] Epoch: [72] Total time: 0:00:00 (0.2208 s / it)\n","[09:39:01.748216] [Val] averaged stats: jaccard_index: 0.0323 (0.0323)  loss: 0.0109 (0.0109)\n","[09:39:01.748605] [Val] best loss: 0.0109 best  jaccard_index: 0.0258 \n","EarlyStopping counter: 1 out of 20\n","[09:39:01.749978] [Time] 2.8s 7.5m/8.8m\n","\n","[09:39:01.750013] ~~~ Epoch 73/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:02.685809] Epoch: [73]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0621 (0.0621)  loss: 0.0352 (0.0352)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9278  max mem: 4442MB\n","[09:39:04.262402] Epoch: [73]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0559 (0.0540)  loss: 0.0430 (0.0455)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8343  max mem: 4442MB\n","[09:39:04.319006] Epoch: [73] Total time: 0:00:02 (0.8561 s / it)\n","[09:39:04.319119] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0559 (0.0540)  loss: 0.0430 (0.0455)  weight_decay: 0.0500 (0.0500)\n","[09:39:04.486947] Epoch: [73]  [0/1]  eta: 0:00:00  jaccard_index: 0.0337 (0.0337)  loss: 0.0108 (0.0108)  iter-time: 0.1658  max mem: 4442MB\n","[09:39:04.557252] Epoch: [73] Total time: 0:00:00 (0.2371 s / it)\n","[09:39:04.557558] [Val] averaged stats: jaccard_index: 0.0337 (0.0337)  loss: 0.0108 (0.0108)\n","[09:39:04.558175] Val loss improved from 0.010895242914557457 to 0.010839826427400112, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:04.597802] [Val] best loss: 0.0108 best  jaccard_index: 0.0337 \n","[09:39:04.599330] [Time] 2.8s 7.5m/8.9m\n","\n","[09:39:04.599406] ~~~ Epoch 74/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:05.538022] Epoch: [74]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0793 (0.0793)  loss: 0.0352 (0.0352)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9356  max mem: 4442MB\n","[09:39:07.125138] Epoch: [74]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0485 (0.0569)  loss: 0.0430 (0.0455)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8403  max mem: 4442MB\n","[09:39:07.234934] Epoch: [74] Total time: 0:00:02 (0.8782 s / it)\n","[09:39:07.235259] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0485 (0.0569)  loss: 0.0430 (0.0455)  weight_decay: 0.0500 (0.0500)\n","[09:39:07.433097] Epoch: [74]  [0/1]  eta: 0:00:00  jaccard_index: 0.0320 (0.0320)  loss: 0.0108 (0.0108)  iter-time: 0.1951  max mem: 4442MB\n","[09:39:07.535939] Epoch: [74] Total time: 0:00:00 (0.2991 s / it)\n","[09:39:07.536229] [Val] averaged stats: jaccard_index: 0.0320 (0.0320)  loss: 0.0108 (0.0108)\n","[09:39:07.536796] Val loss improved from 0.010839826427400112 to 0.01080339401960373, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:07.596962] [Val] best loss: 0.0108 best  jaccard_index: 0.0320 \n","[09:39:07.598869] [Time] 3.0s 7.6m/8.9m\n","\n","[09:39:07.598909] ~~~ Epoch 75/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:08.585194] Epoch: [75]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0734 (0.0734)  loss: 0.0349 (0.0349)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9825  max mem: 4442MB\n","[09:39:10.168264] Epoch: [75]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0572 (0.0610)  loss: 0.0428 (0.0452)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8547  max mem: 4442MB\n","[09:39:10.228307] Epoch: [75] Total time: 0:00:02 (0.8761 s / it)\n","[09:39:10.228675] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0572 (0.0610)  loss: 0.0428 (0.0452)  weight_decay: 0.0500 (0.0500)\n","[09:39:10.397771] Epoch: [75]  [0/1]  eta: 0:00:00  jaccard_index: 0.0342 (0.0342)  loss: 0.0108 (0.0108)  iter-time: 0.1669  max mem: 4442MB\n","[09:39:10.458189] Epoch: [75] Total time: 0:00:00 (0.2284 s / it)\n","[09:39:10.458450] [Val] averaged stats: jaccard_index: 0.0342 (0.0342)  loss: 0.0108 (0.0108)\n","[09:39:10.459023] [Val] best loss: 0.0108 best  jaccard_index: 0.0320 \n","[09:39:10.460428] Creating training plots . . .\n","EarlyStopping counter: 1 out of 20\n","[09:39:10.971353] [Time] 3.4s 7.6m/9.1m\n","\n","[09:39:10.971400] ~~~ Epoch 76/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:11.922191] Epoch: [76]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0733 (0.0733)  loss: 0.0349 (0.0349)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9476  max mem: 4442MB\n","[09:39:13.507242] Epoch: [76]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0589 (0.0581)  loss: 0.0426 (0.0451)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8437  max mem: 4442MB\n","[09:39:13.565250] Epoch: [76] Total time: 0:00:02 (0.8643 s / it)\n","[09:39:13.565357] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0589 (0.0581)  loss: 0.0426 (0.0451)  weight_decay: 0.0500 (0.0500)\n","[09:39:13.733086] Epoch: [76]  [0/1]  eta: 0:00:00  jaccard_index: 0.0272 (0.0272)  loss: 0.0107 (0.0107)  iter-time: 0.1658  max mem: 4442MB\n","[09:39:13.793093] Epoch: [76] Total time: 0:00:00 (0.2267 s / it)\n","[09:39:13.793293] [Val] averaged stats: jaccard_index: 0.0272 (0.0272)  loss: 0.0107 (0.0107)\n","[09:39:13.793907] Val loss improved from 0.01080339401960373 to 0.010729318484663963, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:13.842000] [Val] best loss: 0.0107 best  jaccard_index: 0.0272 \n","[09:39:13.843535] [Time] 2.9s 7.7m/8.9m\n","\n","[09:39:13.843574] ~~~ Epoch 77/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:14.803779] Epoch: [77]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0900 (0.0900)  loss: 0.0349 (0.0349)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9574  max mem: 4442MB\n","[09:39:16.389738] Epoch: [77]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0513 (0.0625)  loss: 0.0427 (0.0450)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8473  max mem: 4442MB\n","[09:39:16.447361] Epoch: [77] Total time: 0:00:02 (0.8677 s / it)\n","[09:39:16.447580] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0513 (0.0625)  loss: 0.0427 (0.0450)  weight_decay: 0.0500 (0.0500)\n","[09:39:16.618443] Epoch: [77]  [0/1]  eta: 0:00:00  jaccard_index: 0.0311 (0.0311)  loss: 0.0108 (0.0108)  iter-time: 0.1689  max mem: 4442MB\n","[09:39:16.678313] Epoch: [77] Total time: 0:00:00 (0.2296 s / it)\n","[09:39:16.678617] [Val] averaged stats: jaccard_index: 0.0311 (0.0311)  loss: 0.0108 (0.0108)\n","[09:39:16.679059] [Val] best loss: 0.0107 best  jaccard_index: 0.0272 \n","EarlyStopping counter: 1 out of 20\n","[09:39:16.680432] [Time] 2.8s 7.7m/8.9m\n","\n","[09:39:16.680464] ~~~ Epoch 78/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:17.619653] Epoch: [78]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0698 (0.0698)  loss: 0.0347 (0.0347)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9365  max mem: 4442MB\n","[09:39:19.204508] Epoch: [78]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0665 (0.0660)  loss: 0.0425 (0.0449)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8399  max mem: 4442MB\n","[09:39:19.291951] Epoch: [78] Total time: 0:00:02 (0.8702 s / it)\n","[09:39:19.292082] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0665 (0.0660)  loss: 0.0425 (0.0449)  weight_decay: 0.0500 (0.0500)\n","[09:39:19.485059] Epoch: [78]  [0/1]  eta: 0:00:00  jaccard_index: 0.0392 (0.0392)  loss: 0.0108 (0.0108)  iter-time: 0.1901  max mem: 4442MB\n","[09:39:19.569750] Epoch: [78] Total time: 0:00:00 (0.2761 s / it)\n","[09:39:19.569817] [Val] averaged stats: jaccard_index: 0.0392 (0.0392)  loss: 0.0108 (0.0108)\n","[09:39:19.570273] [Val] best loss: 0.0107 best  jaccard_index: 0.0272 \n","EarlyStopping counter: 2 out of 20\n","[09:39:19.571628] [Time] 2.9s 7.8m/8.9m\n","\n","[09:39:19.571655] ~~~ Epoch 79/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:20.549975] Epoch: [79]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0756 (0.0756)  loss: 0.0345 (0.0345)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9750  max mem: 4442MB\n","[09:39:22.126145] Epoch: [79]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0676 (0.0616)  loss: 0.0424 (0.0449)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8498  max mem: 4442MB\n","[09:39:22.232515] Epoch: [79] Total time: 0:00:02 (0.8866 s / it)\n","[09:39:22.232645] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0676 (0.0616)  loss: 0.0424 (0.0449)  weight_decay: 0.0500 (0.0500)\n","[09:39:22.426769] Epoch: [79]  [0/1]  eta: 0:00:00  jaccard_index: 0.0316 (0.0316)  loss: 0.0106 (0.0106)  iter-time: 0.1914  max mem: 4442MB\n","[09:39:22.504145] Epoch: [79] Total time: 0:00:00 (0.2700 s / it)\n","[09:39:22.504447] [Val] averaged stats: jaccard_index: 0.0316 (0.0316)  loss: 0.0106 (0.0106)\n","[09:39:22.505271] Val loss improved from 0.010729318484663963 to 0.010602904483675957, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:22.554178] [Val] best loss: 0.0106 best  jaccard_index: 0.0316 \n","[09:39:22.555772] [Time] 3.0s 7.8m/8.9m\n","\n","[09:39:22.555817] ~~~ Epoch 80/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:23.493796] Epoch: [80]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1035 (0.1035)  loss: 0.0346 (0.0346)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9352  max mem: 4442MB\n","[09:39:25.078729] Epoch: [80]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0569 (0.0680)  loss: 0.0425 (0.0448)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8395  max mem: 4442MB\n","[09:39:25.149642] Epoch: [80] Total time: 0:00:02 (0.8644 s / it)\n","[09:39:25.149754] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0569 (0.0680)  loss: 0.0425 (0.0448)  weight_decay: 0.0500 (0.0500)\n","[09:39:25.318981] Epoch: [80]  [0/1]  eta: 0:00:00  jaccard_index: 0.0360 (0.0360)  loss: 0.0107 (0.0107)  iter-time: 0.1671  max mem: 4442MB\n","[09:39:25.372649] Epoch: [80] Total time: 0:00:00 (0.2217 s / it)\n","[09:39:25.372703] [Val] averaged stats: jaccard_index: 0.0360 (0.0360)  loss: 0.0107 (0.0107)\n","[09:39:25.373066] [Val] best loss: 0.0106 best  jaccard_index: 0.0316 \n","[09:39:25.374352] Creating training plots . . .\n","EarlyStopping counter: 1 out of 20\n","[09:39:25.681637] [Time] 3.1s 7.9m/9.0m\n","\n","[09:39:25.681673] ~~~ Epoch 81/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:26.614140] Epoch: [81]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0672 (0.0672)  loss: 0.0344 (0.0344)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9297  max mem: 4442MB\n","[09:39:28.196044] Epoch: [81]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0790 (0.0760)  loss: 0.0422 (0.0446)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8367  max mem: 4442MB\n","[09:39:28.252867] Epoch: [81] Total time: 0:00:02 (0.8568 s / it)\n","[09:39:28.252982] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0790 (0.0760)  loss: 0.0422 (0.0446)  weight_decay: 0.0500 (0.0500)\n","[09:39:28.421590] Epoch: [81]  [0/1]  eta: 0:00:00  jaccard_index: 0.0483 (0.0483)  loss: 0.0107 (0.0107)  iter-time: 0.1667  max mem: 4442MB\n","[09:39:28.474309] Epoch: [81] Total time: 0:00:00 (0.2202 s / it)\n","[09:39:28.474493] [Val] averaged stats: jaccard_index: 0.0483 (0.0483)  loss: 0.0107 (0.0107)\n","[09:39:28.474972] [Val] best loss: 0.0106 best  jaccard_index: 0.0316 \n","EarlyStopping counter: 2 out of 20\n","[09:39:28.476273] [Time] 2.8s 7.9m/8.9m\n","\n","[09:39:28.476303] ~~~ Epoch 82/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:29.410661] Epoch: [82]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0727 (0.0727)  loss: 0.0343 (0.0343)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9316  max mem: 4442MB\n","[09:39:30.994366] Epoch: [82]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0727 (0.0631)  loss: 0.0421 (0.0446)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8379  max mem: 4442MB\n","[09:39:31.052884] Epoch: [82] Total time: 0:00:02 (0.8586 s / it)\n","[09:39:31.053103] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0727 (0.0631)  loss: 0.0421 (0.0446)  weight_decay: 0.0500 (0.0500)\n","[09:39:31.225563] Epoch: [82]  [0/1]  eta: 0:00:00  jaccard_index: 0.0383 (0.0383)  loss: 0.0105 (0.0105)  iter-time: 0.1700  max mem: 4442MB\n","[09:39:31.287660] Epoch: [82] Total time: 0:00:00 (0.2335 s / it)\n","[09:39:31.287718] [Val] averaged stats: jaccard_index: 0.0383 (0.0383)  loss: 0.0105 (0.0105)\n","[09:39:31.288179] Val loss improved from 0.010602904483675957 to 0.01049362774938345, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:31.328736] [Val] best loss: 0.0105 best  jaccard_index: 0.0383 \n","[09:39:31.330244] [Time] 2.9s 8.0m/8.9m\n","\n","[09:39:31.330288] ~~~ Epoch 83/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:32.266370] Epoch: [83]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1093 (0.1093)  loss: 0.0345 (0.0345)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9333  max mem: 4442MB\n","[09:39:33.852762] Epoch: [83]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0648 (0.0768)  loss: 0.0420 (0.0444)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8393  max mem: 4442MB\n","[09:39:33.936194] Epoch: [83] Total time: 0:00:02 (0.8684 s / it)\n","[09:39:33.936560] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0648 (0.0768)  loss: 0.0420 (0.0444)  weight_decay: 0.0500 (0.0500)\n","[09:39:34.134572] Epoch: [83]  [0/1]  eta: 0:00:00  jaccard_index: 0.0352 (0.0352)  loss: 0.0106 (0.0106)  iter-time: 0.1953  max mem: 4442MB\n","[09:39:34.233325] Epoch: [83] Total time: 0:00:00 (0.2953 s / it)\n","[09:39:34.233615] [Val] averaged stats: jaccard_index: 0.0352 (0.0352)  loss: 0.0106 (0.0106)\n","[09:39:34.234069] [Val] best loss: 0.0105 best  jaccard_index: 0.0383 \n","EarlyStopping counter: 1 out of 20\n","[09:39:34.235338] [Time] 2.9s 8.0m/8.9m\n","\n","[09:39:34.235367] ~~~ Epoch 84/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:35.262959] Epoch: [84]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0800 (0.0800)  loss: 0.0340 (0.0340)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0241  max mem: 4442MB\n","[09:39:36.848807] Epoch: [84]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0706 (0.0718)  loss: 0.0419 (0.0442)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8694  max mem: 4442MB\n","[09:39:36.904910] Epoch: [84] Total time: 0:00:02 (0.8895 s / it)\n","[09:39:36.905021] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0706 (0.0718)  loss: 0.0419 (0.0442)  weight_decay: 0.0500 (0.0500)\n","[09:39:37.075062] Epoch: [84]  [0/1]  eta: 0:00:00  jaccard_index: 0.0317 (0.0317)  loss: 0.0106 (0.0106)  iter-time: 0.1679  max mem: 4442MB\n","[09:39:37.135920] Epoch: [84] Total time: 0:00:00 (0.2297 s / it)\n","[09:39:37.135974] [Val] averaged stats: jaccard_index: 0.0317 (0.0317)  loss: 0.0106 (0.0106)\n","[09:39:37.136321] [Val] best loss: 0.0105 best  jaccard_index: 0.0383 \n","EarlyStopping counter: 2 out of 20\n","[09:39:37.137637] [Time] 2.9s 8.1m/8.9m\n","\n","[09:39:37.137669] ~~~ Epoch 85/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:38.062306] Epoch: [85]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0741 (0.0741)  loss: 0.0340 (0.0340)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9221  max mem: 4442MB\n","[09:39:39.647416] Epoch: [85]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0747 (0.0745)  loss: 0.0418 (0.0441)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8352  max mem: 4442MB\n","[09:39:39.703894] Epoch: [85] Total time: 0:00:02 (0.8552 s / it)\n","[09:39:39.704184] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0747 (0.0745)  loss: 0.0418 (0.0441)  weight_decay: 0.0500 (0.0500)\n","[09:39:39.876393] Epoch: [85]  [0/1]  eta: 0:00:00  jaccard_index: 0.0445 (0.0445)  loss: 0.0106 (0.0106)  iter-time: 0.1702  max mem: 4442MB\n","[09:39:39.929663] Epoch: [85] Total time: 0:00:00 (0.2243 s / it)\n","[09:39:39.929725] [Val] averaged stats: jaccard_index: 0.0445 (0.0445)  loss: 0.0106 (0.0106)\n","[09:39:39.930133] [Val] best loss: 0.0105 best  jaccard_index: 0.0383 \n","[09:39:39.932115] Creating training plots . . .\n","EarlyStopping counter: 3 out of 20\n","[09:39:40.239133] [Time] 3.1s 8.1m/8.9m\n","\n","[09:39:40.239173] ~~~ Epoch 86/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:41.171927] Epoch: [86]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0873 (0.0873)  loss: 0.0338 (0.0338)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9296  max mem: 4442MB\n","[09:39:42.753091] Epoch: [86]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0807 (0.0748)  loss: 0.0416 (0.0439)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8364  max mem: 4442MB\n","[09:39:42.811141] Epoch: [86] Total time: 0:00:02 (0.8570 s / it)\n","[09:39:42.811256] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0807 (0.0748)  loss: 0.0416 (0.0439)  weight_decay: 0.0500 (0.0500)\n","[09:39:42.978404] Epoch: [86]  [0/1]  eta: 0:00:00  jaccard_index: 0.0458 (0.0458)  loss: 0.0105 (0.0105)  iter-time: 0.1644  max mem: 4442MB\n","[09:39:43.032396] Epoch: [86] Total time: 0:00:00 (0.2193 s / it)\n","[09:39:43.032448] [Val] averaged stats: jaccard_index: 0.0458 (0.0458)  loss: 0.0105 (0.0105)\n","[09:39:43.032810] Val loss improved from 0.01049362774938345 to 0.010491534136235714, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:43.078086] [Val] best loss: 0.0105 best  jaccard_index: 0.0458 \n","[09:39:43.079460] [Time] 2.8s 8.2m/8.9m\n","\n","[09:39:43.079515] ~~~ Epoch 87/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:44.018842] Epoch: [87]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0996 (0.0996)  loss: 0.0339 (0.0339)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9366  max mem: 4442MB\n","[09:39:45.600802] Epoch: [87]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0721 (0.0767)  loss: 0.0417 (0.0439)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8389  max mem: 4442MB\n","[09:39:45.657914] Epoch: [87] Total time: 0:00:02 (0.8592 s / it)\n","[09:39:45.658087] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0721 (0.0767)  loss: 0.0417 (0.0439)  weight_decay: 0.0500 (0.0500)\n","[09:39:45.829060] Epoch: [87]  [0/1]  eta: 0:00:00  jaccard_index: 0.0391 (0.0391)  loss: 0.0105 (0.0105)  iter-time: 0.1688  max mem: 4442MB\n","[09:39:45.894979] Epoch: [87] Total time: 0:00:00 (0.2358 s / it)\n","[09:39:45.895034] [Val] averaged stats: jaccard_index: 0.0391 (0.0391)  loss: 0.0105 (0.0105)\n","[09:39:45.895440] [Val] best loss: 0.0105 best  jaccard_index: 0.0458 \n","EarlyStopping counter: 1 out of 20\n","[09:39:45.897015] [Time] 2.8s 8.2m/8.9m\n","\n","[09:39:45.897048] ~~~ Epoch 88/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:46.907211] Epoch: [88]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0930 (0.0930)  loss: 0.0336 (0.0336)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0073  max mem: 4442MB\n","[09:39:48.495913] Epoch: [88]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0754 (0.0801)  loss: 0.0414 (0.0436)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8647  max mem: 4442MB\n","[09:39:48.584825] Epoch: [88] Total time: 0:00:02 (0.8957 s / it)\n","[09:39:48.585187] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0754 (0.0801)  loss: 0.0414 (0.0436)  weight_decay: 0.0500 (0.0500)\n","[09:39:48.788105] Epoch: [88]  [0/1]  eta: 0:00:00  jaccard_index: 0.0364 (0.0364)  loss: 0.0105 (0.0105)  iter-time: 0.2000  max mem: 4442MB\n","[09:39:48.875800] Epoch: [88] Total time: 0:00:00 (0.2890 s / it)\n","[09:39:48.876070] [Val] averaged stats: jaccard_index: 0.0364 (0.0364)  loss: 0.0105 (0.0105)\n","[09:39:48.876702] Val loss improved from 0.010491534136235714 to 0.010481474921107292, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:48.938851] [Val] best loss: 0.0105 best  jaccard_index: 0.0364 \n","[09:39:48.940517] [Time] 3.0s 8.3m/8.9m\n","\n","[09:39:48.940571] ~~~ Epoch 89/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:49.950274] Epoch: [89]  [0/3]  eta: 0:00:03  lr: 0.000100  jaccard_index: 0.0817 (0.0817)  loss: 0.0337 (0.0337)  weight_decay: 0.0500 (0.0500)  iter-time: 1.0064  max mem: 4442MB\n","[09:39:51.531077] Epoch: [89]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0811 (0.0794)  loss: 0.0413 (0.0436)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8618  max mem: 4442MB\n","[09:39:51.588827] Epoch: [89] Total time: 0:00:02 (0.8824 s / it)\n","[09:39:51.589037] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0811 (0.0794)  loss: 0.0413 (0.0436)  weight_decay: 0.0500 (0.0500)\n","[09:39:51.767702] Epoch: [89]  [0/1]  eta: 0:00:00  jaccard_index: 0.0467 (0.0467)  loss: 0.0105 (0.0105)  iter-time: 0.1766  max mem: 4442MB\n","[09:39:51.827650] Epoch: [89] Total time: 0:00:00 (0.2375 s / it)\n","[09:39:51.827814] [Val] averaged stats: jaccard_index: 0.0467 (0.0467)  loss: 0.0105 (0.0105)\n","[09:39:51.828284] Val loss improved from 0.010481474921107292 to 0.010479621589183807, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:51.869993] [Val] best loss: 0.0105 best  jaccard_index: 0.0467 \n","[09:39:51.871575] [Time] 2.9s 8.3m/8.9m\n","\n","[09:39:51.871617] ~~~ Epoch 90/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:52.803102] Epoch: [90]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0865 (0.0865)  loss: 0.0335 (0.0335)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9286  max mem: 4442MB\n","[09:39:54.388027] Epoch: [90]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0865 (0.0810)  loss: 0.0414 (0.0435)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8373  max mem: 4442MB\n","[09:39:54.445537] Epoch: [90] Total time: 0:00:02 (0.8577 s / it)\n","[09:39:54.445758] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0865 (0.0810)  loss: 0.0414 (0.0435)  weight_decay: 0.0500 (0.0500)\n","[09:39:54.613926] Epoch: [90]  [0/1]  eta: 0:00:00  jaccard_index: 0.0465 (0.0465)  loss: 0.0104 (0.0104)  iter-time: 0.1661  max mem: 4442MB\n","[09:39:54.675194] Epoch: [90] Total time: 0:00:00 (0.2283 s / it)\n","[09:39:54.675512] [Val] averaged stats: jaccard_index: 0.0465 (0.0465)  loss: 0.0104 (0.0104)\n","[09:39:54.675975] Val loss improved from 0.010479621589183807 to 0.010433336719870567, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:54.718973] [Val] best loss: 0.0104 best  jaccard_index: 0.0465 \n","[09:39:54.720006] Creating training plots . . .\n","[09:39:55.014654] [Time] 3.1s 8.4m/8.9m\n","\n","[09:39:55.014700] ~~~ Epoch 91/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:55.942903] Epoch: [91]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1054 (0.1054)  loss: 0.0335 (0.0335)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9254  max mem: 4442MB\n","[09:39:57.524927] Epoch: [91]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0748 (0.0818)  loss: 0.0412 (0.0434)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8352  max mem: 4442MB\n","[09:39:57.581259] Epoch: [91] Total time: 0:00:02 (0.8553 s / it)\n","[09:39:57.581624] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0748 (0.0818)  loss: 0.0412 (0.0434)  weight_decay: 0.0500 (0.0500)\n","[09:39:57.750517] Epoch: [91]  [0/1]  eta: 0:00:00  jaccard_index: 0.0430 (0.0430)  loss: 0.0104 (0.0104)  iter-time: 0.1669  max mem: 4442MB\n","[09:39:57.813525] Epoch: [91] Total time: 0:00:00 (0.2308 s / it)\n","[09:39:57.813937] [Val] averaged stats: jaccard_index: 0.0430 (0.0430)  loss: 0.0104 (0.0104)\n","[09:39:57.814386] Val loss improved from 0.010433336719870567 to 0.010433102957904339, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:39:57.859260] [Val] best loss: 0.0104 best  jaccard_index: 0.0430 \n","[09:39:57.860822] [Time] 2.8s 8.4m/8.9m\n","\n","[09:39:57.860849] ~~~ Epoch 92/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:39:58.795243] Epoch: [92]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1018 (0.1018)  loss: 0.0334 (0.0334)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9318  max mem: 4442MB\n","[09:40:00.379542] Epoch: [92]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0878 (0.0894)  loss: 0.0411 (0.0433)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8381  max mem: 4442MB\n","[09:40:00.466192] Epoch: [92] Total time: 0:00:02 (0.8682 s / it)\n","[09:40:00.466312] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0878 (0.0894)  loss: 0.0411 (0.0433)  weight_decay: 0.0500 (0.0500)\n","[09:40:00.666206] Epoch: [92]  [0/1]  eta: 0:00:00  jaccard_index: 0.0485 (0.0485)  loss: 0.0105 (0.0105)  iter-time: 0.1972  max mem: 4442MB\n","[09:40:00.753853] Epoch: [92] Total time: 0:00:00 (0.2860 s / it)\n","[09:40:00.754095] [Val] averaged stats: jaccard_index: 0.0485 (0.0485)  loss: 0.0105 (0.0105)\n","[09:40:00.754516] [Val] best loss: 0.0104 best  jaccard_index: 0.0430 \n","EarlyStopping counter: 1 out of 20\n","[09:40:00.755850] [Time] 2.9s 8.5m/8.9m\n","\n","[09:40:00.755887] ~~~ Epoch 93/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:01.757988] Epoch: [93]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0873 (0.0873)  loss: 0.0332 (0.0332)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9986  max mem: 4442MB\n","[09:40:03.339628] Epoch: [93]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0873 (0.0880)  loss: 0.0410 (0.0431)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8595  max mem: 4442MB\n","[09:40:03.401539] Epoch: [93] Total time: 0:00:02 (0.8816 s / it)\n","[09:40:03.401736] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0873 (0.0880)  loss: 0.0410 (0.0431)  weight_decay: 0.0500 (0.0500)\n","[09:40:03.572065] Epoch: [93]  [0/1]  eta: 0:00:00  jaccard_index: 0.0522 (0.0522)  loss: 0.0104 (0.0104)  iter-time: 0.1682  max mem: 4442MB\n","[09:40:03.630511] Epoch: [93] Total time: 0:00:00 (0.2276 s / it)\n","[09:40:03.630576] [Val] averaged stats: jaccard_index: 0.0522 (0.0522)  loss: 0.0104 (0.0104)\n","[09:40:03.631362] Val loss improved from 0.010433102957904339 to 0.010424865409731865, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:40:03.671530] [Val] best loss: 0.0104 best  jaccard_index: 0.0522 \n","[09:40:03.673140] [Time] 2.9s 8.5m/8.9m\n","\n","[09:40:03.673179] ~~~ Epoch 94/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:04.615251] Epoch: [94]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1022 (0.1022)  loss: 0.0331 (0.0331)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9392  max mem: 4442MB\n","[09:40:06.194208] Epoch: [94]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0819 (0.0840)  loss: 0.0409 (0.0430)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8389  max mem: 4442MB\n","[09:40:06.254412] Epoch: [94] Total time: 0:00:02 (0.8602 s / it)\n","[09:40:06.254771] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0819 (0.0840)  loss: 0.0409 (0.0430)  weight_decay: 0.0500 (0.0500)\n","[09:40:06.423336] Epoch: [94]  [0/1]  eta: 0:00:00  jaccard_index: 0.0468 (0.0468)  loss: 0.0104 (0.0104)  iter-time: 0.1666  max mem: 4442MB\n","[09:40:06.482701] Epoch: [94] Total time: 0:00:00 (0.2268 s / it)\n","[09:40:06.482921] [Val] averaged stats: jaccard_index: 0.0468 (0.0468)  loss: 0.0104 (0.0104)\n","[09:40:06.483517] Val loss improved from 0.010424865409731865 to 0.010362425819039345, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:40:06.523303] [Val] best loss: 0.0104 best  jaccard_index: 0.0468 \n","[09:40:06.524851] [Time] 2.9s 8.6m/8.9m\n","\n","[09:40:06.524888] ~~~ Epoch 95/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:07.448834] Epoch: [95]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1038 (0.1038)  loss: 0.0331 (0.0331)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9210  max mem: 4442MB\n","[09:40:09.033309] Epoch: [95]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0960 (0.0927)  loss: 0.0410 (0.0430)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8346  max mem: 4442MB\n","[09:40:09.092895] Epoch: [95] Total time: 0:00:02 (0.8558 s / it)\n","[09:40:09.093133] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0960 (0.0927)  loss: 0.0410 (0.0430)  weight_decay: 0.0500 (0.0500)\n","[09:40:09.282042] Epoch: [95]  [0/1]  eta: 0:00:00  jaccard_index: 0.0491 (0.0491)  loss: 0.0104 (0.0104)  iter-time: 0.1866  max mem: 4442MB\n","[09:40:09.339194] Epoch: [95] Total time: 0:00:00 (0.2448 s / it)\n","[09:40:09.339479] [Val] averaged stats: jaccard_index: 0.0491 (0.0491)  loss: 0.0104 (0.0104)\n","[09:40:09.339840] [Val] best loss: 0.0104 best  jaccard_index: 0.0468 \n","[09:40:09.341137] Creating training plots . . .\n","EarlyStopping counter: 1 out of 20\n","[09:40:09.622106] [Time] 3.1s 8.6m/8.9m\n","\n","[09:40:09.622144] ~~~ Epoch 96/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:10.564538] Epoch: [96]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0937 (0.0937)  loss: 0.0331 (0.0331)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9395  max mem: 4442MB\n","[09:40:12.152394] Epoch: [96]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0937 (0.0939)  loss: 0.0407 (0.0429)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8419  max mem: 4442MB\n","[09:40:12.222433] Epoch: [96] Total time: 0:00:02 (0.8665 s / it)\n","[09:40:12.222675] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0937 (0.0939)  loss: 0.0407 (0.0429)  weight_decay: 0.0500 (0.0500)\n","[09:40:12.388001] Epoch: [96]  [0/1]  eta: 0:00:00  jaccard_index: 0.0503 (0.0503)  loss: 0.0103 (0.0103)  iter-time: 0.1634  max mem: 4442MB\n","[09:40:12.443159] Epoch: [96] Total time: 0:00:00 (0.2194 s / it)\n","[09:40:12.443218] [Val] averaged stats: jaccard_index: 0.0503 (0.0503)  loss: 0.0103 (0.0103)\n","[09:40:12.443721] Val loss improved from 0.010362425819039345 to 0.010322360321879387, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:40:12.489030] [Val] best loss: 0.0103 best  jaccard_index: 0.0503 \n","[09:40:12.490593] [Time] 2.9s 8.7m/8.9m\n","\n","[09:40:12.490633] ~~~ Epoch 97/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:13.428768] Epoch: [97]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0966 (0.0966)  loss: 0.0330 (0.0330)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9353  max mem: 4442MB\n","[09:40:15.012789] Epoch: [97]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0910 (0.0859)  loss: 0.0406 (0.0428)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8392  max mem: 4442MB\n","[09:40:15.104982] Epoch: [97] Total time: 0:00:02 (0.8712 s / it)\n","[09:40:15.105124] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0910 (0.0859)  loss: 0.0406 (0.0428)  weight_decay: 0.0500 (0.0500)\n","[09:40:15.312202] Epoch: [97]  [0/1]  eta: 0:00:00  jaccard_index: 0.0436 (0.0436)  loss: 0.0103 (0.0103)  iter-time: 0.2040  max mem: 4442MB\n","[09:40:15.405498] Epoch: [97] Total time: 0:00:00 (0.2987 s / it)\n","[09:40:15.405823] [Val] averaged stats: jaccard_index: 0.0436 (0.0436)  loss: 0.0103 (0.0103)\n","[09:40:15.406426] Val loss improved from 0.010322360321879387 to 0.010272644460201263, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:40:15.471425] [Val] best loss: 0.0103 best  jaccard_index: 0.0436 \n","[09:40:15.472368] [Time] 3.0s 8.7m/8.9m\n","\n","[09:40:15.472416] ~~~ Epoch 98/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:16.451712] Epoch: [98]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1140 (0.1140)  loss: 0.0329 (0.0329)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9761  max mem: 4442MB\n","[09:40:18.034990] Epoch: [98]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0930 (0.0943)  loss: 0.0406 (0.0426)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8525  max mem: 4442MB\n","[09:40:18.092870] Epoch: [98] Total time: 0:00:02 (0.8731 s / it)\n","[09:40:18.093062] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0930 (0.0943)  loss: 0.0406 (0.0426)  weight_decay: 0.0500 (0.0500)\n","[09:40:18.261643] Epoch: [98]  [0/1]  eta: 0:00:00  jaccard_index: 0.0511 (0.0511)  loss: 0.0103 (0.0103)  iter-time: 0.1665  max mem: 4442MB\n","[09:40:18.321624] Epoch: [98] Total time: 0:00:00 (0.2275 s / it)\n","[09:40:18.321683] [Val] averaged stats: jaccard_index: 0.0511 (0.0511)  loss: 0.0103 (0.0103)\n","[09:40:18.322093] [Val] best loss: 0.0103 best  jaccard_index: 0.0436 \n","EarlyStopping counter: 1 out of 20\n","[09:40:18.323526] [Time] 2.9s 8.8m/8.9m\n","\n","[09:40:18.323563] ~~~ Epoch 99/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:19.269225] Epoch: [99]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.0940 (0.0940)  loss: 0.0327 (0.0327)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9429  max mem: 4442MB\n","[09:40:20.856935] Epoch: [99]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0980 (0.1002)  loss: 0.0405 (0.0425)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8431  max mem: 4442MB\n","[09:40:20.917273] Epoch: [99] Total time: 0:00:02 (0.8643 s / it)\n","[09:40:20.917554] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0980 (0.1002)  loss: 0.0405 (0.0425)  weight_decay: 0.0500 (0.0500)\n","[09:40:21.088212] Epoch: [99]  [0/1]  eta: 0:00:00  jaccard_index: 0.0627 (0.0627)  loss: 0.0103 (0.0103)  iter-time: 0.1685  max mem: 4442MB\n","[09:40:21.147780] Epoch: [99] Total time: 0:00:00 (0.2290 s / it)\n","[09:40:21.147842] [Val] averaged stats: jaccard_index: 0.0627 (0.0627)  loss: 0.0103 (0.0103)\n","[09:40:21.148233] [Val] best loss: 0.0103 best  jaccard_index: 0.0436 \n","EarlyStopping counter: 2 out of 20\n","[09:40:21.149599] [Time] 2.8s 8.8m/8.9m\n","\n","[09:40:21.149632] ~~~ Epoch 100/100 ~~~\n","\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n","  ia.warn(\n","[09:40:22.084724] Epoch: [100]  [0/3]  eta: 0:00:02  lr: 0.000100  jaccard_index: 0.1088 (0.1088)  loss: 0.0327 (0.0327)  weight_decay: 0.0500 (0.0500)  iter-time: 0.9323  max mem: 4442MB\n","[09:40:23.670102] Epoch: [100]  [2/3]  eta: 0:00:00  lr: 0.000100  jaccard_index: 0.0961 (0.0928)  loss: 0.0403 (0.0424)  weight_decay: 0.0500 (0.0500)  iter-time: 0.8387  max mem: 4442MB\n","[09:40:23.727374] Epoch: [100] Total time: 0:00:02 (0.8590 s / it)\n","[09:40:23.727578] [Train] averaged stats: lr: 0.000100  jaccard_index: 0.0961 (0.0928)  loss: 0.0403 (0.0424)  weight_decay: 0.0500 (0.0500)\n","[09:40:23.894539] Epoch: [100]  [0/1]  eta: 0:00:00  jaccard_index: 0.0512 (0.0512)  loss: 0.0102 (0.0102)  iter-time: 0.1650  max mem: 4442MB\n","[09:40:23.955948] Epoch: [100] Total time: 0:00:00 (0.2273 s / it)\n","[09:40:23.956042] [Val] averaged stats: jaccard_index: 0.0512 (0.0512)  loss: 0.0102 (0.0102)\n","[09:40:23.956643] Val loss improved from 0.010272644460201263 to 0.010198673233389854, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:40:23.996963] [Val] best loss: 0.0102 best  jaccard_index: 0.0512 \n","[09:40:23.998418] Creating training plots . . .\n","[09:40:24.288241] [Time] 3.1s 8.9m/8.9m\n","\n","[09:40:24.288293] Training time 0:08:51\n","[09:40:24.288314] Train loss: 0.04241615658005079\n","[09:40:24.288337] Train jaccard_index: 0.09279615432024002\n","[09:40:24.288356] Val loss: 0.010198673233389854\n","[09:40:24.288641] Val jaccard_index: [0.05116894]\n","[09:40:24.288667] Finished Training\n","[09:40:24.288681] Releasing memory . . .\n","[09:40:24.288753] ######################\n","[09:40:24.288770] #   LOAD TEST DATA   #\n","[09:40:24.288781] ######################\n","[09:40:24.288807] 2) Loading test images . . .\n","[09:40:24.288841] Loading data from /content/data/test/x\n","100% 27/27 [00:00<00:00, 1222.17it/s]\n","[09:40:24.316105] *** Loaded data shape is (27, 64, 64, 64, 1)\n","[09:40:24.316169] 3) Loading test masks . . .\n","[09:40:24.316199] Loading data from /content/data/test/y_detection_masks\n","100% 27/27 [00:00<00:00, 1635.06it/s]\n","[09:40:24.335314] *** Loaded data shape is (27, 64, 64, 64, 1)\n","[09:40:24.335455] ############################\n","[09:40:24.335486] #  PREPARE TEST GENERATOR  #\n","[09:40:24.335504] ############################\n","[09:40:24.336839] Loading checkpoint from file /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:40:24.393600] Model weights loaded!\n","[09:40:24.394106] ###############\n","[09:40:24.394137] #  INFERENCE  #\n","[09:40:24.394152] ###############\n","[09:40:24.394166] Making predictions on test data . . .\n","  0% 0/27 [00:00<?, ?it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:24.395349] Processing image(s): ['vol_000.tif']\n","[09:40:24.395486] ### 3D-OV-CROP ###\n","[09:40:24.395513] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:24.395533] Minimum overlap selected: (0, 0, 0)\n","[09:40:24.395551] Padding: (8, 8, 8)\n","[09:40:24.396289] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:24.396326] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:24.396343] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:24.400707] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:24.400737] ### END 3D-OV-CROP ###\n","[09:40:24.400777] ### 3D-OV-CROP ###\n","[09:40:24.400797] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:24.400817] Minimum overlap selected: (0, 0, 0)\n","[09:40:24.400834] Padding: (8, 8, 8)\n","[09:40:24.401305] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:24.401340] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:24.401369] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:24.401809] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:24.401837] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:02<00:00,  2.04s/it]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  9.89it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A[09:40:26.564907] ### MERGE-3D-OV-CROP ###\n","[09:40:26.564973] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:26.564997] Minimum overlap selected: (0, 0, 0)\n","[09:40:26.565019] Padding: (8, 8, 8)\n","[09:40:26.565301] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:26.565327] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:26.565349] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:26.568063] **** New data shape is: (64, 64, 64, 1)\n","[09:40:26.568112] ### END MERGE-3D-OV-CROP ###\n","[09:40:26.568154] ### MERGE-3D-OV-CROP ###\n","[09:40:26.568179] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:26.568202] Minimum overlap selected: (0, 0, 0)\n","[09:40:26.568219] Padding: (8, 8, 8)\n","[09:40:26.568364] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:26.568389] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:26.568407] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:26.571509] **** New data shape is: (64, 64, 64, 1)\n","[09:40:26.571551] ### END MERGE-3D-OV-CROP ###\n","[09:40:26.571665] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:26.580143] Capturing the local maxima \n","[09:40:26.580197] Class 1\n","[09:40:26.596458] Removing close points . . .\n","[09:40:26.596509] Initial number of points: 42\n","[09:40:26.597396] Final number of points: 34\n","[09:40:26.597493] Creating the images with detected points . . .\n","[09:40:26.627526] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:26.658687] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:26.669674] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:26.669718] Its respective CSV file seems to be: /content/data/test/y/mask_000.csv\n","[09:40:26.669740] Reading GT data from: /content/data/test/y/mask_000.csv\n","[09:40:26.674434] Detection (class 1)\n","[09:40:26.678397] Points in ground truth: 61, Points in prediction: 34\n","[09:40:26.678442] True positives: 34, False positives: 0, False negatives: 27\n","[09:40:26.678493] Detection metrics: ['Precision', 1.0, 'Recall', 0.5573770491803278, 'F1', 0.7157894736842105]\n","[09:40:26.680730] All classes 1\n","[09:40:26.680787] Detection metrics: ['Precision', 1.0, 'Recall', 0.5573770491803278, 'F1', 0.7157894736842105]\n","[09:40:26.680819] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:26.741287] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:26.829723] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:02<00:00,  2.44s/it]\u001b[A\n","  4% 1/27 [00:02<01:03,  2.44s/it]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:26.834445] Processing image(s): ['vol_001.tif']\n","[09:40:26.834611] ### 3D-OV-CROP ###\n","[09:40:26.834643] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:26.834667] Minimum overlap selected: (0, 0, 0)\n","[09:40:26.834689] Padding: (8, 8, 8)\n","[09:40:26.835797] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:26.835842] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:26.835862] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:26.838264] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:26.838305] ### END 3D-OV-CROP ###\n","[09:40:26.838374] ### 3D-OV-CROP ###\n","[09:40:26.838402] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:26.838425] Minimum overlap selected: (0, 0, 0)\n","[09:40:26.838446] Padding: (8, 8, 8)\n","[09:40:26.839124] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:26.839166] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:26.839188] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:26.839861] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:26.839898] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.08it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:27.078756] ### MERGE-3D-OV-CROP ###\n","[09:40:27.078822] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:27.078845] Minimum overlap selected: (0, 0, 0)\n","[09:40:27.078865] Padding: (8, 8, 8)\n","[09:40:27.079174] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:27.079201] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:27.079222] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:27.082039] **** New data shape is: (64, 64, 64, 1)\n","[09:40:27.082086] ### END MERGE-3D-OV-CROP ###\n","[09:40:27.082133] ### MERGE-3D-OV-CROP ###\n","[09:40:27.082158] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:27.082179] Minimum overlap selected: (0, 0, 0)\n","[09:40:27.082199] Padding: (8, 8, 8)\n","[09:40:27.082314] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:27.082339] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:27.082369] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:27.085077] **** New data shape is: (64, 64, 64, 1)\n","[09:40:27.085119] ### END MERGE-3D-OV-CROP ###\n","[09:40:27.085222] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:27.093788] Capturing the local maxima \n","[09:40:27.093869] Class 1\n","[09:40:27.122226] Removing close points . . .\n","[09:40:27.122276] Initial number of points: 543\n","[09:40:27.132205] Final number of points: 471\n","[09:40:27.132352] Creating the images with detected points . . .\n","[09:40:27.163490] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:27.194430] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:27.214009] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:27.214055] Its respective CSV file seems to be: /content/data/test/y/mask_001.csv\n","[09:40:27.214077] Reading GT data from: /content/data/test/y/mask_001.csv\n","[09:40:27.217014] Detection (class 1)\n","[09:40:27.249864] Points in ground truth: 649, Points in prediction: 471\n","[09:40:27.249914] True positives: 471, False positives: 0, False negatives: 178\n","[09:40:27.249977] Detection metrics: ['Precision', 1.0, 'Recall', 0.7257318952234206, 'F1', 0.8410714285714286]\n","[09:40:27.257930] All classes 1\n","[09:40:27.257984] Detection metrics: ['Precision', 1.0, 'Recall', 0.7257318952234206, 'F1', 0.8410714285714286]\n","[09:40:27.258011] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:27.612082] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:27.710729] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.14it/s]\u001b[A\n","  7% 2/27 [00:03<00:38,  1.52s/it]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:27.715804] Processing image(s): ['vol_002.tif']\n","[09:40:27.715962] ### 3D-OV-CROP ###\n","[09:40:27.715999] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:27.716023] Minimum overlap selected: (0, 0, 0)\n","[09:40:27.716045] Padding: (8, 8, 8)\n","[09:40:27.717391] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:27.717445] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:27.717485] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:27.719712] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:27.719754] ### END 3D-OV-CROP ###\n","[09:40:27.719818] ### 3D-OV-CROP ###\n","[09:40:27.719848] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:27.719871] Minimum overlap selected: (0, 0, 0)\n","[09:40:27.719895] Padding: (8, 8, 8)\n","[09:40:27.720773] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:27.720823] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:27.720847] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:27.721525] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:27.721560] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.00it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:27.959219] ### MERGE-3D-OV-CROP ###\n","[09:40:27.959289] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:27.959312] Minimum overlap selected: (0, 0, 0)\n","[09:40:27.959332] Padding: (8, 8, 8)\n","[09:40:27.959651] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:27.959681] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:27.959702] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:27.962332] **** New data shape is: (64, 64, 64, 1)\n","[09:40:27.962390] ### END MERGE-3D-OV-CROP ###\n","[09:40:27.962437] ### MERGE-3D-OV-CROP ###\n","[09:40:27.962462] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:27.962496] Minimum overlap selected: (0, 0, 0)\n","[09:40:27.962516] Padding: (8, 8, 8)\n","[09:40:27.962625] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:27.962649] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:27.962670] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:27.965393] **** New data shape is: (64, 64, 64, 1)\n","[09:40:27.965445] ### END MERGE-3D-OV-CROP ###\n","[09:40:27.965589] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:27.973061] Capturing the local maxima \n","[09:40:27.973111] Class 1\n","[09:40:27.988189] Removing close points . . .\n","[09:40:27.988233] Initial number of points: 26\n","[09:40:27.988819] Final number of points: 20\n","[09:40:27.988882] Creating the images with detected points . . .\n","[09:40:28.016312] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.048062] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.054346] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:28.054409] Its respective CSV file seems to be: /content/data/test/y/mask_002.csv\n","[09:40:28.054431] Reading GT data from: /content/data/test/y/mask_002.csv\n","[09:40:28.056857] Detection (class 1)\n","[09:40:28.058695] Points in ground truth: 19, Points in prediction: 20\n","[09:40:28.058736] True positives: 15, False positives: 5, False negatives: 4\n","[09:40:28.058772] Detection metrics: ['Precision', 0.75, 'Recall', 0.7894736842105263, 'F1', 0.7692307692307692]\n","[09:40:28.060767] All classes 1\n","[09:40:28.060823] Detection metrics: ['Precision', 0.75, 'Recall', 0.7894736842105263, 'F1', 0.7692307692307692]\n","[09:40:28.060851] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:28.096684] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.184398] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.12it/s]\u001b[A\n"," 11% 3/27 [00:03<00:25,  1.04s/it]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:28.189233] Processing image(s): ['vol_003.tif']\n","[09:40:28.189374] ### 3D-OV-CROP ###\n","[09:40:28.189403] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:28.189425] Minimum overlap selected: (0, 0, 0)\n","[09:40:28.189446] Padding: (8, 8, 8)\n","[09:40:28.190448] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:28.190511] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:28.190536] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:28.193322] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:28.193380] ### END 3D-OV-CROP ###\n","[09:40:28.193453] ### 3D-OV-CROP ###\n","[09:40:28.193490] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:28.193515] Minimum overlap selected: (0, 0, 0)\n","[09:40:28.193536] Padding: (8, 8, 8)\n","[09:40:28.194323] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:28.194386] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:28.194410] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:28.195095] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:28.195134] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.09it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.433066] ### MERGE-3D-OV-CROP ###\n","[09:40:28.433187] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:28.433215] Minimum overlap selected: (0, 0, 0)\n","[09:40:28.433249] Padding: (8, 8, 8)\n","[09:40:28.433558] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:28.433587] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:28.433608] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:28.436439] **** New data shape is: (64, 64, 64, 1)\n","[09:40:28.436503] ### END MERGE-3D-OV-CROP ###\n","[09:40:28.436555] ### MERGE-3D-OV-CROP ###\n","[09:40:28.436581] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:28.436601] Minimum overlap selected: (0, 0, 0)\n","[09:40:28.436622] Padding: (8, 8, 8)\n","[09:40:28.436793] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:28.436818] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:28.436839] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:28.439755] **** New data shape is: (64, 64, 64, 1)\n","[09:40:28.439801] ### END MERGE-3D-OV-CROP ###\n","[09:40:28.439917] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.448026] Capturing the local maxima \n","[09:40:28.448077] Class 1\n","[09:40:28.474607] Removing close points . . .\n","[09:40:28.474659] Initial number of points: 452\n","[09:40:28.483555] Final number of points: 378\n","[09:40:28.483730] Creating the images with detected points . . .\n","[09:40:28.514963] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.548811] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.566198] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:28.566251] Its respective CSV file seems to be: /content/data/test/y/mask_003.csv\n","[09:40:28.566275] Reading GT data from: /content/data/test/y/mask_003.csv\n","[09:40:28.569362] Detection (class 1)\n","[09:40:28.592348] Points in ground truth: 501, Points in prediction: 378\n","[09:40:28.592415] True positives: 368, False positives: 10, False negatives: 133\n","[09:40:28.592486] Detection metrics: ['Precision', 0.9735449735449735, 'Recall', 0.7345309381237525, 'F1', 0.8373151308304893]\n","[09:40:28.599921] All classes 1\n","[09:40:28.599989] Detection metrics: ['Precision', 0.9735449735449735, 'Recall', 0.7345309381237525, 'F1', 0.8373151308304893]\n","[09:40:28.600028] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:28.876656] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:28.970961] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.27it/s]\u001b[A\n"," 15% 4/27 [00:04<00:21,  1.06it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:28.976051] Processing image(s): ['vol_004.tif']\n","[09:40:28.976184] ### 3D-OV-CROP ###\n","[09:40:28.976211] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:28.976233] Minimum overlap selected: (0, 0, 0)\n","[09:40:28.976253] Padding: (8, 8, 8)\n","[09:40:28.977453] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:28.977513] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:28.977536] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:28.979728] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:28.979765] ### END 3D-OV-CROP ###\n","[09:40:28.979820] ### 3D-OV-CROP ###\n","[09:40:28.979845] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:28.979864] Minimum overlap selected: (0, 0, 0)\n","[09:40:28.979884] Padding: (8, 8, 8)\n","[09:40:28.980638] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:28.980697] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:28.980721] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:28.981373] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:28.981409] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.05it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  9.92it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A[09:40:29.225611] ### MERGE-3D-OV-CROP ###\n","[09:40:29.225676] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:29.225700] Minimum overlap selected: (0, 0, 0)\n","[09:40:29.225721] Padding: (8, 8, 8)\n","[09:40:29.226039] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:29.226077] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:29.226096] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:29.229352] **** New data shape is: (64, 64, 64, 1)\n","[09:40:29.229398] ### END MERGE-3D-OV-CROP ###\n","[09:40:29.229447] ### MERGE-3D-OV-CROP ###\n","[09:40:29.229489] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:29.229510] Minimum overlap selected: (0, 0, 0)\n","[09:40:29.229529] Padding: (8, 8, 8)\n","[09:40:29.229654] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:29.229685] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:29.229701] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:29.232638] **** New data shape is: (64, 64, 64, 1)\n","[09:40:29.232682] ### END MERGE-3D-OV-CROP ###\n","[09:40:29.232788] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:29.240013] Capturing the local maxima \n","[09:40:29.240064] Class 1\n","[09:40:29.261709] Removing close points . . .\n","[09:40:29.261752] Initial number of points: 261\n","[09:40:29.266481] Final number of points: 195\n","[09:40:29.266618] Creating the images with detected points . . .\n","[09:40:29.301086] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:29.336522] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:29.348063] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:29.348118] Its respective CSV file seems to be: /content/data/test/y/mask_004.csv\n","[09:40:29.348140] Reading GT data from: /content/data/test/y/mask_004.csv\n","[09:40:29.351153] Detection (class 1)\n","[09:40:29.360512] Points in ground truth: 259, Points in prediction: 195\n","[09:40:29.360552] True positives: 192, False positives: 3, False negatives: 67\n","[09:40:29.360602] Detection metrics: ['Precision', 0.9846153846153847, 'Recall', 0.7413127413127413, 'F1', 0.8458149779735684]\n","[09:40:29.365433] All classes 1\n","[09:40:29.365504] Detection metrics: ['Precision', 0.9846153846153847, 'Recall', 0.7413127413127413, 'F1', 0.8458149779735684]\n","[09:40:29.365534] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:29.562965] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:29.660990] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.45it/s]\u001b[A\n"," 19% 5/27 [00:05<00:18,  1.17it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:29.665796] Processing image(s): ['vol_005.tif']\n","[09:40:29.665967] ### 3D-OV-CROP ###\n","[09:40:29.666003] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:29.666025] Minimum overlap selected: (0, 0, 0)\n","[09:40:29.666045] Padding: (8, 8, 8)\n","[09:40:29.667204] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:29.667271] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:29.667294] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:29.669847] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:29.669914] ### END 3D-OV-CROP ###\n","[09:40:29.669974] ### 3D-OV-CROP ###\n","[09:40:29.670003] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:29.670026] Minimum overlap selected: (0, 0, 0)\n","[09:40:29.670048] Padding: (8, 8, 8)\n","[09:40:29.670814] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:29.670871] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:29.670896] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:29.671652] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:29.671694] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.88it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:29.915950] ### MERGE-3D-OV-CROP ###\n","[09:40:29.916030] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:29.916053] Minimum overlap selected: (0, 0, 0)\n","[09:40:29.916074] Padding: (8, 8, 8)\n","[09:40:29.916380] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:29.916420] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:29.916444] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:29.919706] **** New data shape is: (64, 64, 64, 1)\n","[09:40:29.919752] ### END MERGE-3D-OV-CROP ###\n","[09:40:29.919800] ### MERGE-3D-OV-CROP ###\n","[09:40:29.919827] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:29.919847] Minimum overlap selected: (0, 0, 0)\n","[09:40:29.919861] Padding: (8, 8, 8)\n","[09:40:29.919985] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:29.920016] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:29.920038] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:29.922973] **** New data shape is: (64, 64, 64, 1)\n","[09:40:29.923031] ### END MERGE-3D-OV-CROP ###\n","[09:40:29.923164] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:29.931604] Capturing the local maxima \n","[09:40:29.931651] Class 1\n","[09:40:29.951112] Removing close points . . .\n","[09:40:29.951159] Initial number of points: 145\n","[09:40:29.953680] Final number of points: 120\n","[09:40:29.953791] Creating the images with detected points . . .\n","[09:40:29.986425] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.022703] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.032344] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:30.032406] Its respective CSV file seems to be: /content/data/test/y/mask_005.csv\n","[09:40:30.032428] Reading GT data from: /content/data/test/y/mask_005.csv\n","[09:40:30.035100] Detection (class 1)\n","[09:40:30.041437] Points in ground truth: 174, Points in prediction: 120\n","[09:40:30.041491] True positives: 120, False positives: 0, False negatives: 54\n","[09:40:30.041538] Detection metrics: ['Precision', 1.0, 'Recall', 0.6896551724137931, 'F1', 0.8163265306122449]\n","[09:40:30.044746] All classes 1\n","[09:40:30.044799] Detection metrics: ['Precision', 1.0, 'Recall', 0.6896551724137931, 'F1', 0.8163265306122449]\n","[09:40:30.044829] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:30.183129] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.274099] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.64it/s]\u001b[A\n"," 22% 6/27 [00:05<00:16,  1.30it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:30.277798] Processing image(s): ['vol_006.tif']\n","[09:40:30.277902] ### 3D-OV-CROP ###\n","[09:40:30.277926] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.277943] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.277961] Padding: (8, 8, 8)\n","[09:40:30.279017] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.279054] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.279071] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.281395] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:30.281425] ### END 3D-OV-CROP ###\n","[09:40:30.281475] ### 3D-OV-CROP ###\n","[09:40:30.281496] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.281511] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.281529] Padding: (8, 8, 8)\n","[09:40:30.282021] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.282057] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.282074] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.282508] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:30.282537] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.02it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.516600] ### MERGE-3D-OV-CROP ###\n","[09:40:30.516659] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.516676] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.516692] Padding: (8, 8, 8)\n","[09:40:30.516984] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.517006] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.517027] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.519282] **** New data shape is: (64, 64, 64, 1)\n","[09:40:30.519321] ### END MERGE-3D-OV-CROP ###\n","[09:40:30.519364] ### MERGE-3D-OV-CROP ###\n","[09:40:30.519386] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.519407] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.519422] Padding: (8, 8, 8)\n","[09:40:30.519647] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.519669] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.519682] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.521736] **** New data shape is: (64, 64, 64, 1)\n","[09:40:30.521768] ### END MERGE-3D-OV-CROP ###\n","[09:40:30.521858] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.528369] Capturing the local maxima \n","[09:40:30.528408] Class 1\n","[09:40:30.539561] Removing close points . . .\n","[09:40:30.539594] Initial number of points: 28\n","[09:40:30.539940] Final number of points: 14\n","[09:40:30.539999] Creating the images with detected points . . .\n","[09:40:30.555020] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.572879] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.577431] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:30.577494] Its respective CSV file seems to be: /content/data/test/y/mask_006.csv\n","[09:40:30.577521] Reading GT data from: /content/data/test/y/mask_006.csv\n","[09:40:30.579532] Detection (class 1)\n","[09:40:30.581507] Points in ground truth: 22, Points in prediction: 14\n","[09:40:30.581540] True positives: 14, False positives: 0, False negatives: 8\n","[09:40:30.581568] Detection metrics: ['Precision', 1.0, 'Recall', 0.6363636363636364, 'F1', 0.7777777777777778]\n","[09:40:30.582751] All classes 1\n","[09:40:30.582791] Detection metrics: ['Precision', 1.0, 'Recall', 0.6363636363636364, 'F1', 0.7777777777777778]\n","[09:40:30.582811] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:30.605246] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.655972] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.63it/s]\u001b[A\n"," 26% 7/27 [00:06<00:12,  1.56it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:30.659236] Processing image(s): ['vol_007.tif']\n","[09:40:30.659336] ### 3D-OV-CROP ###\n","[09:40:30.659365] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.659384] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.659403] Padding: (8, 8, 8)\n","[09:40:30.660334] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.660378] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.660397] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.662530] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:30.662559] ### END 3D-OV-CROP ###\n","[09:40:30.662602] ### 3D-OV-CROP ###\n","[09:40:30.662622] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.662640] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.662656] Padding: (8, 8, 8)\n","[09:40:30.663154] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.663191] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.663217] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.663698] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:30.663728] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.96it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.896082] ### MERGE-3D-OV-CROP ###\n","[09:40:30.896134] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.896148] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.896160] Padding: (8, 8, 8)\n","[09:40:30.896439] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.896460] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.896485] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.898697] **** New data shape is: (64, 64, 64, 1)\n","[09:40:30.898729] ### END MERGE-3D-OV-CROP ###\n","[09:40:30.898765] ### MERGE-3D-OV-CROP ###\n","[09:40:30.898787] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:30.898805] Minimum overlap selected: (0, 0, 0)\n","[09:40:30.898819] Padding: (8, 8, 8)\n","[09:40:30.898920] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:30.898941] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:30.898956] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:30.901374] **** New data shape is: (64, 64, 64, 1)\n","[09:40:30.901409] ### END MERGE-3D-OV-CROP ###\n","[09:40:30.901504] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.906298] Capturing the local maxima \n","[09:40:30.906341] Class 1\n","[09:40:30.919039] Removing close points . . .\n","[09:40:30.919073] Initial number of points: 100\n","[09:40:30.920764] Final number of points: 85\n","[09:40:30.920849] Creating the images with detected points . . .\n","[09:40:30.937672] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.955375] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:30.961023] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:30.961061] Its respective CSV file seems to be: /content/data/test/y/mask_007.csv\n","[09:40:30.961086] Reading GT data from: /content/data/test/y/mask_007.csv\n","[09:40:30.962948] Detection (class 1)\n","[09:40:30.966138] Points in ground truth: 121, Points in prediction: 85\n","[09:40:30.966176] True positives: 85, False positives: 0, False negatives: 36\n","[09:40:30.966208] Detection metrics: ['Precision', 1.0, 'Recall', 0.7024793388429752, 'F1', 0.8252427184466019]\n","[09:40:30.967939] All classes 1\n","[09:40:30.967980] Detection metrics: ['Precision', 1.0, 'Recall', 0.7024793388429752, 'F1', 0.8252427184466019]\n","[09:40:30.968001] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:31.021068] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.092392] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.30it/s]\u001b[A\n"," 30% 8/27 [00:06<00:10,  1.73it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:31.095911] Processing image(s): ['vol_008.tif']\n","[09:40:31.096006] ### 3D-OV-CROP ###\n","[09:40:31.096029] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.096048] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.096067] Padding: (8, 8, 8)\n","[09:40:31.096998] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.097037] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.097058] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.099176] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:31.099207] ### END 3D-OV-CROP ###\n","[09:40:31.099248] ### 3D-OV-CROP ###\n","[09:40:31.099267] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.099282] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.099299] Padding: (8, 8, 8)\n","[09:40:31.099781] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.099815] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.099830] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.100249] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:31.100273] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.08it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.333817] ### MERGE-3D-OV-CROP ###\n","[09:40:31.333880] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.333899] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.333913] Padding: (8, 8, 8)\n","[09:40:31.334230] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.334258] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.334271] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.337973] **** New data shape is: (64, 64, 64, 1)\n","[09:40:31.338038] ### END MERGE-3D-OV-CROP ###\n","[09:40:31.338106] ### MERGE-3D-OV-CROP ###\n","[09:40:31.338141] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.338171] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.338194] Padding: (8, 8, 8)\n","[09:40:31.338331] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.338371] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.338400] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.341705] **** New data shape is: (64, 64, 64, 1)\n","[09:40:31.341760] ### END MERGE-3D-OV-CROP ###\n","[09:40:31.341900] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.351138] Capturing the local maxima \n","[09:40:31.351199] Class 1\n","[09:40:31.377160] Removing close points . . .\n","[09:40:31.377207] Initial number of points: 350\n","[09:40:31.383968] Final number of points: 273\n","[09:40:31.384122] Creating the images with detected points . . .\n","[09:40:31.407159] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.425567] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.435603] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:31.435661] Its respective CSV file seems to be: /content/data/test/y/mask_008.csv\n","[09:40:31.435689] Reading GT data from: /content/data/test/y/mask_008.csv\n","[09:40:31.438724] Detection (class 1)\n","[09:40:31.450854] Points in ground truth: 369, Points in prediction: 273\n","[09:40:31.450895] True positives: 273, False positives: 0, False negatives: 96\n","[09:40:31.450941] Detection metrics: ['Precision', 1.0, 'Recall', 0.7398373983739838, 'F1', 0.8504672897196263]\n","[09:40:31.454252] All classes 1\n","[09:40:31.454300] Detection metrics: ['Precision', 1.0, 'Recall', 0.7398373983739838, 'F1', 0.8504672897196263]\n","[09:40:31.454324] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:31.586550] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.643186] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.82it/s]\u001b[A\n"," 33% 9/27 [00:07<00:10,  1.76it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:31.648249] Processing image(s): ['vol_009.tif']\n","[09:40:31.648404] ### 3D-OV-CROP ###\n","[09:40:31.648438] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.648463] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.648506] Padding: (8, 8, 8)\n","[09:40:31.649807] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.649859] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.649886] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.652436] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:31.652486] ### END 3D-OV-CROP ###\n","[09:40:31.652545] ### 3D-OV-CROP ###\n","[09:40:31.652571] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.652593] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.652614] Padding: (8, 8, 8)\n","[09:40:31.653452] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.653511] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.653538] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.654249] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:31.654285] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.03it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.887268] ### MERGE-3D-OV-CROP ###\n","[09:40:31.887338] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.887363] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.887385] Padding: (8, 8, 8)\n","[09:40:31.887704] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.887728] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.887743] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.890219] **** New data shape is: (64, 64, 64, 1)\n","[09:40:31.890265] ### END MERGE-3D-OV-CROP ###\n","[09:40:31.890318] ### MERGE-3D-OV-CROP ###\n","[09:40:31.890341] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:31.890376] Minimum overlap selected: (0, 0, 0)\n","[09:40:31.890393] Padding: (8, 8, 8)\n","[09:40:31.890545] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:31.890569] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:31.890585] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:31.893016] **** New data shape is: (64, 64, 64, 1)\n","[09:40:31.893054] ### END MERGE-3D-OV-CROP ###\n","[09:40:31.893151] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.898497] Capturing the local maxima \n","[09:40:31.898538] Class 1\n","[09:40:31.915419] Removing close points . . .\n","[09:40:31.915457] Initial number of points: 390\n","[09:40:31.919187] Final number of points: 304\n","[09:40:31.919321] Creating the images with detected points . . .\n","[09:40:31.941611] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.972248] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:31.987060] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:31.987109] Its respective CSV file seems to be: /content/data/test/y/mask_009.csv\n","[09:40:31.987132] Reading GT data from: /content/data/test/y/mask_009.csv\n","[09:40:31.989863] Detection (class 1)\n","[09:40:32.003031] Points in ground truth: 372, Points in prediction: 304\n","[09:40:32.003070] True positives: 285, False positives: 19, False negatives: 87\n","[09:40:32.003127] Detection metrics: ['Precision', 0.9375, 'Recall', 0.7661290322580645, 'F1', 0.8431952662721893]\n","[09:40:32.006689] All classes 1\n","[09:40:32.006735] Detection metrics: ['Precision', 0.9375, 'Recall', 0.7661290322580645, 'F1', 0.8431952662721893]\n","[09:40:32.006765] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:32.148778] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:32.205524] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.79it/s]\u001b[A\n"," 37% 10/27 [00:07<00:09,  1.76it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:32.209739] Processing image(s): ['vol_010.tif']\n","[09:40:32.209890] ### 3D-OV-CROP ###\n","[09:40:32.209923] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:32.209940] Minimum overlap selected: (0, 0, 0)\n","[09:40:32.209984] Padding: (8, 8, 8)\n","[09:40:32.211140] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:32.211196] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:32.211224] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:32.213728] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:32.213765] ### END 3D-OV-CROP ###\n","[09:40:32.213812] ### 3D-OV-CROP ###\n","[09:40:32.213836] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:32.213855] Minimum overlap selected: (0, 0, 0)\n","[09:40:32.213873] Padding: (8, 8, 8)\n","[09:40:32.214370] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:32.214420] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:32.214438] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:32.214916] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:32.214946] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.02it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:32.447107] ### MERGE-3D-OV-CROP ###\n","[09:40:32.447165] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:32.447189] Minimum overlap selected: (0, 0, 0)\n","[09:40:32.447208] Padding: (8, 8, 8)\n","[09:40:32.447493] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:32.447515] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:32.447530] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:32.449648] **** New data shape is: (64, 64, 64, 1)\n","[09:40:32.449681] ### END MERGE-3D-OV-CROP ###\n","[09:40:32.449718] ### MERGE-3D-OV-CROP ###\n","[09:40:32.449740] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:32.449755] Minimum overlap selected: (0, 0, 0)\n","[09:40:32.449770] Padding: (8, 8, 8)\n","[09:40:32.449881] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:32.449901] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:32.449913] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:32.452307] **** New data shape is: (64, 64, 64, 1)\n","[09:40:32.452344] ### END MERGE-3D-OV-CROP ###\n","[09:40:32.452432] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:32.458002] Capturing the local maxima \n","[09:40:32.458044] Class 1\n","[09:40:32.475299] Removing close points . . .\n","[09:40:32.475335] Initial number of points: 461\n","[09:40:32.479568] Final number of points: 356\n","[09:40:32.479706] Creating the images with detected points . . .\n","[09:40:32.496847] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:32.521917] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:32.531612] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:32.531656] Its respective CSV file seems to be: /content/data/test/y/mask_010.csv\n","[09:40:32.531682] Reading GT data from: /content/data/test/y/mask_010.csv\n","[09:40:32.534561] Detection (class 1)\n","[09:40:32.549563] Points in ground truth: 502, Points in prediction: 356\n","[09:40:32.549598] True positives: 352, False positives: 4, False negatives: 150\n","[09:40:32.549662] Detection metrics: ['Precision', 0.9887640449438202, 'Recall', 0.701195219123506, 'F1', 0.8205128205128205]\n","[09:40:32.553684] All classes 1\n","[09:40:32.553727] Detection metrics: ['Precision', 0.9887640449438202, 'Recall', 0.701195219123506, 'F1', 0.8205128205128205]\n","[09:40:32.553747] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:32.736541] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:32.794162] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.70it/s]\u001b[A\n"," 41% 11/27 [00:08<00:09,  1.74it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:32.797789] Processing image(s): ['vol_011.tif']\n","[09:40:32.797900] ### 3D-OV-CROP ###\n","[09:40:32.797925] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:32.797946] Minimum overlap selected: (0, 0, 0)\n","[09:40:32.797966] Padding: (8, 8, 8)\n","[09:40:32.798850] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:32.798887] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:32.798902] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:32.801009] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:32.801041] ### END 3D-OV-CROP ###\n","[09:40:32.801079] ### 3D-OV-CROP ###\n","[09:40:32.801099] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:32.801117] Minimum overlap selected: (0, 0, 0)\n","[09:40:32.801134] Padding: (8, 8, 8)\n","[09:40:32.801592] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:32.801624] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:32.801637] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:32.802075] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:32.802113] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.97it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.033377] ### MERGE-3D-OV-CROP ###\n","[09:40:33.033428] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:33.033442] Minimum overlap selected: (0, 0, 0)\n","[09:40:33.033455] Padding: (8, 8, 8)\n","[09:40:33.033741] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:33.033765] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:33.033778] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:33.036088] **** New data shape is: (64, 64, 64, 1)\n","[09:40:33.036121] ### END MERGE-3D-OV-CROP ###\n","[09:40:33.036158] ### MERGE-3D-OV-CROP ###\n","[09:40:33.036179] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:33.036198] Minimum overlap selected: (0, 0, 0)\n","[09:40:33.036216] Padding: (8, 8, 8)\n","[09:40:33.036324] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:33.036344] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:33.036357] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:33.038751] **** New data shape is: (64, 64, 64, 1)\n","[09:40:33.038798] ### END MERGE-3D-OV-CROP ###\n","[09:40:33.038909] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.047867] Capturing the local maxima \n","[09:40:33.047913] Class 1\n","[09:40:33.071582] Removing close points . . .\n","[09:40:33.071624] Initial number of points: 410\n","[09:40:33.078512] Final number of points: 330\n","[09:40:33.078686] Creating the images with detected points . . .\n","[09:40:33.098254] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.115867] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.125219] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:33.125259] Its respective CSV file seems to be: /content/data/test/y/mask_011.csv\n","[09:40:33.125273] Reading GT data from: /content/data/test/y/mask_011.csv\n","[09:40:33.127137] Detection (class 1)\n","[09:40:33.138566] Points in ground truth: 421, Points in prediction: 330\n","[09:40:33.138608] True positives: 324, False positives: 6, False negatives: 97\n","[09:40:33.138679] Detection metrics: ['Precision', 0.9818181818181818, 'Recall', 0.7695961995249406, 'F1', 0.8628495339547271]\n","[09:40:33.142751] All classes 1\n","[09:40:33.142795] Detection metrics: ['Precision', 0.9818181818181818, 'Recall', 0.7695961995249406, 'F1', 0.8628495339547271]\n","[09:40:33.142822] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:33.291515] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.340131] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.83it/s]\u001b[A\n"," 44% 12/27 [00:08<00:08,  1.77it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:33.345260] Processing image(s): ['vol_012.tif']\n","[09:40:33.349661] ### 3D-OV-CROP ###\n","[09:40:33.349709] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:33.349730] Minimum overlap selected: (0, 0, 0)\n","[09:40:33.349750] Padding: (8, 8, 8)\n","[09:40:33.351067] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:33.351113] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:33.351136] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:33.356701] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:33.356745] ### END 3D-OV-CROP ###\n","[09:40:33.356807] ### 3D-OV-CROP ###\n","[09:40:33.356835] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:33.356867] Minimum overlap selected: (0, 0, 0)\n","[09:40:33.356890] Padding: (8, 8, 8)\n","[09:40:33.357650] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:33.357694] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:33.357717] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:33.358389] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:33.358422] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.07it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.602351] ### MERGE-3D-OV-CROP ###\n","[09:40:33.602419] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:33.602440] Minimum overlap selected: (0, 0, 0)\n","[09:40:33.602476] Padding: (8, 8, 8)\n","[09:40:33.602776] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:33.602802] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:33.602818] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:33.605556] **** New data shape is: (64, 64, 64, 1)\n","[09:40:33.605599] ### END MERGE-3D-OV-CROP ###\n","[09:40:33.605646] ### MERGE-3D-OV-CROP ###\n","[09:40:33.605675] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:33.605717] Minimum overlap selected: (0, 0, 0)\n","[09:40:33.605749] Padding: (8, 8, 8)\n","[09:40:33.605880] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:33.605907] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:33.605933] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:33.608637] **** New data shape is: (64, 64, 64, 1)\n","[09:40:33.608678] ### END MERGE-3D-OV-CROP ###\n","[09:40:33.608783] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.615063] Capturing the local maxima \n","[09:40:33.615111] Class 1\n","[09:40:33.635395] Removing close points . . .\n","[09:40:33.635437] Initial number of points: 481\n","[09:40:33.640562] Final number of points: 419\n","[09:40:33.640707] Creating the images with detected points . . .\n","[09:40:33.660999] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.682018] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:33.693974] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:33.694017] Its respective CSV file seems to be: /content/data/test/y/mask_012.csv\n","[09:40:33.694034] Reading GT data from: /content/data/test/y/mask_012.csv\n","[09:40:33.697370] Detection (class 1)\n","[09:40:33.726720] Points in ground truth: 565, Points in prediction: 419\n","[09:40:33.726780] True positives: 415, False positives: 4, False negatives: 150\n","[09:40:33.726853] Detection metrics: ['Precision', 0.9904534606205251, 'Recall', 0.7345132743362832, 'F1', 0.8434959349593496]\n","[09:40:33.732687] All classes 1\n","[09:40:33.732745] Detection metrics: ['Precision', 0.9904534606205251, 'Recall', 0.7345132743362832, 'F1', 0.8434959349593496]\n","[09:40:33.732778] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:33.981854] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.050173] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.41it/s]\u001b[A\n"," 48% 13/27 [00:09<00:08,  1.64it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:34.054338] Processing image(s): ['vol_013.tif']\n","[09:40:34.054446] ### 3D-OV-CROP ###\n","[09:40:34.054488] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.054509] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.054525] Padding: (8, 8, 8)\n","[09:40:34.055236] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.055288] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.055303] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.057604] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:34.057634] ### END 3D-OV-CROP ###\n","[09:40:34.057677] ### 3D-OV-CROP ###\n","[09:40:34.057698] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.057711] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.057727] Padding: (8, 8, 8)\n","[09:40:34.058160] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.058194] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.058207] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.058609] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:34.058635] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.05it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.291068] ### MERGE-3D-OV-CROP ###\n","[09:40:34.291132] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.291158] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.291179] Padding: (8, 8, 8)\n","[09:40:34.291463] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.291514] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.291533] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.295082] **** New data shape is: (64, 64, 64, 1)\n","[09:40:34.295169] ### END MERGE-3D-OV-CROP ###\n","[09:40:34.295213] ### MERGE-3D-OV-CROP ###\n","[09:40:34.295236] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.295255] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.295273] Padding: (8, 8, 8)\n","[09:40:34.295384] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.295408] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.295426] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.298140] **** New data shape is: (64, 64, 64, 1)\n","[09:40:34.298188] ### END MERGE-3D-OV-CROP ###\n","[09:40:34.298397] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.304084] Capturing the local maxima \n","[09:40:34.304129] Class 1\n","[09:40:34.319287] Removing close points . . .\n","[09:40:34.319321] Initial number of points: 374\n","[09:40:34.322608] Final number of points: 309\n","[09:40:34.322726] Creating the images with detected points . . .\n","[09:40:34.339815] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.359385] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.368238] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:34.368278] Its respective CSV file seems to be: /content/data/test/y/mask_013.csv\n","[09:40:34.368291] Reading GT data from: /content/data/test/y/mask_013.csv\n","[09:40:34.370403] Detection (class 1)\n","[09:40:34.380297] Points in ground truth: 388, Points in prediction: 309\n","[09:40:34.380349] True positives: 305, False positives: 4, False negatives: 83\n","[09:40:34.380400] Detection metrics: ['Precision', 0.9870550161812298, 'Recall', 0.7860824742268041, 'F1', 0.8751793400286944]\n","[09:40:34.384216] All classes 1\n","[09:40:34.384264] Detection metrics: ['Precision', 0.9870550161812298, 'Recall', 0.7860824742268041, 'F1', 0.8751793400286944]\n","[09:40:34.384287] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:34.523000] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.594220] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.84it/s]\u001b[A\n"," 52% 14/27 [00:10<00:07,  1.70it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:34.598786] Processing image(s): ['vol_014.tif']\n","[09:40:34.598917] ### 3D-OV-CROP ###\n","[09:40:34.598944] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.598964] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.598982] Padding: (8, 8, 8)\n","[09:40:34.600258] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.600339] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.600361] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.602917] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:34.602953] ### END 3D-OV-CROP ###\n","[09:40:34.603002] ### 3D-OV-CROP ###\n","[09:40:34.603026] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.603043] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.603060] Padding: (8, 8, 8)\n","[09:40:34.603582] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.603617] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.603636] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.604093] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:34.604122] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.05it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.838163] ### MERGE-3D-OV-CROP ###\n","[09:40:34.838230] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.838254] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.838276] Padding: (8, 8, 8)\n","[09:40:34.838588] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.838623] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.838645] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.841997] **** New data shape is: (64, 64, 64, 1)\n","[09:40:34.842049] ### END MERGE-3D-OV-CROP ###\n","[09:40:34.842103] ### MERGE-3D-OV-CROP ###\n","[09:40:34.842133] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:34.842157] Minimum overlap selected: (0, 0, 0)\n","[09:40:34.842178] Padding: (8, 8, 8)\n","[09:40:34.842313] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:34.842341] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:34.842361] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:34.845533] **** New data shape is: (64, 64, 64, 1)\n","[09:40:34.845585] ### END MERGE-3D-OV-CROP ###\n","[09:40:34.845755] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.851162] Capturing the local maxima \n","[09:40:34.851202] Class 1\n","[09:40:34.863192] Removing close points . . .\n","[09:40:34.863226] Initial number of points: 54\n","[09:40:34.863846] Final number of points: 43\n","[09:40:34.863919] Creating the images with detected points . . .\n","[09:40:34.880499] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.899280] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:34.904615] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:34.904657] Its respective CSV file seems to be: /content/data/test/y/mask_014.csv\n","[09:40:34.904682] Reading GT data from: /content/data/test/y/mask_014.csv\n","[09:40:34.906725] Detection (class 1)\n","[09:40:34.908717] Points in ground truth: 71, Points in prediction: 43\n","[09:40:34.908754] True positives: 42, False positives: 1, False negatives: 29\n","[09:40:34.908790] Detection metrics: ['Precision', 0.9767441860465116, 'Recall', 0.5915492957746479, 'F1', 0.7368421052631579]\n","[09:40:34.910689] All classes 1\n","[09:40:34.910738] Detection metrics: ['Precision', 0.9767441860465116, 'Recall', 0.5915492957746479, 'F1', 0.7368421052631579]\n","[09:40:34.910762] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:34.954862] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.011874] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.41it/s]\u001b[A\n"," 56% 15/27 [00:10<00:06,  1.86it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:35.015735] Processing image(s): ['vol_015.tif']\n","[09:40:35.015854] ### 3D-OV-CROP ###\n","[09:40:35.015880] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.015901] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.015921] Padding: (8, 8, 8)\n","[09:40:35.016901] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.016943] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.016976] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.019114] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:35.019149] ### END 3D-OV-CROP ###\n","[09:40:35.019194] ### 3D-OV-CROP ###\n","[09:40:35.019216] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.019234] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.019253] Padding: (8, 8, 8)\n","[09:40:35.019783] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.019816] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.019834] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.020253] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:35.020281] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.96it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.252807] ### MERGE-3D-OV-CROP ###\n","[09:40:35.252880] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.252897] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.252913] Padding: (8, 8, 8)\n","[09:40:35.253203] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.253225] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.253240] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.255662] **** New data shape is: (64, 64, 64, 1)\n","[09:40:35.255697] ### END MERGE-3D-OV-CROP ###\n","[09:40:35.255737] ### MERGE-3D-OV-CROP ###\n","[09:40:35.255761] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.255776] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.255793] Padding: (8, 8, 8)\n","[09:40:35.255909] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.255931] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.255945] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.258350] **** New data shape is: (64, 64, 64, 1)\n","[09:40:35.258390] ### END MERGE-3D-OV-CROP ###\n","[09:40:35.258507] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.265653] Capturing the local maxima \n","[09:40:35.265703] Class 1\n","[09:40:35.284482] Removing close points . . .\n","[09:40:35.284528] Initial number of points: 144\n","[09:40:35.287052] Final number of points: 114\n","[09:40:35.287147] Creating the images with detected points . . .\n","[09:40:35.312915] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.330453] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.336411] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:35.336450] Its respective CSV file seems to be: /content/data/test/y/mask_015.csv\n","[09:40:35.336463] Reading GT data from: /content/data/test/y/mask_015.csv\n","[09:40:35.338407] Detection (class 1)\n","[09:40:35.341811] Points in ground truth: 163, Points in prediction: 114\n","[09:40:35.341846] True positives: 112, False positives: 2, False negatives: 51\n","[09:40:35.341885] Detection metrics: ['Precision', 0.9824561403508771, 'Recall', 0.6871165644171779, 'F1', 0.8086642599277978]\n","[09:40:35.344177] All classes 1\n","[09:40:35.344225] Detection metrics: ['Precision', 0.9824561403508771, 'Recall', 0.6871165644171779, 'F1', 0.8086642599277978]\n","[09:40:35.344261] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:35.426737] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.476608] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.16it/s]\u001b[A\n"," 59% 16/27 [00:11<00:05,  1.94it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:35.480007] Processing image(s): ['vol_016.tif']\n","[09:40:35.480107] ### 3D-OV-CROP ###\n","[09:40:35.480130] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.480150] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.480167] Padding: (8, 8, 8)\n","[09:40:35.481006] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.481044] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.481057] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.483228] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:35.483260] ### END 3D-OV-CROP ###\n","[09:40:35.483300] ### 3D-OV-CROP ###\n","[09:40:35.483320] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.483333] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.483348] Padding: (8, 8, 8)\n","[09:40:35.483850] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.483888] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.483908] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.484332] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:35.484366] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.01it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.716555] ### MERGE-3D-OV-CROP ###\n","[09:40:35.716607] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.716629] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.716652] Padding: (8, 8, 8)\n","[09:40:35.716937] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.716959] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.716972] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.719326] **** New data shape is: (64, 64, 64, 1)\n","[09:40:35.719375] ### END MERGE-3D-OV-CROP ###\n","[09:40:35.719413] ### MERGE-3D-OV-CROP ###\n","[09:40:35.719445] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:35.719458] Minimum overlap selected: (0, 0, 0)\n","[09:40:35.719484] Padding: (8, 8, 8)\n","[09:40:35.719597] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:35.719617] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:35.719635] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:35.721988] **** New data shape is: (64, 64, 64, 1)\n","[09:40:35.722023] ### END MERGE-3D-OV-CROP ###\n","[09:40:35.722111] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.727179] Capturing the local maxima \n","[09:40:35.727222] Class 1\n","[09:40:35.741457] Removing close points . . .\n","[09:40:35.741501] Initial number of points: 300\n","[09:40:35.744352] Final number of points: 249\n","[09:40:35.744478] Creating the images with detected points . . .\n","[09:40:35.760548] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.779995] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:35.788083] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:35.788125] Its respective CSV file seems to be: /content/data/test/y/mask_016.csv\n","[09:40:35.788140] Reading GT data from: /content/data/test/y/mask_016.csv\n","[09:40:35.790173] Detection (class 1)\n","[09:40:35.798173] Points in ground truth: 337, Points in prediction: 249\n","[09:40:35.798209] True positives: 243, False positives: 6, False negatives: 94\n","[09:40:35.798250] Detection metrics: ['Precision', 0.9759036144578314, 'Recall', 0.7210682492581603, 'F1', 0.8293515358361775]\n","[09:40:35.801526] All classes 1\n","[09:40:35.801567] Detection metrics: ['Precision', 0.9759036144578314, 'Recall', 0.7210682492581603, 'F1', 0.8293515358361775]\n","[09:40:35.801586] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:35.952503] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.002948] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.90it/s]\u001b[A\n"," 63% 17/27 [00:11<00:05,  1.93it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:36.006570] Processing image(s): ['vol_017.tif']\n","[09:40:36.006667] ### 3D-OV-CROP ###\n","[09:40:36.006690] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.006709] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.006727] Padding: (8, 8, 8)\n","[09:40:36.007444] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.007493] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.007513] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.009689] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:36.009718] ### END 3D-OV-CROP ###\n","[09:40:36.009755] ### 3D-OV-CROP ###\n","[09:40:36.009773] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.009791] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.009807] Padding: (8, 8, 8)\n","[09:40:36.010309] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.010356] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.010375] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.010819] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:36.010851] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.97it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.242245] ### MERGE-3D-OV-CROP ###\n","[09:40:36.242302] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.242320] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.242332] Padding: (8, 8, 8)\n","[09:40:36.242625] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.242647] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.242661] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.244819] **** New data shape is: (64, 64, 64, 1)\n","[09:40:36.244854] ### END MERGE-3D-OV-CROP ###\n","[09:40:36.244892] ### MERGE-3D-OV-CROP ###\n","[09:40:36.244917] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.244933] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.244949] Padding: (8, 8, 8)\n","[09:40:36.245057] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.245076] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.245093] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.247463] **** New data shape is: (64, 64, 64, 1)\n","[09:40:36.247512] ### END MERGE-3D-OV-CROP ###\n","[09:40:36.247608] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.252617] Capturing the local maxima \n","[09:40:36.252657] Class 1\n","[09:40:36.268039] Removing close points . . .\n","[09:40:36.268077] Initial number of points: 280\n","[09:40:36.270797] Final number of points: 225\n","[09:40:36.270913] Creating the images with detected points . . .\n","[09:40:36.290225] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.312371] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.320943] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:36.320985] Its respective CSV file seems to be: /content/data/test/y/mask_017.csv\n","[09:40:36.321004] Reading GT data from: /content/data/test/y/mask_017.csv\n","[09:40:36.323135] Detection (class 1)\n","[09:40:36.330197] Points in ground truth: 286, Points in prediction: 225\n","[09:40:36.330237] True positives: 217, False positives: 8, False negatives: 69\n","[09:40:36.330282] Detection metrics: ['Precision', 0.9644444444444444, 'Recall', 0.7587412587412588, 'F1', 0.8493150684931507]\n","[09:40:36.333623] All classes 1\n","[09:40:36.333673] Detection metrics: ['Precision', 0.9644444444444444, 'Recall', 0.7587412587412588, 'F1', 0.8493150684931507]\n","[09:40:36.333696] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:36.443794] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.516647] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.95it/s]\u001b[A\n"," 67% 18/27 [00:12<00:04,  1.93it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:36.521073] Processing image(s): ['vol_018.tif']\n","[09:40:36.521215] ### 3D-OV-CROP ###\n","[09:40:36.521248] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.521273] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.521295] Padding: (8, 8, 8)\n","[09:40:36.522623] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.522677] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.522701] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.525065] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:36.525104] ### END 3D-OV-CROP ###\n","[09:40:36.525148] ### 3D-OV-CROP ###\n","[09:40:36.525171] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.525191] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.525210] Padding: (8, 8, 8)\n","[09:40:36.525707] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.525742] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.525763] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.526201] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:36.526242] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.09it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.756199] ### MERGE-3D-OV-CROP ###\n","[09:40:36.756254] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.756274] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.756288] Padding: (8, 8, 8)\n","[09:40:36.756574] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.756596] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.756609] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.758726] **** New data shape is: (64, 64, 64, 1)\n","[09:40:36.758760] ### END MERGE-3D-OV-CROP ###\n","[09:40:36.758796] ### MERGE-3D-OV-CROP ###\n","[09:40:36.758817] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:36.758830] Minimum overlap selected: (0, 0, 0)\n","[09:40:36.758844] Padding: (8, 8, 8)\n","[09:40:36.758950] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:36.758970] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:36.758982] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:36.761138] **** New data shape is: (64, 64, 64, 1)\n","[09:40:36.761174] ### END MERGE-3D-OV-CROP ###\n","[09:40:36.761263] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.765987] Capturing the local maxima \n","[09:40:36.766021] Class 1\n","[09:40:36.786954] Removing close points . . .\n","[09:40:36.786996] Initial number of points: 289\n","[09:40:36.791923] Final number of points: 226\n","[09:40:36.792050] Creating the images with detected points . . .\n","[09:40:36.821097] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.840338] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:36.848162] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:36.848200] Its respective CSV file seems to be: /content/data/test/y/mask_018.csv\n","[09:40:36.848213] Reading GT data from: /content/data/test/y/mask_018.csv\n","[09:40:36.850184] Detection (class 1)\n","[09:40:36.856996] Points in ground truth: 307, Points in prediction: 226\n","[09:40:36.857034] True positives: 225, False positives: 1, False negatives: 82\n","[09:40:36.857077] Detection metrics: ['Precision', 0.995575221238938, 'Recall', 0.7328990228013029, 'F1', 0.8442776735459662]\n","[09:40:36.860946] All classes 1\n","[09:40:36.860996] Detection metrics: ['Precision', 0.995575221238938, 'Recall', 0.7328990228013029, 'F1', 0.8442776735459662]\n","[09:40:36.861019] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:36.999642] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.062867] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.84it/s]\u001b[A\n"," 70% 19/27 [00:12<00:04,  1.90it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:37.066776] Processing image(s): ['vol_019.tif']\n","[09:40:37.066897] ### 3D-OV-CROP ###\n","[09:40:37.066925] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.066946] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.066968] Padding: (8, 8, 8)\n","[09:40:37.068130] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.068170] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.068186] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.070420] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:37.070456] ### END 3D-OV-CROP ###\n","[09:40:37.070508] ### 3D-OV-CROP ###\n","[09:40:37.070531] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.070549] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.070567] Padding: (8, 8, 8)\n","[09:40:37.071059] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.071097] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.071115] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.071609] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:37.071641] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.99it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.305831] ### MERGE-3D-OV-CROP ###\n","[09:40:37.305891] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.305916] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.305936] Padding: (8, 8, 8)\n","[09:40:37.306180] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.306205] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.306226] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.308935] **** New data shape is: (64, 64, 64, 1)\n","[09:40:37.308979] ### END MERGE-3D-OV-CROP ###\n","[09:40:37.309029] ### MERGE-3D-OV-CROP ###\n","[09:40:37.309055] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.309078] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.309100] Padding: (8, 8, 8)\n","[09:40:37.309213] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.309239] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.309261] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.311966] **** New data shape is: (64, 64, 64, 1)\n","[09:40:37.312012] ### END MERGE-3D-OV-CROP ###\n","[09:40:37.312116] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.319001] Capturing the local maxima \n","[09:40:37.319049] Class 1\n","[09:40:37.335514] Removing close points . . .\n","[09:40:37.335545] Initial number of points: 288\n","[09:40:37.338100] Final number of points: 238\n","[09:40:37.338221] Creating the images with detected points . . .\n","[09:40:37.354680] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.373620] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.381669] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:37.381711] Its respective CSV file seems to be: /content/data/test/y/mask_019.csv\n","[09:40:37.381727] Reading GT data from: /content/data/test/y/mask_019.csv\n","[09:40:37.383921] Detection (class 1)\n","[09:40:37.391626] Points in ground truth: 326, Points in prediction: 238\n","[09:40:37.391662] True positives: 237, False positives: 1, False negatives: 89\n","[09:40:37.391706] Detection metrics: ['Precision', 0.9957983193277311, 'Recall', 0.7269938650306749, 'F1', 0.8404255319148937]\n","[09:40:37.394903] All classes 1\n","[09:40:37.394949] Detection metrics: ['Precision', 0.9957983193277311, 'Recall', 0.7269938650306749, 'F1', 0.8404255319148937]\n","[09:40:37.394970] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:37.509129] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.559964] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.02it/s]\u001b[A\n"," 74% 20/27 [00:13<00:03,  1.93it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:37.563207] Processing image(s): ['vol_020.tif']\n","[09:40:37.563305] ### 3D-OV-CROP ###\n","[09:40:37.563328] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.563348] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.563364] Padding: (8, 8, 8)\n","[09:40:37.564068] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.564103] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.564120] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.565858] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:37.565900] ### END 3D-OV-CROP ###\n","[09:40:37.565940] ### 3D-OV-CROP ###\n","[09:40:37.565960] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.565978] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.565996] Padding: (8, 8, 8)\n","[09:40:37.566422] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.566455] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.566484] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.566875] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:37.566906] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.98it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.799048] ### MERGE-3D-OV-CROP ###\n","[09:40:37.799103] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.799120] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.799133] Padding: (8, 8, 8)\n","[09:40:37.799407] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.799435] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.799451] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.801710] **** New data shape is: (64, 64, 64, 1)\n","[09:40:37.801745] ### END MERGE-3D-OV-CROP ###\n","[09:40:37.801784] ### MERGE-3D-OV-CROP ###\n","[09:40:37.801806] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:37.801821] Minimum overlap selected: (0, 0, 0)\n","[09:40:37.801837] Padding: (8, 8, 8)\n","[09:40:37.801953] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:37.801974] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:37.801991] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:37.804092] **** New data shape is: (64, 64, 64, 1)\n","[09:40:37.804126] ### END MERGE-3D-OV-CROP ###\n","[09:40:37.804212] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.809144] Capturing the local maxima \n","[09:40:37.809185] Class 1\n","[09:40:37.824159] Removing close points . . .\n","[09:40:37.824194] Initial number of points: 292\n","[09:40:37.827082] Final number of points: 230\n","[09:40:37.827209] Creating the images with detected points . . .\n","[09:40:37.845560] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.863800] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:37.871833] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:37.871888] Its respective CSV file seems to be: /content/data/test/y/mask_020.csv\n","[09:40:37.871913] Reading GT data from: /content/data/test/y/mask_020.csv\n","[09:40:37.874500] Detection (class 1)\n","[09:40:37.885052] Points in ground truth: 315, Points in prediction: 230\n","[09:40:37.885094] True positives: 228, False positives: 2, False negatives: 87\n","[09:40:37.885143] Detection metrics: ['Precision', 0.991304347826087, 'Recall', 0.7238095238095238, 'F1', 0.836697247706422]\n","[09:40:37.889746] All classes 1\n","[09:40:37.889796] Detection metrics: ['Precision', 0.991304347826087, 'Recall', 0.7238095238095238, 'F1', 0.836697247706422]\n","[09:40:37.889820] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:38.028816] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.078355] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.93it/s]\u001b[A\n"," 78% 21/27 [00:13<00:03,  1.93it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:38.081890] Processing image(s): ['vol_021.tif']\n","[09:40:38.081992] ### 3D-OV-CROP ###\n","[09:40:38.082016] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.082035] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.082053] Padding: (8, 8, 8)\n","[09:40:38.082785] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.082822] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.082841] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.084911] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:38.084940] ### END 3D-OV-CROP ###\n","[09:40:38.084978] ### 3D-OV-CROP ###\n","[09:40:38.084998] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.085015] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.085032] Padding: (8, 8, 8)\n","[09:40:38.085445] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.085488] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.085506] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.085942] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:38.085969] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.08it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.315848] ### MERGE-3D-OV-CROP ###\n","[09:40:38.315900] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.315914] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.315939] Padding: (8, 8, 8)\n","[09:40:38.316196] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.316218] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.316234] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.318362] **** New data shape is: (64, 64, 64, 1)\n","[09:40:38.318398] ### END MERGE-3D-OV-CROP ###\n","[09:40:38.318435] ### MERGE-3D-OV-CROP ###\n","[09:40:38.318457] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.318485] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.318501] Padding: (8, 8, 8)\n","[09:40:38.318613] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.318633] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.318650] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.320737] **** New data shape is: (64, 64, 64, 1)\n","[09:40:38.320771] ### END MERGE-3D-OV-CROP ###\n","[09:40:38.320852] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.325989] Capturing the local maxima \n","[09:40:38.326032] Class 1\n","[09:40:38.337713] Removing close points . . .\n","[09:40:38.337761] Initial number of points: 31\n","[09:40:38.338374] Final number of points: 23\n","[09:40:38.338440] Creating the images with detected points . . .\n","[09:40:38.355886] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.373617] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.378203] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:38.378244] Its respective CSV file seems to be: /content/data/test/y/mask_021.csv\n","[09:40:38.378261] Reading GT data from: /content/data/test/y/mask_021.csv\n","[09:40:38.380130] Detection (class 1)\n","[09:40:38.382449] Points in ground truth: 36, Points in prediction: 23\n","[09:40:38.382504] True positives: 23, False positives: 0, False negatives: 13\n","[09:40:38.382537] Detection metrics: ['Precision', 1.0, 'Recall', 0.6388888888888888, 'F1', 0.7796610169491525]\n","[09:40:38.383812] All classes 1\n","[09:40:38.383853] Detection metrics: ['Precision', 1.0, 'Recall', 0.6388888888888888, 'F1', 0.7796610169491525]\n","[09:40:38.383870] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:38.410720] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.459510] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.63it/s]\u001b[A\n"," 81% 22/27 [00:14<00:02,  2.10it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:38.462744] Processing image(s): ['vol_022.tif']\n","[09:40:38.462840] ### 3D-OV-CROP ###\n","[09:40:38.462862] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.462882] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.462900] Padding: (8, 8, 8)\n","[09:40:38.463878] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.463915] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.463931] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.465893] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:38.465923] ### END 3D-OV-CROP ###\n","[09:40:38.465962] ### 3D-OV-CROP ###\n","[09:40:38.465981] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.465997] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.466014] Padding: (8, 8, 8)\n","[09:40:38.466448] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.466496] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.466514] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.466918] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:38.466944] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.14it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.696371] ### MERGE-3D-OV-CROP ###\n","[09:40:38.696430] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.696448] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.696461] Padding: (8, 8, 8)\n","[09:40:38.696747] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.696769] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.696783] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.698992] **** New data shape is: (64, 64, 64, 1)\n","[09:40:38.699028] ### END MERGE-3D-OV-CROP ###\n","[09:40:38.699066] ### MERGE-3D-OV-CROP ###\n","[09:40:38.699087] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:38.699100] Minimum overlap selected: (0, 0, 0)\n","[09:40:38.699115] Padding: (8, 8, 8)\n","[09:40:38.699224] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:38.699244] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:38.699260] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:38.701505] **** New data shape is: (64, 64, 64, 1)\n","[09:40:38.701534] ### END MERGE-3D-OV-CROP ###\n","[09:40:38.701616] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.706350] Capturing the local maxima \n","[09:40:38.706408] Class 1\n","[09:40:38.721476] Removing close points . . .\n","[09:40:38.721517] Initial number of points: 349\n","[09:40:38.724662] Final number of points: 268\n","[09:40:38.724777] Creating the images with detected points . . .\n","[09:40:38.741009] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.758919] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:38.766847] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:38.766891] Its respective CSV file seems to be: /content/data/test/y/mask_022.csv\n","[09:40:38.766905] Reading GT data from: /content/data/test/y/mask_022.csv\n","[09:40:38.768770] Detection (class 1)\n","[09:40:38.777774] Points in ground truth: 374, Points in prediction: 268\n","[09:40:38.777807] True positives: 261, False positives: 7, False negatives: 113\n","[09:40:38.777848] Detection metrics: ['Precision', 0.9738805970149254, 'Recall', 0.6978609625668449, 'F1', 0.8130841121495328]\n","[09:40:38.781172] All classes 1\n","[09:40:38.781219] Detection metrics: ['Precision', 0.9738805970149254, 'Recall', 0.6978609625668449, 'F1', 0.8130841121495328]\n","[09:40:38.781241] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:38.938769] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.001969] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.84it/s]\u001b[A\n"," 85% 23/27 [00:14<00:01,  2.01it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:39.006267] Processing image(s): ['vol_023.tif']\n","[09:40:39.006396] ### 3D-OV-CROP ###\n","[09:40:39.006423] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.006442] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.006462] Padding: (8, 8, 8)\n","[09:40:39.007776] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.007821] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.007838] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.010077] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:39.010111] ### END 3D-OV-CROP ###\n","[09:40:39.010156] ### 3D-OV-CROP ###\n","[09:40:39.010170] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.010181] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.010192] Padding: (8, 8, 8)\n","[09:40:39.010798] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.010828] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.010840] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.011484] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:39.011514] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.07it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.244069] ### MERGE-3D-OV-CROP ###\n","[09:40:39.244132] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.244149] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.244163] Padding: (8, 8, 8)\n","[09:40:39.244458] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.244489] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.244510] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.246772] **** New data shape is: (64, 64, 64, 1)\n","[09:40:39.246809] ### END MERGE-3D-OV-CROP ###\n","[09:40:39.246849] ### MERGE-3D-OV-CROP ###\n","[09:40:39.246870] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.246883] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.246898] Padding: (8, 8, 8)\n","[09:40:39.246997] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.247018] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.247031] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.249181] **** New data shape is: (64, 64, 64, 1)\n","[09:40:39.249225] ### END MERGE-3D-OV-CROP ###\n","[09:40:39.249307] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.253851] Capturing the local maxima \n","[09:40:39.253891] Class 1\n","[09:40:39.266099] Removing close points . . .\n","[09:40:39.266134] Initial number of points: 109\n","[09:40:39.267236] Final number of points: 79\n","[09:40:39.267312] Creating the images with detected points . . .\n","[09:40:39.283842] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.302486] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.308100] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:39.308138] Its respective CSV file seems to be: /content/data/test/y/mask_023.csv\n","[09:40:39.308156] Reading GT data from: /content/data/test/y/mask_023.csv\n","[09:40:39.310016] Detection (class 1)\n","[09:40:39.312574] Points in ground truth: 112, Points in prediction: 79\n","[09:40:39.312609] True positives: 75, False positives: 4, False negatives: 37\n","[09:40:39.312647] Detection metrics: ['Precision', 0.9493670886075949, 'Recall', 0.6696428571428571, 'F1', 0.7853403141361256]\n","[09:40:39.314618] All classes 1\n","[09:40:39.314660] Detection metrics: ['Precision', 0.9493670886075949, 'Recall', 0.6696428571428571, 'F1', 0.7853403141361256]\n","[09:40:39.314681] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:39.363258] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.434913] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.31it/s]\u001b[A\n"," 89% 24/27 [00:15<00:01,  2.09it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:39.439835] Processing image(s): ['vol_024.tif']\n","[09:40:39.439985] ### 3D-OV-CROP ###\n","[09:40:39.440023] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.440044] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.440068] Padding: (8, 8, 8)\n","[09:40:39.441673] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.441719] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.441737] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.443970] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:39.444005] ### END 3D-OV-CROP ###\n","[09:40:39.444048] ### 3D-OV-CROP ###\n","[09:40:39.444070] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.444090] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.444116] Padding: (8, 8, 8)\n","[09:40:39.444685] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.444721] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.444751] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.445170] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:39.445196] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.96it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.677808] ### MERGE-3D-OV-CROP ###\n","[09:40:39.677868] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.677882] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.677895] Padding: (8, 8, 8)\n","[09:40:39.678180] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.678199] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.678215] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.680543] **** New data shape is: (64, 64, 64, 1)\n","[09:40:39.680578] ### END MERGE-3D-OV-CROP ###\n","[09:40:39.680615] ### MERGE-3D-OV-CROP ###\n","[09:40:39.680636] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.680656] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.680674] Padding: (8, 8, 8)\n","[09:40:39.680802] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.680820] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.680838] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.683152] **** New data shape is: (64, 64, 64, 1)\n","[09:40:39.683201] ### END MERGE-3D-OV-CROP ###\n","[09:40:39.683309] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.690888] Capturing the local maxima \n","[09:40:39.690947] Class 1\n","[09:40:39.708782] Removing close points . . .\n","[09:40:39.708825] Initial number of points: 88\n","[09:40:39.710417] Final number of points: 63\n","[09:40:39.710506] Creating the images with detected points . . .\n","[09:40:39.738826] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.759216] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.764815] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:39.764860] Its respective CSV file seems to be: /content/data/test/y/mask_024.csv\n","[09:40:39.764874] Reading GT data from: /content/data/test/y/mask_024.csv\n","[09:40:39.767009] Detection (class 1)\n","[09:40:39.769234] Points in ground truth: 82, Points in prediction: 63\n","[09:40:39.769272] True positives: 59, False positives: 4, False negatives: 23\n","[09:40:39.769311] Detection metrics: ['Precision', 0.9365079365079365, 'Recall', 0.7195121951219512, 'F1', 0.8137931034482758]\n","[09:40:39.771256] All classes 1\n","[09:40:39.771304] Detection metrics: ['Precision', 0.9365079365079365, 'Recall', 0.7195121951219512, 'F1', 0.8137931034482758]\n","[09:40:39.771328] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:39.814692] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:39.866068] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.33it/s]\u001b[A\n"," 93% 25/27 [00:15<00:00,  2.16it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:39.869666] Processing image(s): ['vol_025.tif']\n","[09:40:39.869763] ### 3D-OV-CROP ###\n","[09:40:39.869785] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.869810] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.869826] Padding: (8, 8, 8)\n","[09:40:39.870574] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.870609] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.870625] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.872748] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:39.872780] ### END 3D-OV-CROP ###\n","[09:40:39.872822] ### 3D-OV-CROP ###\n","[09:40:39.872843] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:39.872867] Minimum overlap selected: (0, 0, 0)\n","[09:40:39.872881] Padding: (8, 8, 8)\n","[09:40:39.873337] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:39.873369] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:39.873381] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:39.873828] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:39.873858] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.06it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.105025] ### MERGE-3D-OV-CROP ###\n","[09:40:40.105087] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:40.105111] Minimum overlap selected: (0, 0, 0)\n","[09:40:40.105127] Padding: (8, 8, 8)\n","[09:40:40.105414] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:40.105435] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:40.105456] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:40.107852] **** New data shape is: (64, 64, 64, 1)\n","[09:40:40.107914] ### END MERGE-3D-OV-CROP ###\n","[09:40:40.107963] ### MERGE-3D-OV-CROP ###\n","[09:40:40.107981] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:40.108001] Minimum overlap selected: (0, 0, 0)\n","[09:40:40.108015] Padding: (8, 8, 8)\n","[09:40:40.108142] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:40.108166] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:40.108180] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:40.110394] **** New data shape is: (64, 64, 64, 1)\n","[09:40:40.110425] ### END MERGE-3D-OV-CROP ###\n","[09:40:40.110532] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.115352] Capturing the local maxima \n","[09:40:40.115395] Class 1\n","[09:40:40.129844] Removing close points . . .\n","[09:40:40.129881] Initial number of points: 333\n","[09:40:40.132950] Final number of points: 249\n","[09:40:40.133069] Creating the images with detected points . . .\n","[09:40:40.149738] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.168652] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.177194] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:40.177236] Its respective CSV file seems to be: /content/data/test/y/mask_025.csv\n","[09:40:40.177251] Reading GT data from: /content/data/test/y/mask_025.csv\n","[09:40:40.179253] Detection (class 1)\n","[09:40:40.187196] Points in ground truth: 330, Points in prediction: 249\n","[09:40:40.187250] True positives: 245, False positives: 4, False negatives: 85\n","[09:40:40.187294] Detection metrics: ['Precision', 0.9839357429718876, 'Recall', 0.7424242424242424, 'F1', 0.8462867012089811]\n","[09:40:40.191078] All classes 1\n","[09:40:40.191125] Detection metrics: ['Precision', 0.9839357429718876, 'Recall', 0.7424242424242424, 'F1', 0.8462867012089811]\n","[09:40:40.191147] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:40.365265] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.455596] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.70it/s]\u001b[A\n"," 96% 26/27 [00:16<00:00,  1.99it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:40:40.460883] Processing image(s): ['vol_026.tif']\n","[09:40:40.461038] ### 3D-OV-CROP ###\n","[09:40:40.461069] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:40.461090] Minimum overlap selected: (0, 0, 0)\n","[09:40:40.461109] Padding: (8, 8, 8)\n","[09:40:40.462148] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:40.463221] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:40.463253] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:40.465767] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:40.465817] ### END 3D-OV-CROP ###\n","[09:40:40.465891] ### 3D-OV-CROP ###\n","[09:40:40.465919] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:40.465942] Minimum overlap selected: (0, 0, 0)\n","[09:40:40.465964] Padding: (8, 8, 8)\n","[09:40:40.466782] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:40.466832] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:40.466869] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:40.467563] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:40:40.467602] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.13it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.704936] ### MERGE-3D-OV-CROP ###\n","[09:40:40.705009] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:40.705032] Minimum overlap selected: (0, 0, 0)\n","[09:40:40.705053] Padding: (8, 8, 8)\n","[09:40:40.705424] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:40.705456] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:40.705487] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:40.708458] **** New data shape is: (64, 64, 64, 1)\n","[09:40:40.708520] ### END MERGE-3D-OV-CROP ###\n","[09:40:40.708572] ### MERGE-3D-OV-CROP ###\n","[09:40:40.708599] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:40:40.708621] Minimum overlap selected: (0, 0, 0)\n","[09:40:40.708644] Padding: (8, 8, 8)\n","[09:40:40.708834] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:40:40.708869] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:40:40.708890] (2, 2, 2) patches per (z,y,x) axis\n","[09:40:40.711852] **** New data shape is: (64, 64, 64, 1)\n","[09:40:40.711897] ### END MERGE-3D-OV-CROP ###\n","[09:40:40.712011] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.719580] Capturing the local maxima \n","[09:40:40.719633] Class 1\n","[09:40:40.735441] Removing close points . . .\n","[09:40:40.735503] Initial number of points: 29\n","[09:40:40.736188] Final number of points: 22\n","[09:40:40.736258] Creating the images with detected points . . .\n","[09:40:40.765981] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.799193] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.805909] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:40:40.805962] Its respective CSV file seems to be: /content/data/test/y/mask_026.csv\n","[09:40:40.805985] Reading GT data from: /content/data/test/y/mask_026.csv\n","[09:40:40.808604] Detection (class 1)\n","[09:40:40.811621] Points in ground truth: 30, Points in prediction: 22\n","[09:40:40.811665] True positives: 22, False positives: 0, False negatives: 8\n","[09:40:40.811703] Detection metrics: ['Precision', 1.0, 'Recall', 0.7333333333333333, 'F1', 0.846153846153846]\n","[09:40:40.813532] All classes 1\n","[09:40:40.813585] Detection metrics: ['Precision', 1.0, 'Recall', 0.7333333333333333, 'F1', 0.846153846153846]\n","[09:40:40.813613] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:40:40.859225] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:40:40.950388] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.03it/s]\u001b[A\n","100% 27/27 [00:16<00:00,  1.63it/s]\n","[09:40:40.954077] Releasing memory . . .\n","[09:40:40.954127] #############\n","[09:40:40.954146] #  RESULTS  #\n","[09:40:40.954165] #############\n","[09:40:40.954193] Epoch number: 100\n","[09:40:40.954213] Train time (s): 0:08:51\n","[09:40:40.954317] Train loss: 0.04241615658005079\n","[09:40:40.954413] Train jaccard_index: 0.10018169383207957\n","[09:40:40.954509] Validation loss: 0.010198673233389854\n","[09:40:40.954576] Validation jaccard_index: 0.06271477788686752\n","[09:40:40.954907] Loss (per patch): 0.08728363392529664\n","[09:40:40.954941] Test Foreground IoU (per patch): 0.011193951330992772\n","[09:40:40.954961]  \n","[09:40:40.954987] Test Foreground IoU (merge patches): 0.09888986005299272\n","[09:40:40.955009] Test Overall IoU (merge patches): 0.5450139263164123\n","[09:40:40.955028]  \n","[09:40:40.955053] Detection specific metrics:\n","[09:40:40.955083] Detection - Test Precision (merge patches): 0.9748025444636623\n","[09:40:40.955104] Detection - Test Recall (merge patches): 0.7117821597342823\n","[09:40:40.955124] Detection - Test F1 (merge patches): 0.82052450034474\n","[09:40:40.955180] FINISHED JOB my_3d_detection_1 !!\n"]}],"source":["#@markdown ##Play to train the model\n","\n","import os\n","import errno\n","\n","# Run the code\n","biapy = BiaPy(f'/content/{job_name}.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n","biapy.run_job()\n"]},{"cell_type":"markdown","metadata":{"id":"k4i0N2vOWUes"},"source":["## **Inspection of the Loss Function and the Intersection over Union (IoU)**\n","---\n","\n","Before proceeding with interpretations, it's pivotal to gauge the training evolution by juxtaposing the training loss against the validation loss. The validation loss casts light on the model's efficacy over a reserved subset of data unseen during training. A deeper understanding can be garnered from [this review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381354/) by Nichols *et al.*\n","\n","- **Training Loss**: This captures the discrepancy between the model's predictions and the actual ground-truth after each epoch.\n","\n","- **Validation Loss**: This signifies the error between the model's estimates on validation images and their actual counterparts.\n","\n","As training unfurls, these metrics are expected to wane, eventually plateauing at an optimal, minimal value. Contrasting the trajectories of these losses can yield vital information about the model's adaptability.\n","\n","- **Decreasing Training and Validation Losses**: This trend is indicative of potential model improvements with further training. Elevating the `number_of_epochs` is advised in such scenarios. Notably, even if the loss curves seem to stabilize towards the tail end, it might be a mere visual effect due to y-axis scaling. The model is considered convergent once the curves genuinely flatten, marking the end of required training.\n","\n","- **Divergent Losses**: An upward tick in validation loss while training loss gravitates towards zero hints at overfitting. It suggests that the model is intricately memorizing training patterns at the cost of broader applicability. A more substantial training dataset can alleviate this.\n","\n","The **Jaccard Index, also known as the Intersection over Union (IoU)**, offers a means to evaluate the overlap between the target mask and prediction. **A score inching towards 1 denotes optimal performance.** It's a handy metric to gauge the precision of your model in predicting cellular structures."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1696930844445,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"ur21krhZVwX2","outputId":"87e9c953-f07d-4e17-eae4-cee0e5d41467"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 2000x1000 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#@markdown ##Play the cell to show a plot of training error vs. epoch number and IoU vs epoch number\n","import matplotlib.pyplot as plt\n","\n","loss_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_loss.png' )\n","\n","iou_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_jaccard_index.png' )\n","\n","fig = plt.figure( figsize = (20,10))\n","ax1 = plt.subplot( 1, 2, 1 )\n","_ = plt.imshow( loss_plot )\n","_ = plt.axis('off')\n","ax1.set_title( 'Training error vs epoch number', fontdict = {'fontsize':22})\n","\n","ax2 = plt.subplot( 1, 2, 2 )\n","_ = plt.imshow( iou_plot )\n","_ = plt.axis('off')\n","_= ax2.set_title( 'Intersection over Union (IoU) vs epoch number', fontdict = {'fontsize':22})"]},{"cell_type":"markdown","metadata":{"id":"30kYCWjYI9W1"},"source":["## **Visualize detection results**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":957,"referenced_widgets":["760ed0fcb3c64f77b0f3da60c9c4ef8f","116efa2f2c8f4a1da5dc2e6784cb773e","fb59d1b43e3c4eb08515510741560681","f954818d61ad4b50aa6bb8d2d9c5d844","41de6ed4d5d6400b951d042e5c65f8fc","28a039a75628480499e7295024ddad9c","4f9a2d4f9f454f3da117442061ca2d26","78d58827cd31400cb6656d621de5614e","d2a4ca39d9274771b8ad52aaca0aa2bc","a42d291db45d425c91cd175ceabbd89b","c3ae580c9f0d442f8662f9fa3746b557","bb964aa6be29492daf61e24e1c499fd0","7e89179600d04a96a0e28127347acab3","720e3800ea4a4946b45b9fcde630726f","7f7b34acb64f4e9abfd0e320a5af0d7e","7f31f2ebd3404642bac814f10659d8b2","0ac71c7c1ece465abe04f3c8f30cb2e5","80bebf64067f4e128468a1ac49b6bf42","ea76d7746cd342c6b6373cca75b4788e","746e0d99c2a9419292baf56de051f3f2","e59fb4c60658448db5d27c219852be36"]},"executionInfo":{"elapsed":926,"status":"ok","timestamp":1696930845364,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"cEIcTV3Tj6OJ","outputId":"65401bb8-32f6-46fd-b300-b7865ae35130"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"760ed0fcb3c64f77b0f3da60c9c4ef8f","version_major":2,"version_minor":0},"text/plain":["interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78d58827cd31400cb6656d621de5614e","version_major":2,"version_minor":0},"text/plain":["interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f7b34acb64f4e9abfd0e320a5af0d7e","version_major":2,"version_minor":0},"text/plain":["interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in…"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#@markdown ###Play to visualize results in 3D\n","#@markdown In the rightmost column, associations between predictions and ground truth are illustrated:\n","#@markdown - **Green**: True positives\n","#@markdown - **Red**: False negatives\n","#@markdown - **Blue**: False positives\n","\n","%matplotlib inline\n","import matplotlib\n","import numpy as np\n","from numpy.random import randint, seed\n","from matplotlib import pyplot as plt\n","from ipywidgets import interact, fixed\n","import ipywidgets as widgets\n","from google.colab import output\n","\n","# output.enable_custom_widget_manager()\n","\n","final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n","detection_results = os.path.join(final_results, \"per_image_local_max_check\")\n","assoc_results = os.path.join(final_results, \"point_associations\")\n","if test_ground_truth:\n","    test_data_gt_path = \"/content/data/test/y_detection_masks\"\n","\n","# Show a few examples to check that they have been stored correctly\n","ids_pred = sorted(next(os.walk(detection_results))[2])\n","ids_pred = [x for x in ids_pred if not x.endswith('.csv') ]\n","ids_assoc = sorted(next(os.walk(assoc_results))[2])\n","ids_assoc = [x for x in ids_assoc if not x.endswith('.csv') ]\n","ids_assoc = [x for x in ids_assoc if \"_gt_ids\" not in x ]\n","ids_assoc = [x for x in ids_assoc if \"_pred_ids\" not in x ]\n","ids_input = sorted(next(os.walk(test_data_path))[2])\n","if test_ground_truth:\n","    ids_gt = sorted(next(os.walk(test_data_gt_path))[2])\n","\n","# create random color map\n","vals = np.linspace(0,1,256)\n","np.random.shuffle(vals)\n","cmap = plt.cm.colors.ListedColormap(plt.cm.gist_rainbow(vals))\n","cmap.colors[0] = [0., 0., 0., 1.] # set background to black\n","\n","samples_to_show = min(len(ids_input), 3)\n","chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n","seed(1)\n","\n","test_samples = []\n","test_sample_preds = []\n","if test_ground_truth:\n","    test_sample_gt = []\n","    test_sample_assoc = []\n","\n","# read 3D images again\n","for i in range(len(chosen_images)):\n","    aux = imread(os.path.join(test_data_path, ids_input[chosen_images[i]]))\n","    test_samples.append(np.squeeze(aux))\n","\n","    aux = imread(os.path.join(detection_results, ids_pred[chosen_images[i]])).astype(np.uint16)\n","    test_sample_preds.append(np.squeeze(aux))\n","\n","    if test_ground_truth:\n","        aux = imread(os.path.join(test_data_gt_path, ids_gt[chosen_images[i]])).astype(np.uint16)\n","        test_sample_gt.append(np.squeeze(aux))\n","\n","        aux = imread(os.path.join(assoc_results, ids_assoc[chosen_images[i]]))\n","        test_sample_assoc.append(np.squeeze(aux))\n","\n","# function to show results in 3D within a widget\n","def scroll_in_z(z, j):\n","    plt.figure(figsize=(25,5))\n","    # Source\n","    plt.subplot(1,4,1)\n","    plt.axis('off')\n","    plt.imshow(test_samples[j][z-1], cmap='gray')\n","    plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n","\n","    # Prediction\n","    plt.subplot(1,4,3)\n","    plt.axis('off')\n","    plt.imshow(test_sample_preds[j][z-1], cmap=cmap, interpolation='nearest')\n","    plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n","\n","    if test_ground_truth:\n","        # Target (Ground-truth)\n","        plt.subplot(1,4,2)\n","        plt.axis('off')\n","        plt.imshow(test_sample_gt[j][z-1], cmap=cmap, interpolation='nearest')\n","        plt.title('Ground truth (z = ' + str(z) + ')', fontsize=15)\n","\n","        # Overlay\n","        plt.subplot(1,4,4)\n","        plt.axis('off')\n","        plt.imshow(test_sample_assoc[j][z-1], interpolation='nearest')\n","        plt.title('Associations (z = ' + str(z) + ')', fontsize=15)\n","\n","for j in range(samples_to_show):\n","    interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_samples[j].shape[0], step=1, value=test_samples[j].shape[0]//2), j=fixed(j));"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"mlQnAH6uAawl","outputId":"bde6eadb-092e-4870-e805-a0aa20e3879f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output paths:\n","    Detection files are in /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"]}],"source":["#@markdown ###Play to display the path to the output files (one 3D TIFF label image for each input image).\n","\n","final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n","\n","detection_results = os.path.join(final_results, \"per_image_local_max_check\")\n","\n","print(\"Output paths:\")\n","print(\"    Detection files are in {}\".format(detection_results))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"VwabL1znb1h7","outputId":"77bc8565-3589-4ec7-c885-6f65a8a78d66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output paths:\n","    Detection files are in /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"]}],"source":["#@markdown ###Play to display the path to the association files (one 3D TIFF label image for each input image).\n","\n","final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n","\n","detection_assoc_results = os.path.join(final_results, \"point_associations\")\n","\n","print(\"Output paths:\")\n","print(\"    Detection files are in {}\".format(detection_results))"]},{"cell_type":"markdown","metadata":{"id":"zdCIYo4ohcAw"},"source":["## **Download detection results**"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"id":"gnRa9DOUP0FM","outputId":"e3a120af-1594-4e53-bb31-e6295a109094"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_9972b2b8-0cd4-4077-a54b-6a5e68907fea\", \"detection.zip\", 175589)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["#@markdown ###Play to download a zip file with all detection results in test.\n","\n","from google.colab import files\n","\n","!zip -q -j /content/detection.zip $detection_results/*.tif\n","\n","files.download(\"/content/detection.zip\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"id":"cOkH_YgqX0l2","outputId":"0bac80c9-4426-4092-937d-10ea253f774d"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_a15ab68c-c8f5-4acc-8e1a-2a512912ddbf\", \"detection_associations.zip\", 791332)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["#@markdown ### Click to Download a ZIP File with All Detection Association Results from Testing\n","#@markdown For each test sample, several files are expected:\n","#@markdown - '*_fn.csv': Contains the false positives (FPs)\n","#@markdown - '*_gt_assoc.csv': Houses the associations between ground truth (GT) and prediction, encompassing both true positives (TP) and false negatives (FN)\n","#@markdown - '*_gt_ids.tif': Represents labels for ground truth points\n","#@markdown - '*_pred_ids.tif': Contains labels for predicted points\n","#@markdown - '*.tif': Showcases associations between GT and predictions with colored indicators:\n","#@markdown   - **Green**: True positives (TP)\n","#@markdown   - **Red**: False negatives (FN)\n","#@markdown   - **Blue**: False positives (FP)\n","\n","from google.colab import files\n","\n","\n","!zip -q -j /content/detection_associations.zip $detection_assoc_results/*.tif\n","\n","files.download(\"/content/detection_associations.zip\")\n"]},{"cell_type":"markdown","metadata":{"id":"Kwt72WYddVgl"},"source":["## **Download train model (weights and configuration file)**\n","If you want to **reuse the train model in the future**, you can download both the model weights and its configuration file (.YAML) by running the following cells."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"id":"XoFclBfEduZC","outputId":"6886ef7c-453d-4f0e-bfa2-e0deb21663ef"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_087df531-2b63-4abb-a826-4d6d702616bb\", \"model_weights_my_3d_instance_segmentation_1.h5\", 8366600)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","\n","#@markdown ###Play to download the model weights\n","\n","checkpoints_path = os.path.join(output_path, job_name, 'checkpoints')\n","\n","weights_filename = str( job_name ) + '_1-checkpoint-best.pth'\n","\n","files.download( os.path.join( checkpoints_path, weights_filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"id":"raDdSsz1dujE","outputId":"deac9145-d0f1-4426-ddad-13f34126f4f0"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_32a5000b-a7f2-4315-9748-8d2c8ae8fb41\", \"my_3d_instance_segmentation.yaml\", 1049)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["#@markdown ###Play to download the model configuration file (.YAML)\n","\n","config_path = os.path.join(output_path, job_name, 'config_files')\n","\n","files.download( os.path.join( config_path, yaml_file))"]},{"cell_type":"markdown","metadata":{},"source":["### **Export your model to BioImage Model Zoo format:**\n","\n","If you want to export the model into the [BioImage Model Zoo](https://bioimage.io/#/) format, fill the metadata and run the following cell. After the cell is run a `trained_model_name.bmz.zip` file will be downloaded."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ------------- User input ------------\n","# information about the model\n","#@markdown ##Introduce the metadata of the model architecture to export the model to BioImage Model Zoo format:\n","export_bioimage_model_zoo = False #@param {type:\"boolean\"}\n","trained_model_name    = \"\" #@param {type:\"string\"}\n","trained_model_authors =  \"[First Author, Second Author, Third Author]\" #@param {type:\"string\"}\n","trained_model_authors_affiliation =  \"[First Author Affiliation, Second Author Affiliation, Third Author Affiliation]\" #@param {type:\"string\"}\n","trained_model_description = \"\" #@param {type:\"string\"}\n","trained_model_license = 'CC-BY-4.0'#@param {type:\"string\"}\n","trained_model_references = [\"Ronneberger et al. arXiv in 2015\",\n","                            \"Franco-Barranco, Daniel, et al. ISBI in 2023\"]\n","trained_model_DOI = [\"10.1007/978-3-319-24574-4_28\",\"10.1109/ISBI53787.2023.10230593\"] #@param {type:\"string\"}\n","trained_model_tags = \"modality: electron-microscopy, content: mitochondria\" #@param {type:\"string\"}\n","trained_model_documentation = \"/content/README.md\" #@param {type:\"string\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@markdown ###Play to download a zip file with your [BioImage Model Zoo](https://bioimage.io/#/) exported model\n","# update BMZ export parameters\n","from google.colab import files\n","\n","if export_bioimage_model_zoo:\n","    # create the author spec input\n","    auth_names = trained_model_authors[1:-1].split(\",\")\n","    auth_affs = trained_model_authors_affiliation[1:-1].split(\",\")\n","    assert len(auth_names) == len(auth_affs)\n","    authors = [{\"name\": auth_name, \"affiliation\": auth_aff} for auth_name, auth_aff in zip(auth_names, auth_affs)]\n","\n","    # create the citation input spec\n","    assert len(trained_model_DOI) == len(trained_model_references)\n","    citations = [{'text': text, 'doi': doi} for text, doi in zip(trained_model_references, trained_model_DOI)]\n","\n","    tags = [{t.split(\":\")[0]: t.split(\":\")[1]} for t in trained_model_tags.split(\",\")]\n","\n","    with open(trained_model_documentation, \"w\") as f:\n","        f.write(\"### **Description**\\n\")\n","        f.write(f\"{trained_model_description}\\n\\n\")\n","        f.write(\"This model was created using the [BiaPy library](https://biapyx.github.io/).\\n\")\n","\n","\n","    final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n","    bmz_results = os.path.join(final_results, \"bmz_model\")\n","\n","\n","    bmz_cfg = {}\n","    # Description of the model\n","    bmz_cfg['description'] = trained_model_description \n","    # Authors of the model. Need to be a list of dicts, e.g. authors=[{\"name\": \"Gizmo\"}]\n","    bmz_cfg['authors'] = authors\n","    # License of the model. E.g. \"CC-BY-4.0\"\n","    bmz_cfg['license'] = trained_model_license\n","    # List of dictionaries of citations associated, e.g. [{\"text\": \"Gizmo et al.\", \"doi\": \"doi:10.1002/xyzacab123\"}]\n","    bmz_cfg['tags'] = tags\n","    # Tags to make models more findable on the website, e.g. tags=[{'modality': 'electron-microscopy', 'content': 'mitochondria'}]\n","    bmz_cfg['cite'] = citations\n","    # Path to a file with a documentation of the model in markdown, e.g. \"my-model/doc.md\"\n","    bmz_cfg['doc'] = trained_model_documentation\n","    bmz_cfg['build_dir'] = bmz_results\n","    \n","    biapy.export_model_to_bmz(bmz_cfg)\n","\n","\n","    bmz_zip_path = f\"/content/{trained_model_name}.bmz.zip\"\n","    if os.path.isdir(bmz_results):\n","        !zip -r $bmz_zip_path $bmz_results\n","    else:\n","        print(\"The model was not exported to this format\")\n","\n","    files.download(bmz_zip_path)"]},{"cell_type":"markdown","metadata":{"id":"ObM24OqXIIEL"},"source":["## **Advanced options**"]},{"cell_type":"markdown","metadata":{"id":"eYWec6IqNzIH"},"source":["### **Adjust detection threshold values**"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"OyTutXhTIwTO"},"outputs":[],"source":["#@markdown ### Detection parameters:\n","min_value_to_be_peak = 0.5 #@param {type:\"number\"}\n","tolerance = 10 #@param {type:\"number\"}\n","remove_close_points = True #@param {type:\"boolean\"}\n","remove_close_points_radius= 3 #@param {type:\"number\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1696930865573,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"lUddfofTKffT","outputId":"7e219583-d994-40bb-8ecd-f58029b40145"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inference configuration finished.\n"]}],"source":["#@markdown ### Play to create inference YAML with new parameters\n","# Transcribe model architecture\n","\n","biapy_config_inference = biapy_config\n","\n","# set the training to false to peform inference\n","biapy_config_inference['TRAIN']['ENABLE'] = False\n","\n","# Detection parameters\n","biapy_config_inference['PROBLEM']['DETECTION']['CENTRAL_POINT_DILATION'] = central_point_dilation\n","biapy_config_inference['TEST']['DET_MIN_TH_TO_BE_PEAK'] = [min_value_to_be_peak]\n","biapy_config_inference['TEST']['DET_TOLERANCE'] = [tolerance]\n","biapy_config_inference['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS'] = remove_close_points\n","biapy_config_inference['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS_RADIUS'] = [remove_close_points_radius]\n","\n","\n","# save file\n","inference_file = \"/content/\"+str(job_name)+\"_inference.yaml\"\n","\n","with open( inference_file, 'w') as outfile:\n","    yaml.dump(biapy_config_inference, outfile, default_flow_style=False)\n","\n","print( \"Inference configuration finished.\")"]},{"cell_type":"markdown","metadata":{"id":"B4msBG9zOE64"},"source":["### **Run inference**"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25719,"status":"ok","timestamp":1696930893469,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"XCUY_JxANO9_","outputId":"1cfd1d97-398d-49e7-85d1-339ad3a462f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Date: 2023-10-10 09:41:11\n","Arguments: Namespace(config='/content/my_3d_detection_inference.yaml', result_dir='/content/output', name='my_3d_detection', run_id=1, gpu='0', world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n","Job: my_3d_detection_1\n","Python       : 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","PyTorch:  2.0.1+cu118\n","Not using distributed mode\n","[09:41:11.103228] Configuration details:\n","[09:41:11.103279] AUGMENTOR:\n","  AFFINE_MODE: constant\n","  AUG_NUM_SAMPLES: 10\n","  AUG_SAMPLES: True\n","  BRIGHTNESS: False\n","  BRIGHTNESS_EM: False\n","  BRIGHTNESS_EM_FACTOR: (-0.1, 0.1)\n","  BRIGHTNESS_EM_MODE: 3D\n","  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n","  BRIGHTNESS_MODE: 3D\n","  CBLUR_DOWN_RANGE: (2, 8)\n","  CBLUR_INSIDE: True\n","  CBLUR_SIZE: (0.2, 0.4)\n","  CHANNEL_SHUFFLE: False\n","  CMIX_SIZE: (0.2, 0.4)\n","  CNOISE_NB_ITERATIONS: (1, 3)\n","  CNOISE_SCALE: (0.05, 0.1)\n","  CNOISE_SIZE: (0.2, 0.4)\n","  CONTRAST: False\n","  CONTRAST_EM: False\n","  CONTRAST_EM_FACTOR: (-0.1, 0.1)\n","  CONTRAST_EM_MODE: 3D\n","  CONTRAST_FACTOR: (-0.1, 0.1)\n","  CONTRAST_MODE: 3D\n","  COUT_APPLY_TO_MASK: False\n","  COUT_CVAL: 0.0\n","  COUT_NB_ITERATIONS: (1, 3)\n","  COUT_SIZE: (0.05, 0.3)\n","  CUTBLUR: False\n","  CUTMIX: False\n","  CUTNOISE: False\n","  CUTOUT: False\n","  DA_PROB: 0.5\n","  DRAW_GRID: True\n","  DROPOUT: False\n","  DROP_RANGE: (0, 0.2)\n","  ELASTIC: False\n","  ENABLE: True\n","  E_ALPHA: (12, 16)\n","  E_MODE: constant\n","  E_SIGMA: 4\n","  GAMMA_CONTRAST: False\n","  GAUSSIAN_NOISE: False\n","  GAUSSIAN_NOISE_MEAN: 0.0\n","  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n","  GAUSSIAN_NOISE_VAR: 0.05\n","  GC_GAMMA: (1.25, 1.75)\n","  GRAYSCALE: False\n","  GRIDMASK: False\n","  GRID_D_RANGE: (0.4, 1)\n","  GRID_INVERT: False\n","  GRID_RATIO: 0.6\n","  GRID_ROTATE: 1.0\n","  G_BLUR: False\n","  G_SIGMA: (1.0, 2.0)\n","  HFLIP: True\n","  MB_KERNEL: (3, 7)\n","  MEDIAN_BLUR: False\n","  MISALIGNMENT: False\n","  MISSING_SECTIONS: False\n","  MISSP_ITERATIONS: (10, 30)\n","  MOTB_K_RANGE: (8, 12)\n","  MOTION_BLUR: False\n","  MS_DISPLACEMENT: 16\n","  MS_ROTATE_RATIO: 0.5\n","  PEPPER: False\n","  PEPPER_AMOUNT: 0.05\n","  POISSON_NOISE: False\n","  RANDOM_ROT: False\n","  RANDOM_ROT_RANGE: (-180, 180)\n","  ROT90: False\n","  SALT: False\n","  SALT_AMOUNT: 0.05\n","  SALT_AND_PEPPER: False\n","  SALT_AND_PEPPER_AMOUNT: 0.05\n","  SALT_AND_PEPPER_PROP: 0.5\n","  SHEAR: False\n","  SHEAR_RANGE: (-20, 20)\n","  SHIFT: False\n","  SHIFT_RANGE: (0.1, 0.2)\n","  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n","  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n","  VFLIP: True\n","  ZFLIP: True\n","  ZOOM: False\n","  ZOOM_RANGE: (0.8, 1.2)\n","DATA:\n","  CHECK_GENERATORS: False\n","  EXTRACT_RANDOM_PATCH: False\n","  NORMALIZATION:\n","    CUSTOM_MEAN: -1.0\n","    CUSTOM_STD: -1.0\n","    TYPE: div\n","  PATCH_SIZE: (64, 64, 64, 1)\n","  PROBABILITY_MAP: False\n","  REFLECT_TO_COMPLETE_SHAPE: False\n","  TEST:\n","    ARGMAX_TO_OUTPUT: False\n","    BINARY_MASKS: /content/data/test/x/../bin_mask\n","    CHECK_DATA: True\n","    DETECTION_MASK_DIR: /content/data/test/y_detection_masks\n","    GT_PATH: /content/data/test/y\n","    INSTANCE_CHANNELS_DIR: /content/data/test/x_BC_thick\n","    INSTANCE_CHANNELS_MASK_DIR: /content/data/test/y_BC_thick\n","    IN_MEMORY: True\n","    LOAD_GT: True\n","    MEDIAN_PADDING: False\n","    OVERLAP: (0, 0, 0)\n","    PADDING: (8, 8, 8)\n","    PATH: /content/data/test/x\n","    RESOLUTION: (0.48, 0.51, 0.51)\n","    SSL_SOURCE_DIR: /content/data/test/x_ssl_source\n","    USE_VAL_AS_TEST: False\n","  TRAIN:\n","    CHECK_DATA: True\n","    DETECTION_MASK_DIR: /content/data/train/y_detection_masks\n","    GT_PATH: /content/data/train/y\n","    INSTANCE_CHANNELS_DIR: /content/data/train/x_BC_thick\n","    INSTANCE_CHANNELS_MASK_DIR: /content/data/train/y_BC_thick\n","    IN_MEMORY: True\n","    MINIMUM_FOREGROUND_PER: -1.0\n","    OVERLAP: (0, 0, 0)\n","    PADDING: (0, 0, 0)\n","    PATH: /content/data/train/x\n","    REPLICATE: 0\n","    RESOLUTION: (1, 1, 1)\n","    SSL_SOURCE_DIR: /content/data/train/x_ssl_source\n","  VAL:\n","    BINARY_MASKS: user_data/val/x/../bin_mask\n","    CROSS_VAL: False\n","    CROSS_VAL_FOLD: 1\n","    CROSS_VAL_NFOLD: 5\n","    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n","    DIST_EVAL: True\n","    FROM_TRAIN: True\n","    GT_PATH: user_data/val/y\n","    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n","    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n","    IN_MEMORY: True\n","    OVERLAP: (0, 0, 0)\n","    PADDING: (0, 0, 0)\n","    PATH: user_data/val/x\n","    RANDOM: True\n","    RESOLUTION: (1, 1, 1)\n","    SPLIT_TRAIN: 0.1\n","    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n","  W_BACKGROUND: 0.06\n","  W_FOREGROUND: 0.94\n","LOG:\n","  CHART_CREATION_FREQ: 5\n","  LOG_DIR: /content/output/my_3d_detection/train_logs\n","  LOG_FILE_PREFIX: my_3d_detection_1\n","  TENSORBOARD_LOG_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/tensorboard\n","LOSS:\n","  TYPE: CE\n","MODEL:\n","  ACTIVATION: ELU\n","  ARCHITECTURE: resunet\n","  BATCH_NORMALIZATION: True\n","  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0]\n","  FEATURE_MAPS: [18, 36, 48, 64]\n","  KERNEL_SIZE: 3\n","  LAST_ACTIVATION: sigmoid\n","  LOAD_CHECKPOINT: False\n","  LOAD_CHECKPOINT_EPOCH: best_on_val\n","  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n","  MAE_DEC_HIDDEN_SIZE: 512\n","  MAE_DEC_MLP_DIMS: 2048\n","  MAE_DEC_NUM_HEADS: 16\n","  MAE_DEC_NUM_LAYERS: 8\n","  N_CLASSES: 2\n","  SAVE_CKPT_FREQ: -1\n","  UNETR_DEC_ACTIVATION: relu\n","  UNETR_VIT_HIDD_MULT: 3\n","  UNETR_VIT_NUM_FILTERS: 16\n","  UNET_SR_UPSAMPLE_POSITION: pre\n","  UPSAMPLE_LAYER: convtranspose\n","  VIT_EMBED_DIM: 768\n","  VIT_MLP_RATIO: 4.0\n","  VIT_MODEL: custom\n","  VIT_NORM_EPS: 1e-06\n","  VIT_NUM_HEADS: 12\n","  VIT_NUM_LAYERS: 12\n","  VIT_TOKEN_SIZE: 16\n","  Z_DOWN: [2, 2, 2]\n","PATHS:\n","  CHARTS: /content/output/my_3d_detection/results/my_3d_detection_1/charts\n","  CHECKPOINT: /content/output/my_3d_detection/checkpoints\n","  CHECKPOINT_FILE: \n","  DA_SAMPLES: /content/output/my_3d_detection/results/my_3d_detection_1/aug\n","  GEN_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_check\n","  GEN_MASK_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_mask_check\n","  MAE_CALLBACK_OUT_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/MAE_checks\n","  MEAN_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_mean_value.npy\n","  PROB_MAP_DIR: /content/output/my_3d_detection/prob_map\n","  PROB_MAP_FILENAME: prob_map.npy\n","  PROFILER: /content/output/my_3d_detection/results/my_3d_detection_1/profiler\n","  RESULT_DIR:\n","    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack_post_processing\n","    DET_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","    FULL_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/full_image\n","    FULL_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_binarized\n","    INST_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/instance_associations\n","    PATH: /content/output/my_3d_detection/results/my_3d_detection_1\n","    PER_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","    PER_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_binarized\n","    PER_IMAGE_INSTANCES: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_instances\n","    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_post_processing\n","  STD_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_std_value.npy\n","  TEST_FULL_GT_H5: /content/data/test/y/h5\n","  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/test_BC_instance_channels\n","  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/train_BC_instance_channels\n","  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/val_BC_instance_channels\n","  WATERSHED_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/watershed\n","PROBLEM:\n","  DENOISING:\n","    N2V_MANIPULATOR: uniform_withCP\n","    N2V_NEIGHBORHOOD_RADIUS: 5\n","    N2V_PERC_PIX: 0.198\n","    N2V_STRUCTMASK: False\n","  DETECTION:\n","    CENTRAL_POINT_DILATION: 0\n","    CHECK_POINTS_CREATED: True\n","    DATA_CHECK_MW: True\n","  INSTANCE_SEG:\n","    DATA_CHANNELS: BC\n","    DATA_CHANNEL_WEIGHTS: (1, 1)\n","    DATA_CHECK_MW: True\n","    DATA_CONTOUR_MODE: thick\n","    DATA_MW_TH_BINARY_MASK: 0.5\n","    DATA_MW_TH_CONTOUR: 0.1\n","    DATA_MW_TH_DISTANCE: 1.0\n","    DATA_MW_TH_FOREGROUND: 0.3\n","    DATA_MW_TH_POINTS: 0.5\n","    DATA_MW_TH_TYPE: auto\n","    DATA_REMOVE_AFTER_MW: False\n","    DATA_REMOVE_BEFORE_MW: False\n","    DATA_REMOVE_SMALL_OBJ_AFTER: 100\n","    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n","    DISTANCE_CHANNEL_MASK: True\n","    ERODE_AND_DILATE_FOREGROUND: False\n","    FORE_DILATION_RADIUS: 5\n","    FORE_EROSION_RADIUS: 5\n","    SEED_MORPH_RADIUS: []\n","    SEED_MORPH_SEQUENCE: []\n","  NDIM: 3D\n","  SELF_SUPERVISED:\n","    NOISE: 0.2\n","    PRETEXT_TASK: crappify\n","    RESIZING_FACTOR: 4\n","  SEMANTIC_SEG:\n","    IGNORE_CLASS_ID: 0\n","  SUPER_RESOLUTION:\n","    UPSCALING: 1\n","  TYPE: DETECTION\n","SYSTEM:\n","  NUM_CPUS: 2\n","  NUM_GPUS: 1\n","  PIN_MEM: True\n","  SEED: 0\n","TEST:\n","  ANALIZE_2D_IMGS_AS_3D_STACK: False\n","  AUGMENTATION: False\n","  DET_LOCAL_MAX_COORDS: True\n","  DET_MIN_TH_TO_BE_PEAK: [0.5]\n","  DET_TOLERANCE: [10]\n","  ENABLE: True\n","  EVALUATE: True\n","  MATCHING_SEGCOMPARE: False\n","  MATCHING_STATS: True\n","  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n","  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n","  POST_PROCESSING:\n","    APPLY_MASK: False\n","    CLEAR_BORDER: False\n","    DET_WATERSHED: False\n","    DET_WATERSHED_DONUTS_CLASSES: [-1]\n","    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n","    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n","    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n","    REMOVE_CLOSE_POINTS: True\n","    REMOVE_CLOSE_POINTS_RADIUS: [3]\n","    REPARE_LARGE_BLOBS_SIZE: -1\n","    VORONOI_ON_MASK: False\n","    VORONOI_TH: 0.0\n","    WATERSHED_CIRCULARITY: -1.0\n","    YZ_FILTERING: False\n","    YZ_FILTERING_SIZE: 5\n","    Z_FILTERING: False\n","    Z_FILTERING_SIZE: 5\n","  REDUCE_MEMORY: True\n","  STATS:\n","    FULL_IMG: False\n","    MERGE_PATCHES: True\n","    PER_PATCH: True\n","  VERBOSE: True\n","TRAIN:\n","  ACCUM_ITER: 1\n","  BATCH_SIZE: 8\n","  CHECKPOINT_MONITOR: val_loss\n","  ENABLE: False\n","  EPOCHS: 100\n","  LR: 0.0001\n","  LR_SCHEDULER:\n","    MIN_LR: -1.0\n","    NAME: \n","    REDUCEONPLATEAU_FACTOR: 0.5\n","    REDUCEONPLATEAU_PATIENCE: -1\n","    WARMUP_COSINE_DECAY_EPOCHS: -1\n","  OPTIMIZER: ADAMW\n","  PATIENCE: 20\n","  W_DECAY: 0.05\n","[09:41:11.445533] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n","[09:41:11.445573] Initializing Detection_Workflow\n","[09:41:11.445592] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n","\n","[09:41:11.445732] ####################\n","#  PRE-PROCESSING  #\n","####################\n","\n","[09:41:11.445751] ############################\n","[09:41:11.445764] #  PREPARE DETECTION DATA  #\n","[09:41:11.445775] ############################\n","[09:41:11.445935] DATA.TEST.GT_PATH changed from /content/data/test/y to /content/data/test/y_detection_masks\n","[09:41:11.446183] ######################\n","[09:41:11.446205] #   LOAD TEST DATA   #\n","[09:41:11.446216] ######################\n","[09:41:11.446234] 2) Loading test images . . .\n","[09:41:11.446256] Loading data from /content/data/test/x\n","100% 27/27 [00:00<00:00, 1236.58it/s]\n","[09:41:11.473811] *** Loaded data shape is (27, 64, 64, 64, 1)\n","[09:41:11.473868] 3) Loading test masks . . .\n","[09:41:11.473893] Loading data from /content/data/test/y_detection_masks\n","100% 27/27 [00:00<00:00, 1775.49it/s]\n","[09:41:11.491783] *** Loaded data shape is (27, 64, 64, 64, 1)\n","[09:41:11.491918] ############################\n","[09:41:11.491940] #  PREPARE TEST GENERATOR  #\n","[09:41:11.491955] ############################\n","[09:41:11.492839] ###############\n","[09:41:11.492876] # Build model #\n","[09:41:11.492888] ###############\n","[09:41:15.585137] ==================================================================================================================================\n","Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #\n","==================================================================================================================================\n","ResUNet                                                 [1, 1, 64, 64, 64]        [1, 1, 64, 64, 64]        --\n","├─ModuleList: 1-1                                       --                        --                        --\n","│    └─ResConvBlock: 2-1                                [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    └─Sequential: 3-1                             [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    └─ConvBlock: 4-1                         [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─Sequential: 5-1                   [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Conv3d: 6-1                  [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       504\n","│    │    │    │    │    └─BatchNorm3d: 6-2             [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       36\n","│    │    │    │    │    └─ELU: 6-3                     [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    └─ConvBlock: 4-2                         [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─Sequential: 5-2                   [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Conv3d: 6-4                  [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       8,766\n","│    │    └─Sequential: 3-2                             [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       --\n","│    │    │    └─Conv3d: 4-3                            [1, 1, 64, 64, 64]        [1, 18, 64, 64, 64]       36\n","│    └─ResConvBlock: 2-2                                [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    └─Sequential: 3-3                             [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─BatchNorm3d: 4-4                       [1, 18, 32, 32, 32]       [1, 18, 32, 32, 32]       36\n","│    │    │    └─ELU: 4-5                               [1, 18, 32, 32, 32]       [1, 18, 32, 32, 32]       --\n","│    │    │    └─ConvBlock: 4-6                         [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─Sequential: 5-3                   [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Conv3d: 6-5                  [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       17,532\n","│    │    │    │    │    └─BatchNorm3d: 6-6             [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       72\n","│    │    │    │    │    └─ELU: 6-7                     [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─ConvBlock: 4-7                         [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─Sequential: 5-4                   [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Conv3d: 6-8                  [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       35,028\n","│    │    └─Sequential: 3-4                             [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─Conv3d: 4-8                            [1, 18, 32, 32, 32]       [1, 36, 32, 32, 32]       684\n","│    └─ResConvBlock: 2-3                                [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    └─Sequential: 3-5                             [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    └─BatchNorm3d: 4-9                       [1, 36, 16, 16, 16]       [1, 36, 16, 16, 16]       72\n","│    │    │    └─ELU: 4-10                              [1, 36, 16, 16, 16]       [1, 36, 16, 16, 16]       --\n","│    │    │    └─ConvBlock: 4-11                        [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─Sequential: 5-5                   [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Conv3d: 6-9                  [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       46,704\n","│    │    │    │    │    └─BatchNorm3d: 6-10            [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       96\n","│    │    │    │    │    └─ELU: 6-11                    [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    └─ConvBlock: 4-12                        [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─Sequential: 5-6                   [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Conv3d: 6-12                 [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       62,256\n","│    │    └─Sequential: 3-6                             [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    └─Conv3d: 4-13                           [1, 36, 16, 16, 16]       [1, 48, 16, 16, 16]       1,776\n","├─ResConvBlock: 1-2                                     [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    └─Sequential: 2-4                                  [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    └─BatchNorm3d: 3-7                            [1, 48, 8, 8, 8]          [1, 48, 8, 8, 8]          96\n","│    │    └─ELU: 3-8                                    [1, 48, 8, 8, 8]          [1, 48, 8, 8, 8]          --\n","│    │    └─ConvBlock: 3-9                              [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    └─Sequential: 4-14                       [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    │    └─Conv3d: 5-7                       [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          83,008\n","│    │    │    │    └─BatchNorm3d: 5-8                  [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          128\n","│    │    │    │    └─ELU: 5-9                          [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    └─ConvBlock: 3-10                             [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    └─Sequential: 4-15                       [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    │    │    └─Conv3d: 5-10                      [1, 64, 8, 8, 8]          [1, 64, 8, 8, 8]          110,656\n","│    └─Sequential: 2-5                                  [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          --\n","│    │    └─Conv3d: 3-11                                [1, 48, 8, 8, 8]          [1, 64, 8, 8, 8]          3,136\n","├─ModuleList: 1-3                                       --                        --                        --\n","│    └─ResUpBlock: 2-6                                  [1, 64, 8, 8, 8]          [1, 48, 16, 16, 16]       --\n","│    │    └─ConvTranspose3d: 3-12                       [1, 64, 8, 8, 8]          [1, 64, 16, 16, 16]       32,832\n","│    │    └─ResConvBlock: 3-13                          [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    └─Sequential: 4-16                       [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─BatchNorm3d: 5-11                 [1, 112, 16, 16, 16]      [1, 112, 16, 16, 16]      224\n","│    │    │    │    └─ELU: 5-12                         [1, 112, 16, 16, 16]      [1, 112, 16, 16, 16]      --\n","│    │    │    │    └─ConvBlock: 5-13                   [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Sequential: 6-13             [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    │    └─Conv3d: 7-1             [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       145,200\n","│    │    │    │    │    │    └─BatchNorm3d: 7-2        [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       96\n","│    │    │    │    │    │    └─ELU: 7-3                [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─ConvBlock: 5-14                   [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    └─Sequential: 6-14             [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       --\n","│    │    │    │    │    │    └─Conv3d: 7-4             [1, 48, 16, 16, 16]       [1, 48, 16, 16, 16]       62,256\n","│    │    │    └─Sequential: 4-17                       [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       --\n","│    │    │    │    └─Conv3d: 5-15                      [1, 112, 16, 16, 16]      [1, 48, 16, 16, 16]       5,424\n","│    └─ResUpBlock: 2-7                                  [1, 48, 16, 16, 16]       [1, 36, 32, 32, 32]       --\n","│    │    └─ConvTranspose3d: 3-14                       [1, 48, 16, 16, 16]       [1, 48, 32, 32, 32]       18,480\n","│    │    └─ResConvBlock: 3-15                          [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    └─Sequential: 4-18                       [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─BatchNorm3d: 5-16                 [1, 84, 32, 32, 32]       [1, 84, 32, 32, 32]       168\n","│    │    │    │    └─ELU: 5-17                         [1, 84, 32, 32, 32]       [1, 84, 32, 32, 32]       --\n","│    │    │    │    └─ConvBlock: 5-18                   [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Sequential: 6-15             [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    │    └─Conv3d: 7-5             [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       81,684\n","│    │    │    │    │    │    └─BatchNorm3d: 7-6        [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       72\n","│    │    │    │    │    │    └─ELU: 7-7                [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─ConvBlock: 5-19                   [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    └─Sequential: 6-16             [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    │    │    └─Conv3d: 7-8             [1, 36, 32, 32, 32]       [1, 36, 32, 32, 32]       35,028\n","│    │    │    └─Sequential: 4-19                       [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       --\n","│    │    │    │    └─Conv3d: 5-20                      [1, 84, 32, 32, 32]       [1, 36, 32, 32, 32]       3,060\n","│    └─ResUpBlock: 2-8                                  [1, 36, 32, 32, 32]       [1, 18, 64, 64, 64]       --\n","│    │    └─ConvTranspose3d: 3-16                       [1, 36, 32, 32, 32]       [1, 36, 64, 64, 64]       10,404\n","│    │    └─ResConvBlock: 3-17                          [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    └─Sequential: 4-20                       [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─BatchNorm3d: 5-21                 [1, 54, 64, 64, 64]       [1, 54, 64, 64, 64]       108\n","│    │    │    │    └─ELU: 5-22                         [1, 54, 64, 64, 64]       [1, 54, 64, 64, 64]       --\n","│    │    │    │    └─ConvBlock: 5-23                   [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Sequential: 6-17             [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    │    └─Conv3d: 7-9             [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       26,262\n","│    │    │    │    │    │    └─BatchNorm3d: 7-10       [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       36\n","│    │    │    │    │    │    └─ELU: 7-11               [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─ConvBlock: 5-24                   [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    └─Sequential: 6-18             [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    │    │    └─Conv3d: 7-12            [1, 18, 64, 64, 64]       [1, 18, 64, 64, 64]       8,766\n","│    │    │    └─Sequential: 4-21                       [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       --\n","│    │    │    │    └─Conv3d: 5-25                      [1, 54, 64, 64, 64]       [1, 18, 64, 64, 64]       990\n","├─Conv3d: 1-4                                           [1, 18, 64, 64, 64]       [1, 1, 64, 64, 64]        19\n","==================================================================================================================================\n","Total params: 801,731\n","Trainable params: 801,731\n","Non-trainable params: 0\n","Total mult-adds (G): 22.45\n","==================================================================================================================================\n","Input size (MB): 1.05\n","Forward/backward pass size (MB): 628.42\n","Params size (MB): 3.21\n","Estimated Total Size (MB): 632.68\n","==================================================================================================================================\n","[09:41:15.658337] Loading checkpoint from file /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n","[09:41:15.714414] Model weights loaded!\n","[09:41:15.714846] ###############\n","[09:41:15.714880] #  INFERENCE  #\n","[09:41:15.714898] ###############\n","[09:41:15.714918] Making predictions on test data . . .\n","  0% 0/27 [00:00<?, ?it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:15.717590] Processing image(s): ['vol_000.tif']\n","[09:41:15.717707] ### 3D-OV-CROP ###\n","[09:41:15.717734] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:15.717754] Minimum overlap selected: (0, 0, 0)\n","[09:41:15.717772] Padding: (8, 8, 8)\n","[09:41:15.718548] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:15.718586] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:15.718602] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:15.722786] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:15.722819] ### END 3D-OV-CROP ###\n","[09:41:15.722872] ### 3D-OV-CROP ###\n","[09:41:15.722907] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:15.722927] Minimum overlap selected: (0, 0, 0)\n","[09:41:15.722944] Padding: (8, 8, 8)\n","[09:41:15.723392] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:15.723430] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:15.723447] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:15.724736] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:15.724763] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:01<00:00,  1.97s/it]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:17.812785] ### MERGE-3D-OV-CROP ###\n","[09:41:17.812843] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:17.812864] Minimum overlap selected: (0, 0, 0)\n","[09:41:17.812887] Padding: (8, 8, 8)\n","[09:41:17.813151] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:17.813174] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:17.813197] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:17.815653] **** New data shape is: (64, 64, 64, 1)\n","[09:41:17.815700] ### END MERGE-3D-OV-CROP ###\n","[09:41:17.815738] ### MERGE-3D-OV-CROP ###\n","[09:41:17.815760] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:17.815778] Minimum overlap selected: (0, 0, 0)\n","[09:41:17.815797] Padding: (8, 8, 8)\n","[09:41:17.816054] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:17.816075] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:17.816095] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:17.818552] **** New data shape is: (64, 64, 64, 1)\n","[09:41:17.818595] ### END MERGE-3D-OV-CROP ###\n","[09:41:17.818697] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:17.824456] Capturing the local maxima \n","[09:41:17.824508] Class 1\n","[09:41:17.835614] Removing close points . . .\n","[09:41:17.835648] Initial number of points: 23\n","[09:41:17.835977] Final number of points: 21\n","[09:41:17.836043] Creating the images with detected points . . .\n","[09:41:17.854372] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:17.875637] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:17.882442] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:17.882490] Its respective CSV file seems to be: /content/data/test/y/mask_000.csv\n","[09:41:17.882511] Reading GT data from: /content/data/test/y/mask_000.csv\n","[09:41:17.884495] Detection (class 1)\n","[09:41:17.887507] Points in ground truth: 61, Points in prediction: 21\n","[09:41:17.887539] True positives: 21, False positives: 0, False negatives: 40\n","[09:41:17.887569] Detection metrics: ['Precision', 1.0, 'Recall', 0.3442622950819672, 'F1', 0.5121951219512195]\n","[09:41:17.889181] All classes 1\n","[09:41:17.889227] Detection metrics: ['Precision', 1.0, 'Recall', 0.3442622950819672, 'F1', 0.5121951219512195]\n","[09:41:17.889249] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:17.927003] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:17.995575] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n","  4% 1/27 [00:02<00:59,  2.28s/it]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:17.999677] Processing image(s): ['vol_001.tif']\n","[09:41:17.999778] ### 3D-OV-CROP ###\n","[09:41:17.999802] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:17.999820] Minimum overlap selected: (0, 0, 0)\n","[09:41:17.999838] Padding: (8, 8, 8)\n","[09:41:18.000573] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:18.000611] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:18.000632] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:18.002764] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:18.002798] ### END 3D-OV-CROP ###\n","[09:41:18.002842] ### 3D-OV-CROP ###\n","[09:41:18.002864] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:18.002883] Minimum overlap selected: (0, 0, 0)\n","[09:41:18.002903] Padding: (8, 8, 8)\n","[09:41:18.003355] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:18.003389] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:18.003406] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:18.004016] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:18.004047] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.28it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:18.233437] ### MERGE-3D-OV-CROP ###\n","[09:41:18.233507] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:18.233527] Minimum overlap selected: (0, 0, 0)\n","[09:41:18.233543] Padding: (8, 8, 8)\n","[09:41:18.233815] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:18.233837] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:18.233852] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:18.236118] **** New data shape is: (64, 64, 64, 1)\n","[09:41:18.236162] ### END MERGE-3D-OV-CROP ###\n","[09:41:18.236202] ### MERGE-3D-OV-CROP ###\n","[09:41:18.236223] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:18.236245] Minimum overlap selected: (0, 0, 0)\n","[09:41:18.236265] Padding: (8, 8, 8)\n","[09:41:18.236571] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:18.236597] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:18.236614] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:18.239018] **** New data shape is: (64, 64, 64, 1)\n","[09:41:18.239057] ### END MERGE-3D-OV-CROP ###\n","[09:41:18.239150] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:18.245131] Capturing the local maxima \n","[09:41:18.245188] Class 1\n","[09:41:18.259677] Removing close points . . .\n","[09:41:18.259713] Initial number of points: 317\n","[09:41:18.262507] Final number of points: 300\n","[09:41:18.262597] Creating the images with detected points . . .\n","[09:41:18.279170] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:18.300788] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:18.310423] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:18.310464] Its respective CSV file seems to be: /content/data/test/y/mask_001.csv\n","[09:41:18.310493] Reading GT data from: /content/data/test/y/mask_001.csv\n","[09:41:18.312578] Detection (class 1)\n","[09:41:18.328044] Points in ground truth: 649, Points in prediction: 300\n","[09:41:18.328087] True positives: 300, False positives: 0, False negatives: 349\n","[09:41:18.328137] Detection metrics: ['Precision', 1.0, 'Recall', 0.4622496147919877, 'F1', 0.6322444678609063]\n","[09:41:18.332655] All classes 1\n","[09:41:18.332701] Detection metrics: ['Precision', 1.0, 'Recall', 0.4622496147919877, 'F1', 0.6322444678609063]\n","[09:41:18.332726] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:18.665767] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:18.773284] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.29it/s]\u001b[A\n","  7% 2/27 [00:03<00:34,  1.40s/it]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:18.779146] Processing image(s): ['vol_002.tif']\n","[09:41:18.779280] ### 3D-OV-CROP ###\n","[09:41:18.779307] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:18.779329] Minimum overlap selected: (0, 0, 0)\n","[09:41:18.779350] Padding: (8, 8, 8)\n","[09:41:18.780352] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:18.780416] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:18.780442] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:18.782683] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:18.782725] ### END 3D-OV-CROP ###\n","[09:41:18.782783] ### 3D-OV-CROP ###\n","[09:41:18.782809] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:18.782832] Minimum overlap selected: (0, 0, 0)\n","[09:41:18.782856] Padding: (8, 8, 8)\n","[09:41:18.783640] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:18.783685] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:18.783709] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:18.784362] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:18.784407] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.12it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.030373] ### MERGE-3D-OV-CROP ###\n","[09:41:19.030457] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:19.030493] Minimum overlap selected: (0, 0, 0)\n","[09:41:19.030515] Padding: (8, 8, 8)\n","[09:41:19.030796] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:19.030823] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:19.030851] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:19.033769] **** New data shape is: (64, 64, 64, 1)\n","[09:41:19.033822] ### END MERGE-3D-OV-CROP ###\n","[09:41:19.033885] ### MERGE-3D-OV-CROP ###\n","[09:41:19.033914] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:19.033938] Minimum overlap selected: (0, 0, 0)\n","[09:41:19.033961] Padding: (8, 8, 8)\n","[09:41:19.034129] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:19.034158] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:19.034181] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:19.036923] **** New data shape is: (64, 64, 64, 1)\n","[09:41:19.036966] ### END MERGE-3D-OV-CROP ###\n","[09:41:19.037071] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.045773] Capturing the local maxima \n","[09:41:19.045825] Class 1\n","[09:41:19.061483] Removing close points . . .\n","[09:41:19.061533] Initial number of points: 9\n","[09:41:19.061820] Final number of points: 9\n","[09:41:19.061889] Creating the images with detected points . . .\n","[09:41:19.092321] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.129282] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.136789] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:19.136834] Its respective CSV file seems to be: /content/data/test/y/mask_002.csv\n","[09:41:19.136867] Reading GT data from: /content/data/test/y/mask_002.csv\n","[09:41:19.139298] Detection (class 1)\n","[09:41:19.141107] Points in ground truth: 19, Points in prediction: 9\n","[09:41:19.141151] True positives: 8, False positives: 1, False negatives: 11\n","[09:41:19.141190] Detection metrics: ['Precision', 0.8888888888888888, 'Recall', 0.42105263157894735, 'F1', 0.5714285714285714]\n","[09:41:19.143401] All classes 1\n","[09:41:19.143455] Detection metrics: ['Precision', 0.8888888888888888, 'Recall', 0.42105263157894735, 'F1', 0.5714285714285714]\n","[09:41:19.143500] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:19.181327] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.290772] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.94it/s]\u001b[A\n"," 11% 3/27 [00:03<00:23,  1.00it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:19.297135] Processing image(s): ['vol_003.tif']\n","[09:41:19.297282] ### 3D-OV-CROP ###\n","[09:41:19.297309] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:19.297331] Minimum overlap selected: (0, 0, 0)\n","[09:41:19.297351] Padding: (8, 8, 8)\n","[09:41:19.298451] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:19.298517] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:19.298543] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:19.300806] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:19.300854] ### END 3D-OV-CROP ###\n","[09:41:19.300909] ### 3D-OV-CROP ###\n","[09:41:19.300934] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:19.300954] Minimum overlap selected: (0, 0, 0)\n","[09:41:19.300975] Padding: (8, 8, 8)\n","[09:41:19.301700] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:19.301742] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:19.301764] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:19.302399] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:19.302435] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.25it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.551663] ### MERGE-3D-OV-CROP ###\n","[09:41:19.551734] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:19.551759] Minimum overlap selected: (0, 0, 0)\n","[09:41:19.551781] Padding: (8, 8, 8)\n","[09:41:19.552065] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:19.552094] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:19.552116] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:19.554994] **** New data shape is: (64, 64, 64, 1)\n","[09:41:19.555054] ### END MERGE-3D-OV-CROP ###\n","[09:41:19.555105] ### MERGE-3D-OV-CROP ###\n","[09:41:19.555132] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:19.555154] Minimum overlap selected: (0, 0, 0)\n","[09:41:19.555176] Padding: (8, 8, 8)\n","[09:41:19.555287] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:19.555314] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:19.555336] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:19.558064] **** New data shape is: (64, 64, 64, 1)\n","[09:41:19.558107] ### END MERGE-3D-OV-CROP ###\n","[09:41:19.558213] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.566926] Capturing the local maxima \n","[09:41:19.566976] Class 1\n","[09:41:19.586861] Removing close points . . .\n","[09:41:19.586914] Initial number of points: 225\n","[09:41:19.591154] Final number of points: 209\n","[09:41:19.591254] Creating the images with detected points . . .\n","[09:41:19.621963] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.656603] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:19.668695] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:19.668740] Its respective CSV file seems to be: /content/data/test/y/mask_003.csv\n","[09:41:19.668764] Reading GT data from: /content/data/test/y/mask_003.csv\n","[09:41:19.671401] Detection (class 1)\n","[09:41:19.686612] Points in ground truth: 501, Points in prediction: 209\n","[09:41:19.686651] True positives: 209, False positives: 0, False negatives: 292\n","[09:41:19.686706] Detection metrics: ['Precision', 1.0, 'Recall', 0.4171656686626746, 'F1', 0.5887323943661972]\n","[09:41:19.692758] All classes 1\n","[09:41:19.692807] Detection metrics: ['Precision', 1.0, 'Recall', 0.4171656686626746, 'F1', 0.5887323943661972]\n","[09:41:19.692832] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:19.967212] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.073810] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.28it/s]\u001b[A\n"," 15% 4/27 [00:04<00:20,  1.10it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:20.079362] Processing image(s): ['vol_004.tif']\n","[09:41:20.079532] ### 3D-OV-CROP ###\n","[09:41:20.079565] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.079589] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.079612] Padding: (8, 8, 8)\n","[09:41:20.080652] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.080698] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.080723] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.082944] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:20.082982] ### END 3D-OV-CROP ###\n","[09:41:20.083036] ### 3D-OV-CROP ###\n","[09:41:20.083061] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.083083] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.083104] Padding: (8, 8, 8)\n","[09:41:20.083816] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.083865] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.083890] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.084561] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:20.084597] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.12it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.321650] ### MERGE-3D-OV-CROP ###\n","[09:41:20.321723] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.321747] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.321769] Padding: (8, 8, 8)\n","[09:41:20.322074] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.322102] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.322118] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.325341] **** New data shape is: (64, 64, 64, 1)\n","[09:41:20.325397] ### END MERGE-3D-OV-CROP ###\n","[09:41:20.325453] ### MERGE-3D-OV-CROP ###\n","[09:41:20.325501] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.325525] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.325549] Padding: (8, 8, 8)\n","[09:41:20.325745] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.325780] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.325804] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.329106] **** New data shape is: (64, 64, 64, 1)\n","[09:41:20.329165] ### END MERGE-3D-OV-CROP ###\n","[09:41:20.329290] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.337287] Capturing the local maxima \n","[09:41:20.337341] Class 1\n","[09:41:20.355661] Removing close points . . .\n","[09:41:20.355713] Initial number of points: 123\n","[09:41:20.358036] Final number of points: 106\n","[09:41:20.358153] Creating the images with detected points . . .\n","[09:41:20.389428] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.425287] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.434506] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:20.434559] Its respective CSV file seems to be: /content/data/test/y/mask_004.csv\n","[09:41:20.434585] Reading GT data from: /content/data/test/y/mask_004.csv\n","[09:41:20.437355] Detection (class 1)\n","[09:41:20.444699] Points in ground truth: 259, Points in prediction: 106\n","[09:41:20.444746] True positives: 106, False positives: 0, False negatives: 153\n","[09:41:20.444792] Detection metrics: ['Precision', 1.0, 'Recall', 0.4092664092664093, 'F1', 0.5808219178082191]\n","[09:41:20.448983] All classes 1\n","[09:41:20.449029] Detection metrics: ['Precision', 1.0, 'Recall', 0.4092664092664093, 'F1', 0.5808219178082191]\n","[09:41:20.449055] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:20.597688] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.695660] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.61it/s]\u001b[A\n"," 19% 5/27 [00:04<00:17,  1.24it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:20.700633] Processing image(s): ['vol_005.tif']\n","[09:41:20.700790] ### 3D-OV-CROP ###\n","[09:41:20.700812] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.700824] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.700835] Padding: (8, 8, 8)\n","[09:41:20.701794] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.701834] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.701849] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.704081] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:20.704126] ### END 3D-OV-CROP ###\n","[09:41:20.704190] ### 3D-OV-CROP ###\n","[09:41:20.704218] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.704241] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.704265] Padding: (8, 8, 8)\n","[09:41:20.705093] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.705140] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.705165] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.705936] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:20.705978] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.19it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.946071] ### MERGE-3D-OV-CROP ###\n","[09:41:20.946148] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.946172] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.946192] Padding: (8, 8, 8)\n","[09:41:20.946519] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.946558] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.946579] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.949711] **** New data shape is: (64, 64, 64, 1)\n","[09:41:20.949759] ### END MERGE-3D-OV-CROP ###\n","[09:41:20.949809] ### MERGE-3D-OV-CROP ###\n","[09:41:20.949835] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:20.949856] Minimum overlap selected: (0, 0, 0)\n","[09:41:20.949876] Padding: (8, 8, 8)\n","[09:41:20.949989] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:20.950015] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:20.950036] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:20.953490] **** New data shape is: (64, 64, 64, 1)\n","[09:41:20.953541] ### END MERGE-3D-OV-CROP ###\n","[09:41:20.953667] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:20.961825] Capturing the local maxima \n","[09:41:20.961875] Class 1\n","[09:41:20.978959] Removing close points . . .\n","[09:41:20.979009] Initial number of points: 83\n","[09:41:20.980625] Final number of points: 74\n","[09:41:20.980722] Creating the images with detected points . . .\n","[09:41:21.014515] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.052430] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.060585] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:21.060636] Its respective CSV file seems to be: /content/data/test/y/mask_005.csv\n","[09:41:21.060661] Reading GT data from: /content/data/test/y/mask_005.csv\n","[09:41:21.063409] Detection (class 1)\n","[09:41:21.068797] Points in ground truth: 174, Points in prediction: 74\n","[09:41:21.068838] True positives: 74, False positives: 0, False negatives: 100\n","[09:41:21.068889] Detection metrics: ['Precision', 1.0, 'Recall', 0.42528735632183906, 'F1', 0.596774193548387]\n","[09:41:21.072259] All classes 1\n","[09:41:21.072314] Detection metrics: ['Precision', 1.0, 'Recall', 0.42528735632183906, 'F1', 0.596774193548387]\n","[09:41:21.072343] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:21.203990] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.307412] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.64it/s]\u001b[A\n"," 22% 6/27 [00:05<00:15,  1.35it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:21.313384] Processing image(s): ['vol_006.tif']\n","[09:41:21.313548] ### 3D-OV-CROP ###\n","[09:41:21.313588] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:21.313609] Minimum overlap selected: (0, 0, 0)\n","[09:41:21.313630] Padding: (8, 8, 8)\n","[09:41:21.314733] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:21.314789] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:21.314818] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:21.317422] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:21.317488] ### END 3D-OV-CROP ###\n","[09:41:21.317551] ### 3D-OV-CROP ###\n","[09:41:21.317577] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:21.317601] Minimum overlap selected: (0, 0, 0)\n","[09:41:21.317623] Padding: (8, 8, 8)\n","[09:41:21.318559] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:21.318604] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:21.318628] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:21.319284] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:21.319330] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.12it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.558227] ### MERGE-3D-OV-CROP ###\n","[09:41:21.558300] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:21.558324] Minimum overlap selected: (0, 0, 0)\n","[09:41:21.558345] Padding: (8, 8, 8)\n","[09:41:21.558678] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:21.558717] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:21.558739] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:21.562570] **** New data shape is: (64, 64, 64, 1)\n","[09:41:21.562623] ### END MERGE-3D-OV-CROP ###\n","[09:41:21.562678] ### MERGE-3D-OV-CROP ###\n","[09:41:21.562724] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:21.562748] Minimum overlap selected: (0, 0, 0)\n","[09:41:21.562771] Padding: (8, 8, 8)\n","[09:41:21.562957] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:21.562993] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:21.563017] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:21.566206] **** New data shape is: (64, 64, 64, 1)\n","[09:41:21.566264] ### END MERGE-3D-OV-CROP ###\n","[09:41:21.566419] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.574436] Capturing the local maxima \n","[09:41:21.574518] Class 1\n","[09:41:21.589114] Removing close points . . .\n","[09:41:21.589161] Initial number of points: 11\n","[09:41:21.589519] Final number of points: 9\n","[09:41:21.589592] Creating the images with detected points . . .\n","[09:41:21.627205] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.663730] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.670430] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:21.670496] Its respective CSV file seems to be: /content/data/test/y/mask_006.csv\n","[09:41:21.670522] Reading GT data from: /content/data/test/y/mask_006.csv\n","[09:41:21.673280] Detection (class 1)\n","[09:41:21.676122] Points in ground truth: 22, Points in prediction: 9\n","[09:41:21.676169] True positives: 9, False positives: 0, False negatives: 13\n","[09:41:21.676207] Detection metrics: ['Precision', 1.0, 'Recall', 0.4090909090909091, 'F1', 0.5806451612903226]\n","[09:41:21.677946] All classes 1\n","[09:41:21.678001] Detection metrics: ['Precision', 1.0, 'Recall', 0.4090909090909091, 'F1', 0.5806451612903226]\n","[09:41:21.678028] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:21.722856] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:21.833921] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.91it/s]\u001b[A\n"," 26% 7/27 [00:06<00:13,  1.49it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:21.839460] Processing image(s): ['vol_007.tif']\n","[09:41:21.839652] ### 3D-OV-CROP ###\n","[09:41:21.839686] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:21.839706] Minimum overlap selected: (0, 0, 0)\n","[09:41:21.839726] Padding: (8, 8, 8)\n","[09:41:21.840847] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:21.840912] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:21.840940] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:21.843373] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:21.843421] ### END 3D-OV-CROP ###\n","[09:41:21.843509] ### 3D-OV-CROP ###\n","[09:41:21.843541] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:21.843566] Minimum overlap selected: (0, 0, 0)\n","[09:41:21.843589] Padding: (8, 8, 8)\n","[09:41:21.844414] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:21.844505] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:21.844539] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:21.845543] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:21.845585] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.15it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.091396] ### MERGE-3D-OV-CROP ###\n","[09:41:22.091457] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.091490] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.091515] Padding: (8, 8, 8)\n","[09:41:22.091786] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.091809] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.091825] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.094081] **** New data shape is: (64, 64, 64, 1)\n","[09:41:22.094122] ### END MERGE-3D-OV-CROP ###\n","[09:41:22.094166] ### MERGE-3D-OV-CROP ###\n","[09:41:22.094190] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.094207] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.094225] Padding: (8, 8, 8)\n","[09:41:22.094341] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.094371] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.094392] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.096692] **** New data shape is: (64, 64, 64, 1)\n","[09:41:22.096727] ### END MERGE-3D-OV-CROP ###\n","[09:41:22.096815] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.102220] Capturing the local maxima \n","[09:41:22.102260] Class 1\n","[09:41:22.114181] Removing close points . . .\n","[09:41:22.114217] Initial number of points: 56\n","[09:41:22.114853] Final number of points: 52\n","[09:41:22.114917] Creating the images with detected points . . .\n","[09:41:22.131931] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.154371] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.160095] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:22.160134] Its respective CSV file seems to be: /content/data/test/y/mask_007.csv\n","[09:41:22.160154] Reading GT data from: /content/data/test/y/mask_007.csv\n","[09:41:22.162255] Detection (class 1)\n","[09:41:22.165390] Points in ground truth: 121, Points in prediction: 52\n","[09:41:22.165424] True positives: 52, False positives: 0, False negatives: 69\n","[09:41:22.165457] Detection metrics: ['Precision', 1.0, 'Recall', 0.4297520661157025, 'F1', 0.6011560693641619]\n","[09:41:22.167264] All classes 1\n","[09:41:22.167312] Detection metrics: ['Precision', 1.0, 'Recall', 0.4297520661157025, 'F1', 0.6011560693641619]\n","[09:41:22.167335] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:22.237293] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.298433] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.17it/s]\u001b[A\n"," 30% 8/27 [00:06<00:11,  1.65it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:22.302526] Processing image(s): ['vol_008.tif']\n","[09:41:22.302635] ### 3D-OV-CROP ###\n","[09:41:22.302660] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.302704] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.302728] Padding: (8, 8, 8)\n","[09:41:22.303535] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.303572] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.303594] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.305802] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:22.305836] ### END 3D-OV-CROP ###\n","[09:41:22.305890] ### 3D-OV-CROP ###\n","[09:41:22.305913] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.305929] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.305947] Padding: (8, 8, 8)\n","[09:41:22.306532] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.306564] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.306583] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.307054] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:22.307082] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.13it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.541298] ### MERGE-3D-OV-CROP ###\n","[09:41:22.541355] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.541379] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.541423] Padding: (8, 8, 8)\n","[09:41:22.541712] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.541738] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.541752] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.544205] **** New data shape is: (64, 64, 64, 1)\n","[09:41:22.544243] ### END MERGE-3D-OV-CROP ###\n","[09:41:22.544301] ### MERGE-3D-OV-CROP ###\n","[09:41:22.544325] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.544342] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.544360] Padding: (8, 8, 8)\n","[09:41:22.544548] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.544573] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.544588] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.546589] **** New data shape is: (64, 64, 64, 1)\n","[09:41:22.546624] ### END MERGE-3D-OV-CROP ###\n","[09:41:22.546745] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.552132] Capturing the local maxima \n","[09:41:22.552173] Class 1\n","[09:41:22.564893] Removing close points . . .\n","[09:41:22.564930] Initial number of points: 203\n","[09:41:22.566920] Final number of points: 183\n","[09:41:22.567004] Creating the images with detected points . . .\n","[09:41:22.583003] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.604132] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.612196] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:22.612240] Its respective CSV file seems to be: /content/data/test/y/mask_008.csv\n","[09:41:22.612257] Reading GT data from: /content/data/test/y/mask_008.csv\n","[09:41:22.614144] Detection (class 1)\n","[09:41:22.621544] Points in ground truth: 369, Points in prediction: 183\n","[09:41:22.621578] True positives: 183, False positives: 0, False negatives: 186\n","[09:41:22.621618] Detection metrics: ['Precision', 1.0, 'Recall', 0.4959349593495935, 'F1', 0.6630434782608696]\n","[09:41:22.624631] All classes 1\n","[09:41:22.624681] Detection metrics: ['Precision', 1.0, 'Recall', 0.4959349593495935, 'F1', 0.6630434782608696]\n","[09:41:22.624704] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:22.749092] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:22.810436] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.96it/s]\u001b[A\n"," 33% 9/27 [00:07<00:10,  1.74it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:22.815057] Processing image(s): ['vol_009.tif']\n","[09:41:22.815207] ### 3D-OV-CROP ###\n","[09:41:22.815244] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.815263] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.815283] Padding: (8, 8, 8)\n","[09:41:22.816516] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.816562] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.816582] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.818931] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:22.818978] ### END 3D-OV-CROP ###\n","[09:41:22.819034] ### 3D-OV-CROP ###\n","[09:41:22.819060] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:22.819086] Minimum overlap selected: (0, 0, 0)\n","[09:41:22.819109] Padding: (8, 8, 8)\n","[09:41:22.819922] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:22.819961] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:22.819986] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:22.820798] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:22.820830] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.14it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.050578] ### MERGE-3D-OV-CROP ###\n","[09:41:23.050637] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.050653] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.050670] Padding: (8, 8, 8)\n","[09:41:23.050962] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.050986] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.051010] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.053510] **** New data shape is: (64, 64, 64, 1)\n","[09:41:23.053549] ### END MERGE-3D-OV-CROP ###\n","[09:41:23.053591] ### MERGE-3D-OV-CROP ###\n","[09:41:23.053615] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.053631] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.053649] Padding: (8, 8, 8)\n","[09:41:23.053759] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.053781] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.053797] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.056084] **** New data shape is: (64, 64, 64, 1)\n","[09:41:23.056126] ### END MERGE-3D-OV-CROP ###\n","[09:41:23.056232] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.063117] Capturing the local maxima \n","[09:41:23.063163] Class 1\n","[09:41:23.078296] Removing close points . . .\n","[09:41:23.078345] Initial number of points: 189\n","[09:41:23.080725] Final number of points: 170\n","[09:41:23.080820] Creating the images with detected points . . .\n","[09:41:23.098994] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.125217] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.134230] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:23.134274] Its respective CSV file seems to be: /content/data/test/y/mask_009.csv\n","[09:41:23.134297] Reading GT data from: /content/data/test/y/mask_009.csv\n","[09:41:23.136398] Detection (class 1)\n","[09:41:23.143797] Points in ground truth: 372, Points in prediction: 170\n","[09:41:23.143836] True positives: 170, False positives: 0, False negatives: 202\n","[09:41:23.143879] Detection metrics: ['Precision', 1.0, 'Recall', 0.45698924731182794, 'F1', 0.6273062730627306]\n","[09:41:23.146907] All classes 1\n","[09:41:23.146958] Detection metrics: ['Precision', 1.0, 'Recall', 0.45698924731182794, 'F1', 0.6273062730627306]\n","[09:41:23.146981] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:23.284321] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.343310] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.88it/s]\u001b[A\n"," 37% 10/27 [00:07<00:09,  1.78it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:23.347598] Processing image(s): ['vol_010.tif']\n","[09:41:23.347710] ### 3D-OV-CROP ###\n","[09:41:23.347738] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.347761] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.347781] Padding: (8, 8, 8)\n","[09:41:23.348735] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.348776] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.348794] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.350960] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:23.350995] ### END 3D-OV-CROP ###\n","[09:41:23.351035] ### 3D-OV-CROP ###\n","[09:41:23.351056] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.351077] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.351096] Padding: (8, 8, 8)\n","[09:41:23.351593] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.351626] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.351643] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.352270] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:23.352301] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.23it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.579936] ### MERGE-3D-OV-CROP ###\n","[09:41:23.579997] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.580017] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.580034] Padding: (8, 8, 8)\n","[09:41:23.580298] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.580320] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.580335] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.582401] **** New data shape is: (64, 64, 64, 1)\n","[09:41:23.582442] ### END MERGE-3D-OV-CROP ###\n","[09:41:23.582493] ### MERGE-3D-OV-CROP ###\n","[09:41:23.582515] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.582529] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.582547] Padding: (8, 8, 8)\n","[09:41:23.582693] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.582713] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.582728] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.584915] **** New data shape is: (64, 64, 64, 1)\n","[09:41:23.584963] ### END MERGE-3D-OV-CROP ###\n","[09:41:23.585048] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.590336] Capturing the local maxima \n","[09:41:23.590390] Class 1\n","[09:41:23.603395] Removing close points . . .\n","[09:41:23.603427] Initial number of points: 245\n","[09:41:23.605555] Final number of points: 223\n","[09:41:23.605634] Creating the images with detected points . . .\n","[09:41:23.621951] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.642055] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.649601] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:23.649638] Its respective CSV file seems to be: /content/data/test/y/mask_010.csv\n","[09:41:23.649660] Reading GT data from: /content/data/test/y/mask_010.csv\n","[09:41:23.651616] Detection (class 1)\n","[09:41:23.662076] Points in ground truth: 502, Points in prediction: 223\n","[09:41:23.662115] True positives: 223, False positives: 0, False negatives: 279\n","[09:41:23.662163] Detection metrics: ['Precision', 1.0, 'Recall', 0.4442231075697211, 'F1', 0.6151724137931034]\n","[09:41:23.665964] All classes 1\n","[09:41:23.666011] Detection metrics: ['Precision', 1.0, 'Recall', 0.4442231075697211, 'F1', 0.6151724137931034]\n","[09:41:23.666036] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:23.845141] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:23.906922] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.77it/s]\u001b[A\n"," 41% 11/27 [00:08<00:09,  1.77it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:23.913394] Processing image(s): ['vol_011.tif']\n","[09:41:23.913609] ### 3D-OV-CROP ###\n","[09:41:23.913645] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.913668] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.913690] Padding: (8, 8, 8)\n","[09:41:23.914962] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.915019] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.915046] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.917550] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:23.917597] ### END 3D-OV-CROP ###\n","[09:41:23.917652] ### 3D-OV-CROP ###\n","[09:41:23.917680] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:23.917698] Minimum overlap selected: (0, 0, 0)\n","[09:41:23.917720] Padding: (8, 8, 8)\n","[09:41:23.918421] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:23.918479] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:23.918507] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:23.919273] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:23.919311] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.13it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.149205] ### MERGE-3D-OV-CROP ###\n","[09:41:24.149265] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:24.149283] Minimum overlap selected: (0, 0, 0)\n","[09:41:24.149304] Padding: (8, 8, 8)\n","[09:41:24.149577] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:24.149598] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:24.149612] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:24.151842] **** New data shape is: (64, 64, 64, 1)\n","[09:41:24.151893] ### END MERGE-3D-OV-CROP ###\n","[09:41:24.151940] ### MERGE-3D-OV-CROP ###\n","[09:41:24.151965] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:24.151990] Minimum overlap selected: (0, 0, 0)\n","[09:41:24.152013] Padding: (8, 8, 8)\n","[09:41:24.152133] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:24.152152] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:24.152168] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:24.154400] **** New data shape is: (64, 64, 64, 1)\n","[09:41:24.154436] ### END MERGE-3D-OV-CROP ###\n","[09:41:24.154546] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.160159] Capturing the local maxima \n","[09:41:24.160197] Class 1\n","[09:41:24.173032] Removing close points . . .\n","[09:41:24.173063] Initial number of points: 216\n","[09:41:24.174965] Final number of points: 197\n","[09:41:24.175039] Creating the images with detected points . . .\n","[09:41:24.192335] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.217157] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.225716] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:24.225755] Its respective CSV file seems to be: /content/data/test/y/mask_011.csv\n","[09:41:24.225773] Reading GT data from: /content/data/test/y/mask_011.csv\n","[09:41:24.227764] Detection (class 1)\n","[09:41:24.236053] Points in ground truth: 421, Points in prediction: 197\n","[09:41:24.236089] True positives: 197, False positives: 0, False negatives: 224\n","[09:41:24.236127] Detection metrics: ['Precision', 1.0, 'Recall', 0.4679334916864608, 'F1', 0.6375404530744336]\n","[09:41:24.239254] All classes 1\n","[09:41:24.239296] Detection metrics: ['Precision', 1.0, 'Recall', 0.4679334916864608, 'F1', 0.6375404530744336]\n","[09:41:24.239316] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:24.373708] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.440089] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.89it/s]\u001b[A\n"," 44% 12/27 [00:08<00:08,  1.81it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:24.443993] Processing image(s): ['vol_012.tif']\n","[09:41:24.444099] ### 3D-OV-CROP ###\n","[09:41:24.444125] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:24.444145] Minimum overlap selected: (0, 0, 0)\n","[09:41:24.444165] Padding: (8, 8, 8)\n","[09:41:24.444968] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:24.445009] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:24.445029] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:24.447221] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:24.447250] ### END 3D-OV-CROP ###\n","[09:41:24.447296] ### 3D-OV-CROP ###\n","[09:41:24.447317] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:24.447332] Minimum overlap selected: (0, 0, 0)\n","[09:41:24.447344] Padding: (8, 8, 8)\n","[09:41:24.447866] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:24.447899] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:24.447912] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:24.448334] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:24.448362] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.11it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.676936] ### MERGE-3D-OV-CROP ###\n","[09:41:24.676984] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:24.676998] Minimum overlap selected: (0, 0, 0)\n","[09:41:24.677023] Padding: (8, 8, 8)\n","[09:41:24.677287] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:24.677310] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:24.677325] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:24.679282] **** New data shape is: (64, 64, 64, 1)\n","[09:41:24.679318] ### END MERGE-3D-OV-CROP ###\n","[09:41:24.679355] ### MERGE-3D-OV-CROP ###\n","[09:41:24.679375] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:24.679390] Minimum overlap selected: (0, 0, 0)\n","[09:41:24.679405] Padding: (8, 8, 8)\n","[09:41:24.679508] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:24.679529] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:24.679543] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:24.681772] **** New data shape is: (64, 64, 64, 1)\n","[09:41:24.681805] ### END MERGE-3D-OV-CROP ###\n","[09:41:24.681886] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.687603] Capturing the local maxima \n","[09:41:24.687645] Class 1\n","[09:41:24.702037] Removing close points . . .\n","[09:41:24.702071] Initial number of points: 299\n","[09:41:24.704781] Final number of points: 281\n","[09:41:24.704870] Creating the images with detected points . . .\n","[09:41:24.723286] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.754047] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:24.763563] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:24.763599] Its respective CSV file seems to be: /content/data/test/y/mask_012.csv\n","[09:41:24.763621] Reading GT data from: /content/data/test/y/mask_012.csv\n","[09:41:24.765665] Detection (class 1)\n","[09:41:24.779149] Points in ground truth: 565, Points in prediction: 281\n","[09:41:24.779189] True positives: 281, False positives: 0, False negatives: 284\n","[09:41:24.779249] Detection metrics: ['Precision', 1.0, 'Recall', 0.49734513274336284, 'F1', 0.6643026004728132]\n","[09:41:24.783374] All classes 1\n","[09:41:24.783420] Detection metrics: ['Precision', 1.0, 'Recall', 0.49734513274336284, 'F1', 0.6643026004728132]\n","[09:41:24.783446] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:24.984091] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.052368] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.64it/s]\u001b[A\n"," 48% 13/27 [00:09<00:07,  1.75it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:25.056205] Processing image(s): ['vol_013.tif']\n","[09:41:25.056310] ### 3D-OV-CROP ###\n","[09:41:25.056334] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.056349] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.056364] Padding: (8, 8, 8)\n","[09:41:25.057134] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.057173] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.057186] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.059140] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:25.059181] ### END 3D-OV-CROP ###\n","[09:41:25.059221] ### 3D-OV-CROP ###\n","[09:41:25.059241] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.059256] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.059271] Padding: (8, 8, 8)\n","[09:41:25.059757] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.059789] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.059802] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.060268] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:25.060296] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.18it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.288153] ### MERGE-3D-OV-CROP ###\n","[09:41:25.288208] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.288227] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.288240] Padding: (8, 8, 8)\n","[09:41:25.288516] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.288537] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.288553] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.290723] **** New data shape is: (64, 64, 64, 1)\n","[09:41:25.290758] ### END MERGE-3D-OV-CROP ###\n","[09:41:25.290796] ### MERGE-3D-OV-CROP ###\n","[09:41:25.290817] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.290836] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.290853] Padding: (8, 8, 8)\n","[09:41:25.291067] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.291088] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.291107] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.293332] **** New data shape is: (64, 64, 64, 1)\n","[09:41:25.293368] ### END MERGE-3D-OV-CROP ###\n","[09:41:25.293443] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.299077] Capturing the local maxima \n","[09:41:25.299117] Class 1\n","[09:41:25.311376] Removing close points . . .\n","[09:41:25.311423] Initial number of points: 184\n","[09:41:25.313123] Final number of points: 169\n","[09:41:25.313207] Creating the images with detected points . . .\n","[09:41:25.336572] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.371138] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.378944] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:25.379001] Its respective CSV file seems to be: /content/data/test/y/mask_013.csv\n","[09:41:25.379025] Reading GT data from: /content/data/test/y/mask_013.csv\n","[09:41:25.381072] Detection (class 1)\n","[09:41:25.388825] Points in ground truth: 388, Points in prediction: 169\n","[09:41:25.388878] True positives: 169, False positives: 0, False negatives: 219\n","[09:41:25.388925] Detection metrics: ['Precision', 1.0, 'Recall', 0.43556701030927836, 'F1', 0.6068222621184919]\n","[09:41:25.391847] All classes 1\n","[09:41:25.391902] Detection metrics: ['Precision', 1.0, 'Recall', 0.43556701030927836, 'F1', 0.6068222621184919]\n","[09:41:25.391926] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:25.522828] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.578086] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.91it/s]\u001b[A\n"," 52% 14/27 [00:09<00:07,  1.79it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:25.581815] Processing image(s): ['vol_014.tif']\n","[09:41:25.581915] ### 3D-OV-CROP ###\n","[09:41:25.581938] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.581953] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.581969] Padding: (8, 8, 8)\n","[09:41:25.582855] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.582893] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.582907] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.584885] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:25.584915] ### END 3D-OV-CROP ###\n","[09:41:25.584953] ### 3D-OV-CROP ###\n","[09:41:25.584972] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.584988] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.585001] Padding: (8, 8, 8)\n","[09:41:25.585511] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.585544] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.585558] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.586012] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:25.586048] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.12it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.816587] ### MERGE-3D-OV-CROP ###\n","[09:41:25.816644] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.816666] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.816682] Padding: (8, 8, 8)\n","[09:41:25.816962] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.816995] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.817017] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.819410] **** New data shape is: (64, 64, 64, 1)\n","[09:41:25.819448] ### END MERGE-3D-OV-CROP ###\n","[09:41:25.819505] ### MERGE-3D-OV-CROP ###\n","[09:41:25.819529] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:25.819549] Minimum overlap selected: (0, 0, 0)\n","[09:41:25.819568] Padding: (8, 8, 8)\n","[09:41:25.819735] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:25.819759] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:25.819772] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:25.821989] **** New data shape is: (64, 64, 64, 1)\n","[09:41:25.822024] ### END MERGE-3D-OV-CROP ###\n","[09:41:25.822102] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.827737] Capturing the local maxima \n","[09:41:25.827776] Class 1\n","[09:41:25.840196] Removing close points . . .\n","[09:41:25.840243] Initial number of points: 21\n","[09:41:25.840728] Final number of points: 18\n","[09:41:25.840799] Creating the images with detected points . . .\n","[09:41:25.866124] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.890996] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:25.896774] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:25.896814] Its respective CSV file seems to be: /content/data/test/y/mask_014.csv\n","[09:41:25.896830] Reading GT data from: /content/data/test/y/mask_014.csv\n","[09:41:25.898656] Detection (class 1)\n","[09:41:25.900920] Points in ground truth: 71, Points in prediction: 18\n","[09:41:25.900958] True positives: 18, False positives: 0, False negatives: 53\n","[09:41:25.900986] Detection metrics: ['Precision', 1.0, 'Recall', 0.2535211267605634, 'F1', 0.40449438202247184]\n","[09:41:25.902542] All classes 1\n","[09:41:25.902591] Detection metrics: ['Precision', 1.0, 'Recall', 0.2535211267605634, 'F1', 0.40449438202247184]\n","[09:41:25.902614] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:25.941561] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.010541] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.32it/s]\u001b[A\n"," 56% 15/27 [00:10<00:06,  1.92it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:26.014282] Processing image(s): ['vol_015.tif']\n","[09:41:26.014449] ### 3D-OV-CROP ###\n","[09:41:26.014472] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.014506] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.014522] Padding: (8, 8, 8)\n","[09:41:26.015542] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.015576] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.015596] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.017662] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:26.017693] ### END 3D-OV-CROP ###\n","[09:41:26.017735] ### 3D-OV-CROP ###\n","[09:41:26.017756] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.017770] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.017787] Padding: (8, 8, 8)\n","[09:41:26.018250] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.018286] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.018303] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.018902] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:26.018930] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.15it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.248221] ### MERGE-3D-OV-CROP ###\n","[09:41:26.248272] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.248292] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.248307] Padding: (8, 8, 8)\n","[09:41:26.248590] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.248613] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.248632] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.250827] **** New data shape is: (64, 64, 64, 1)\n","[09:41:26.250870] ### END MERGE-3D-OV-CROP ###\n","[09:41:26.250910] ### MERGE-3D-OV-CROP ###\n","[09:41:26.250935] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.250957] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.250990] Padding: (8, 8, 8)\n","[09:41:26.251114] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.251147] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.251165] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.253400] **** New data shape is: (64, 64, 64, 1)\n","[09:41:26.253434] ### END MERGE-3D-OV-CROP ###\n","[09:41:26.253552] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.258842] Capturing the local maxima \n","[09:41:26.258883] Class 1\n","[09:41:26.270488] Removing close points . . .\n","[09:41:26.270519] Initial number of points: 77\n","[09:41:26.271219] Final number of points: 72\n","[09:41:26.271277] Creating the images with detected points . . .\n","[09:41:26.287498] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.308265] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.313714] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:26.313750] Its respective CSV file seems to be: /content/data/test/y/mask_015.csv\n","[09:41:26.313771] Reading GT data from: /content/data/test/y/mask_015.csv\n","[09:41:26.315721] Detection (class 1)\n","[09:41:26.319091] Points in ground truth: 163, Points in prediction: 72\n","[09:41:26.319128] True positives: 72, False positives: 0, False negatives: 91\n","[09:41:26.319162] Detection metrics: ['Precision', 1.0, 'Recall', 0.44171779141104295, 'F1', 0.6127659574468085]\n","[09:41:26.321082] All classes 1\n","[09:41:26.321127] Detection metrics: ['Precision', 1.0, 'Recall', 0.44171779141104295, 'F1', 0.6127659574468085]\n","[09:41:26.321151] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:26.386597] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.451747] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.27it/s]\u001b[A\n"," 59% 16/27 [00:10<00:05,  2.02it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:26.455391] Processing image(s): ['vol_016.tif']\n","[09:41:26.455541] ### 3D-OV-CROP ###\n","[09:41:26.455570] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.455591] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.455610] Padding: (8, 8, 8)\n","[09:41:26.456614] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.456649] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.456669] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.458743] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:26.458774] ### END 3D-OV-CROP ###\n","[09:41:26.458814] ### 3D-OV-CROP ###\n","[09:41:26.458838] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.458861] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.458876] Padding: (8, 8, 8)\n","[09:41:26.459635] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.459684] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.459709] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.460339] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:26.460403] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.14it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.688987] ### MERGE-3D-OV-CROP ###\n","[09:41:26.689037] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.689054] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.689067] Padding: (8, 8, 8)\n","[09:41:26.689356] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.689393] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.689407] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.691772] **** New data shape is: (64, 64, 64, 1)\n","[09:41:26.691807] ### END MERGE-3D-OV-CROP ###\n","[09:41:26.691847] ### MERGE-3D-OV-CROP ###\n","[09:41:26.691869] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.691888] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.691907] Padding: (8, 8, 8)\n","[09:41:26.692060] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.692081] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.692102] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.694561] **** New data shape is: (64, 64, 64, 1)\n","[09:41:26.694592] ### END MERGE-3D-OV-CROP ###\n","[09:41:26.694668] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.699970] Capturing the local maxima \n","[09:41:26.700009] Class 1\n","[09:41:26.715529] Removing close points . . .\n","[09:41:26.715572] Initial number of points: 166\n","[09:41:26.717704] Final number of points: 154\n","[09:41:26.717787] Creating the images with detected points . . .\n","[09:41:26.739643] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.767170] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.774353] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:26.774396] Its respective CSV file seems to be: /content/data/test/y/mask_016.csv\n","[09:41:26.774415] Reading GT data from: /content/data/test/y/mask_016.csv\n","[09:41:26.776281] Detection (class 1)\n","[09:41:26.782694] Points in ground truth: 337, Points in prediction: 154\n","[09:41:26.782730] True positives: 154, False positives: 0, False negatives: 183\n","[09:41:26.782771] Detection metrics: ['Precision', 1.0, 'Recall', 0.456973293768546, 'F1', 0.6272912423625254]\n","[09:41:26.785581] All classes 1\n","[09:41:26.785629] Detection metrics: ['Precision', 1.0, 'Recall', 0.456973293768546, 'F1', 0.6272912423625254]\n","[09:41:26.785650] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:26.905752] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:26.969030] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.94it/s]\u001b[A\n"," 63% 17/27 [00:11<00:05,  1.99it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:26.972552] Processing image(s): ['vol_017.tif']\n","[09:41:26.972651] ### 3D-OV-CROP ###\n","[09:41:26.972676] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.972695] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.972713] Padding: (8, 8, 8)\n","[09:41:26.973508] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.973561] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.973580] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.975690] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:26.975741] ### END 3D-OV-CROP ###\n","[09:41:26.975784] ### 3D-OV-CROP ###\n","[09:41:26.975806] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:26.975824] Minimum overlap selected: (0, 0, 0)\n","[09:41:26.975841] Padding: (8, 8, 8)\n","[09:41:26.976439] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:26.976495] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:26.976525] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:26.977152] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:26.977184] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.11it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.214156] ### MERGE-3D-OV-CROP ###\n","[09:41:27.214212] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:27.214229] Minimum overlap selected: (0, 0, 0)\n","[09:41:27.214246] Padding: (8, 8, 8)\n","[09:41:27.214553] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:27.214577] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:27.214593] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:27.217108] **** New data shape is: (64, 64, 64, 1)\n","[09:41:27.217150] ### END MERGE-3D-OV-CROP ###\n","[09:41:27.217192] ### MERGE-3D-OV-CROP ###\n","[09:41:27.217215] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:27.217235] Minimum overlap selected: (0, 0, 0)\n","[09:41:27.217253] Padding: (8, 8, 8)\n","[09:41:27.217371] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:27.217394] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:27.217411] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:27.219611] **** New data shape is: (64, 64, 64, 1)\n","[09:41:27.219642] ### END MERGE-3D-OV-CROP ###\n","[09:41:27.219721] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.225028] Capturing the local maxima \n","[09:41:27.225068] Class 1\n","[09:41:27.237955] Removing close points . . .\n","[09:41:27.237992] Initial number of points: 158\n","[09:41:27.239457] Final number of points: 145\n","[09:41:27.239542] Creating the images with detected points . . .\n","[09:41:27.256957] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.279248] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.286192] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:27.286233] Its respective CSV file seems to be: /content/data/test/y/mask_017.csv\n","[09:41:27.286248] Reading GT data from: /content/data/test/y/mask_017.csv\n","[09:41:27.288114] Detection (class 1)\n","[09:41:27.294706] Points in ground truth: 286, Points in prediction: 145\n","[09:41:27.294745] True positives: 145, False positives: 0, False negatives: 141\n","[09:41:27.294787] Detection metrics: ['Precision', 1.0, 'Recall', 0.506993006993007, 'F1', 0.6728538283062644]\n","[09:41:27.297821] All classes 1\n","[09:41:27.297871] Detection metrics: ['Precision', 1.0, 'Recall', 0.506993006993007, 'F1', 0.6728538283062644]\n","[09:41:27.297895] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:27.414554] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.474976] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.98it/s]\u001b[A\n"," 67% 18/27 [00:11<00:04,  1.99it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:27.478910] Processing image(s): ['vol_018.tif']\n","[09:41:27.479015] ### 3D-OV-CROP ###\n","[09:41:27.479038] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:27.479053] Minimum overlap selected: (0, 0, 0)\n","[09:41:27.479069] Padding: (8, 8, 8)\n","[09:41:27.479952] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:27.479990] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:27.480008] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:27.482145] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:27.482175] ### END 3D-OV-CROP ###\n","[09:41:27.482215] ### 3D-OV-CROP ###\n","[09:41:27.482235] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:27.482248] Minimum overlap selected: (0, 0, 0)\n","[09:41:27.482263] Padding: (8, 8, 8)\n","[09:41:27.482683] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:27.482715] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:27.482728] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:27.483211] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:27.483239] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.07it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.713067] ### MERGE-3D-OV-CROP ###\n","[09:41:27.713118] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:27.713132] Minimum overlap selected: (0, 0, 0)\n","[09:41:27.713145] Padding: (8, 8, 8)\n","[09:41:27.713405] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:27.713427] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:27.713443] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:27.715765] **** New data shape is: (64, 64, 64, 1)\n","[09:41:27.715802] ### END MERGE-3D-OV-CROP ###\n","[09:41:27.715841] ### MERGE-3D-OV-CROP ###\n","[09:41:27.715871] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:27.715891] Minimum overlap selected: (0, 0, 0)\n","[09:41:27.715912] Padding: (8, 8, 8)\n","[09:41:27.716075] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:27.716095] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:27.716129] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:27.718350] **** New data shape is: (64, 64, 64, 1)\n","[09:41:27.718388] ### END MERGE-3D-OV-CROP ###\n","[09:41:27.718481] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.724158] Capturing the local maxima \n","[09:41:27.724198] Class 1\n","[09:41:27.737378] Removing close points . . .\n","[09:41:27.737416] Initial number of points: 140\n","[09:41:27.738868] Final number of points: 123\n","[09:41:27.738948] Creating the images with detected points . . .\n","[09:41:27.756604] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.785807] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.792894] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:27.792933] Its respective CSV file seems to be: /content/data/test/y/mask_018.csv\n","[09:41:27.792955] Reading GT data from: /content/data/test/y/mask_018.csv\n","[09:41:27.794996] Detection (class 1)\n","[09:41:27.800814] Points in ground truth: 307, Points in prediction: 123\n","[09:41:27.800852] True positives: 123, False positives: 0, False negatives: 184\n","[09:41:27.800901] Detection metrics: ['Precision', 1.0, 'Recall', 0.4006514657980456, 'F1', 0.572093023255814]\n","[09:41:27.803874] All classes 1\n","[09:41:27.803923] Detection metrics: ['Precision', 1.0, 'Recall', 0.4006514657980456, 'F1', 0.572093023255814]\n","[09:41:27.803949] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:27.922269] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:27.993038] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.94it/s]\u001b[A\n"," 70% 19/27 [00:12<00:04,  1.97it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:27.996696] Processing image(s): ['vol_019.tif']\n","[09:41:27.996804] ### 3D-OV-CROP ###\n","[09:41:27.996827] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:27.996846] Minimum overlap selected: (0, 0, 0)\n","[09:41:27.996869] Padding: (8, 8, 8)\n","[09:41:27.997717] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:27.997756] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:27.997778] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:27.999973] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:28.000008] ### END 3D-OV-CROP ###\n","[09:41:28.000060] ### 3D-OV-CROP ###\n","[09:41:28.000082] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:28.000101] Minimum overlap selected: (0, 0, 0)\n","[09:41:28.000119] Padding: (8, 8, 8)\n","[09:41:28.000590] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:28.000623] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:28.000640] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:28.001177] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:28.001206] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.15it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.230965] ### MERGE-3D-OV-CROP ###\n","[09:41:28.231024] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:28.231048] Minimum overlap selected: (0, 0, 0)\n","[09:41:28.231061] Padding: (8, 8, 8)\n","[09:41:28.231340] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:28.231367] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:28.231387] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:28.233607] **** New data shape is: (64, 64, 64, 1)\n","[09:41:28.233643] ### END MERGE-3D-OV-CROP ###\n","[09:41:28.233683] ### MERGE-3D-OV-CROP ###\n","[09:41:28.233706] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:28.233722] Minimum overlap selected: (0, 0, 0)\n","[09:41:28.233740] Padding: (8, 8, 8)\n","[09:41:28.233843] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:28.233864] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:28.233881] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:28.236161] **** New data shape is: (64, 64, 64, 1)\n","[09:41:28.236197] ### END MERGE-3D-OV-CROP ###\n","[09:41:28.236276] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.246230] Capturing the local maxima \n","[09:41:28.246298] Class 1\n","[09:41:28.266716] Removing close points . . .\n","[09:41:28.266752] Initial number of points: 153\n","[09:41:28.268369] Final number of points: 140\n","[09:41:28.268447] Creating the images with detected points . . .\n","[09:41:28.287158] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.308719] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.315849] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:28.315888] Its respective CSV file seems to be: /content/data/test/y/mask_019.csv\n","[09:41:28.315903] Reading GT data from: /content/data/test/y/mask_019.csv\n","[09:41:28.318002] Detection (class 1)\n","[09:41:28.325384] Points in ground truth: 326, Points in prediction: 140\n","[09:41:28.325420] True positives: 140, False positives: 0, False negatives: 186\n","[09:41:28.325475] Detection metrics: ['Precision', 1.0, 'Recall', 0.4294478527607362, 'F1', 0.6008583690987125]\n","[09:41:28.328678] All classes 1\n","[09:41:28.328731] Detection metrics: ['Precision', 1.0, 'Recall', 0.4294478527607362, 'F1', 0.6008583690987125]\n","[09:41:28.328756] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:28.452746] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.511687] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.93it/s]\u001b[A\n"," 74% 20/27 [00:12<00:03,  1.96it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:28.515454] Processing image(s): ['vol_020.tif']\n","[09:41:28.515582] ### 3D-OV-CROP ###\n","[09:41:28.515608] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:28.515624] Minimum overlap selected: (0, 0, 0)\n","[09:41:28.515641] Padding: (8, 8, 8)\n","[09:41:28.516382] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:28.516422] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:28.516436] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:28.518612] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:28.518643] ### END 3D-OV-CROP ###\n","[09:41:28.518685] ### 3D-OV-CROP ###\n","[09:41:28.518704] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:28.518720] Minimum overlap selected: (0, 0, 0)\n","[09:41:28.518732] Padding: (8, 8, 8)\n","[09:41:28.519240] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:28.519277] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:28.519292] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:28.519757] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:28.519786] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.15it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.749574] ### MERGE-3D-OV-CROP ###\n","[09:41:28.749625] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:28.749641] Minimum overlap selected: (0, 0, 0)\n","[09:41:28.749657] Padding: (8, 8, 8)\n","[09:41:28.749925] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:28.749946] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:28.749960] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:28.752134] **** New data shape is: (64, 64, 64, 1)\n","[09:41:28.752173] ### END MERGE-3D-OV-CROP ###\n","[09:41:28.752213] ### MERGE-3D-OV-CROP ###\n","[09:41:28.752234] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:28.752248] Minimum overlap selected: (0, 0, 0)\n","[09:41:28.752263] Padding: (8, 8, 8)\n","[09:41:28.752508] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:28.752533] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:28.752551] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:28.754579] **** New data shape is: (64, 64, 64, 1)\n","[09:41:28.754610] ### END MERGE-3D-OV-CROP ###\n","[09:41:28.754691] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.760183] Capturing the local maxima \n","[09:41:28.760223] Class 1\n","[09:41:28.772731] Removing close points . . .\n","[09:41:28.772765] Initial number of points: 146\n","[09:41:28.774275] Final number of points: 136\n","[09:41:28.774347] Creating the images with detected points . . .\n","[09:41:28.791873] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.813748] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:28.820716] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:28.820757] Its respective CSV file seems to be: /content/data/test/y/mask_020.csv\n","[09:41:28.820775] Reading GT data from: /content/data/test/y/mask_020.csv\n","[09:41:28.822682] Detection (class 1)\n","[09:41:28.830101] Points in ground truth: 315, Points in prediction: 136\n","[09:41:28.830140] True positives: 136, False positives: 0, False negatives: 179\n","[09:41:28.830181] Detection metrics: ['Precision', 1.0, 'Recall', 0.43174603174603177, 'F1', 0.6031042128603105]\n","[09:41:28.833029] All classes 1\n","[09:41:28.833071] Detection metrics: ['Precision', 1.0, 'Recall', 0.43174603174603177, 'F1', 0.6031042128603105]\n","[09:41:28.833094] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:28.953460] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.021274] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.96it/s]\u001b[A\n"," 78% 21/27 [00:13<00:03,  1.96it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:29.026110] Processing image(s): ['vol_021.tif']\n","[09:41:29.026219] ### 3D-OV-CROP ###\n","[09:41:29.026245] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.026266] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.026291] Padding: (8, 8, 8)\n","[09:41:29.027555] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.027597] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.027619] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.029864] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:29.029901] ### END 3D-OV-CROP ###\n","[09:41:29.029957] ### 3D-OV-CROP ###\n","[09:41:29.029983] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.030009] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.030031] Padding: (8, 8, 8)\n","[09:41:29.030800] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.030841] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.030866] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.031443] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:29.031495] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.16it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.266865] ### MERGE-3D-OV-CROP ###\n","[09:41:29.266928] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.266953] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.266975] Padding: (8, 8, 8)\n","[09:41:29.267251] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.267281] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.267293] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.269383] **** New data shape is: (64, 64, 64, 1)\n","[09:41:29.269429] ### END MERGE-3D-OV-CROP ###\n","[09:41:29.269463] ### MERGE-3D-OV-CROP ###\n","[09:41:29.269501] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.269519] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.269535] Padding: (8, 8, 8)\n","[09:41:29.269634] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.269654] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.269673] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.271960] **** New data shape is: (64, 64, 64, 1)\n","[09:41:29.271994] ### END MERGE-3D-OV-CROP ###\n","[09:41:29.272071] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.277362] Capturing the local maxima \n","[09:41:29.277402] Class 1\n","[09:41:29.288098] Removing close points . . .\n","[09:41:29.288134] Initial number of points: 7\n","[09:41:29.288288] Final number of points: 6\n","[09:41:29.288338] Creating the images with detected points . . .\n","[09:41:29.304421] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.326080] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.330397] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:29.330441] Its respective CSV file seems to be: /content/data/test/y/mask_021.csv\n","[09:41:29.330461] Reading GT data from: /content/data/test/y/mask_021.csv\n","[09:41:29.332258] Detection (class 1)\n","[09:41:29.334140] Points in ground truth: 36, Points in prediction: 6\n","[09:41:29.334177] True positives: 6, False positives: 0, False negatives: 30\n","[09:41:29.334206] Detection metrics: ['Precision', 1.0, 'Recall', 0.16666666666666666, 'F1', 0.2857142857142857]\n","[09:41:29.335518] All classes 1\n","[09:41:29.335562] Detection metrics: ['Precision', 1.0, 'Recall', 0.16666666666666666, 'F1', 0.2857142857142857]\n","[09:41:29.335585] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:29.363486] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.430660] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.46it/s]\u001b[A\n"," 81% 22/27 [00:13<00:02,  2.08it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:29.434616] Processing image(s): ['vol_022.tif']\n","[09:41:29.434720] ### 3D-OV-CROP ###\n","[09:41:29.434746] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.434768] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.434788] Padding: (8, 8, 8)\n","[09:41:29.435804] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.435848] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.435867] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.438246] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:29.438281] ### END 3D-OV-CROP ###\n","[09:41:29.438322] ### 3D-OV-CROP ###\n","[09:41:29.438342] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.438370] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.438393] Padding: (8, 8, 8)\n","[09:41:29.438887] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.438926] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.438945] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.439509] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:29.439535] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  7.87it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.673522] ### MERGE-3D-OV-CROP ###\n","[09:41:29.673570] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.673583] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.673597] Padding: (8, 8, 8)\n","[09:41:29.673856] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.673878] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.673891] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.676135] **** New data shape is: (64, 64, 64, 1)\n","[09:41:29.676174] ### END MERGE-3D-OV-CROP ###\n","[09:41:29.676213] ### MERGE-3D-OV-CROP ###\n","[09:41:29.676236] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.676255] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.676274] Padding: (8, 8, 8)\n","[09:41:29.676499] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.676525] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.676543] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.679043] **** New data shape is: (64, 64, 64, 1)\n","[09:41:29.679077] ### END MERGE-3D-OV-CROP ###\n","[09:41:29.679163] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.686843] Capturing the local maxima \n","[09:41:29.686890] Class 1\n","[09:41:29.701035] Removing close points . . .\n","[09:41:29.701069] Initial number of points: 132\n","[09:41:29.702523] Final number of points: 115\n","[09:41:29.702602] Creating the images with detected points . . .\n","[09:41:29.719522] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.741632] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.748595] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:29.748633] Its respective CSV file seems to be: /content/data/test/y/mask_022.csv\n","[09:41:29.748654] Reading GT data from: /content/data/test/y/mask_022.csv\n","[09:41:29.750677] Detection (class 1)\n","[09:41:29.756758] Points in ground truth: 374, Points in prediction: 115\n","[09:41:29.756794] True positives: 115, False positives: 0, False negatives: 259\n","[09:41:29.756830] Detection metrics: ['Precision', 1.0, 'Recall', 0.3074866310160428, 'F1', 0.4703476482617587]\n","[09:41:29.759821] All classes 1\n","[09:41:29.759871] Detection metrics: ['Precision', 1.0, 'Recall', 0.3074866310160428, 'F1', 0.4703476482617587]\n","[09:41:29.759892] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:29.909794] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:29.976331] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.84it/s]\u001b[A\n"," 85% 23/27 [00:14<00:01,  2.00it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:29.980325] Processing image(s): ['vol_023.tif']\n","[09:41:29.980434] ### 3D-OV-CROP ###\n","[09:41:29.980458] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.980492] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.980511] Padding: (8, 8, 8)\n","[09:41:29.981548] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.981583] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.981599] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.983687] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:29.983718] ### END 3D-OV-CROP ###\n","[09:41:29.983760] ### 3D-OV-CROP ###\n","[09:41:29.983780] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:29.983793] Minimum overlap selected: (0, 0, 0)\n","[09:41:29.983810] Padding: (8, 8, 8)\n","[09:41:29.984281] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:29.984316] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:29.984330] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:29.984881] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:29.984913] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.01it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.218125] ### MERGE-3D-OV-CROP ###\n","[09:41:30.218191] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.218218] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.218238] Padding: (8, 8, 8)\n","[09:41:30.218570] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.218604] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.218627] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.221692] **** New data shape is: (64, 64, 64, 1)\n","[09:41:30.221748] ### END MERGE-3D-OV-CROP ###\n","[09:41:30.221804] ### MERGE-3D-OV-CROP ###\n","[09:41:30.221830] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.221856] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.221879] Padding: (8, 8, 8)\n","[09:41:30.221999] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.222029] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.222053] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.225062] **** New data shape is: (64, 64, 64, 1)\n","[09:41:30.225112] ### END MERGE-3D-OV-CROP ###\n","[09:41:30.225235] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.231092] Capturing the local maxima \n","[09:41:30.231137] Class 1\n","[09:41:30.242123] Removing close points . . .\n","[09:41:30.242162] Initial number of points: 13\n","[09:41:30.242422] Final number of points: 13\n","[09:41:30.242493] Creating the images with detected points . . .\n","[09:41:30.260458] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.283480] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.288705] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:30.288746] Its respective CSV file seems to be: /content/data/test/y/mask_023.csv\n","[09:41:30.288768] Reading GT data from: /content/data/test/y/mask_023.csv\n","[09:41:30.290844] Detection (class 1)\n","[09:41:30.293398] Points in ground truth: 112, Points in prediction: 13\n","[09:41:30.293435] True positives: 13, False positives: 0, False negatives: 99\n","[09:41:30.293476] Detection metrics: ['Precision', 1.0, 'Recall', 0.11607142857142858, 'F1', 0.208]\n","[09:41:30.295325] All classes 1\n","[09:41:30.295368] Detection metrics: ['Precision', 1.0, 'Recall', 0.11607142857142858, 'F1', 0.208]\n","[09:41:30.295398] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:30.344183] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.401239] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.36it/s]\u001b[A\n"," 89% 24/27 [00:14<00:01,  2.09it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:30.405314] Processing image(s): ['vol_024.tif']\n","[09:41:30.405455] ### 3D-OV-CROP ###\n","[09:41:30.405588] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.405621] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.405729] Padding: (8, 8, 8)\n","[09:41:30.406854] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.406899] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.406915] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.409127] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:30.409159] ### END 3D-OV-CROP ###\n","[09:41:30.409200] ### 3D-OV-CROP ###\n","[09:41:30.409220] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.409239] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.409256] Padding: (8, 8, 8)\n","[09:41:30.409772] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.409810] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.409832] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.410557] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:30.410589] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.05it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.641384] ### MERGE-3D-OV-CROP ###\n","[09:41:30.641458] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.641472] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.641503] Padding: (8, 8, 8)\n","[09:41:30.641776] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.641797] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.641812] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.644312] **** New data shape is: (64, 64, 64, 1)\n","[09:41:30.644361] ### END MERGE-3D-OV-CROP ###\n","[09:41:30.644402] ### MERGE-3D-OV-CROP ###\n","[09:41:30.644424] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.644443] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.644460] Padding: (8, 8, 8)\n","[09:41:30.644688] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.644710] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.644734] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.646803] **** New data shape is: (64, 64, 64, 1)\n","[09:41:30.646838] ### END MERGE-3D-OV-CROP ###\n","[09:41:30.646923] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.652246] Capturing the local maxima \n","[09:41:30.652288] Class 1\n","[09:41:30.666438] Removing close points . . .\n","[09:41:30.666489] Initial number of points: 28\n","[09:41:30.667097] Final number of points: 23\n","[09:41:30.667164] Creating the images with detected points . . .\n","[09:41:30.695457] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.717269] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.722368] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:30.722408] Its respective CSV file seems to be: /content/data/test/y/mask_024.csv\n","[09:41:30.722425] Reading GT data from: /content/data/test/y/mask_024.csv\n","[09:41:30.724242] Detection (class 1)\n","[09:41:30.726621] Points in ground truth: 82, Points in prediction: 23\n","[09:41:30.726656] True positives: 23, False positives: 0, False negatives: 59\n","[09:41:30.726687] Detection metrics: ['Precision', 1.0, 'Recall', 0.2804878048780488, 'F1', 0.43809523809523815]\n","[09:41:30.728262] All classes 1\n","[09:41:30.728305] Detection metrics: ['Precision', 1.0, 'Recall', 0.2804878048780488, 'F1', 0.43809523809523815]\n","[09:41:30.728333] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:30.782743] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:30.845488] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.26it/s]\u001b[A\n"," 93% 25/27 [00:15<00:00,  2.14it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:30.849373] Processing image(s): ['vol_025.tif']\n","[09:41:30.849496] ### 3D-OV-CROP ###\n","[09:41:30.849522] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.849539] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.849554] Padding: (8, 8, 8)\n","[09:41:30.850251] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.850289] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.850305] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.852449] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:30.852495] ### END 3D-OV-CROP ###\n","[09:41:30.852535] ### 3D-OV-CROP ###\n","[09:41:30.852554] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:30.852569] Minimum overlap selected: (0, 0, 0)\n","[09:41:30.852581] Padding: (8, 8, 8)\n","[09:41:30.853091] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:30.853127] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:30.853142] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:30.853645] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:30.853675] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.08it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.083574] ### MERGE-3D-OV-CROP ###\n","[09:41:31.083624] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:31.083643] Minimum overlap selected: (0, 0, 0)\n","[09:41:31.083656] Padding: (8, 8, 8)\n","[09:41:31.083929] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:31.083951] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:31.083967] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:31.086123] **** New data shape is: (64, 64, 64, 1)\n","[09:41:31.086162] ### END MERGE-3D-OV-CROP ###\n","[09:41:31.086202] ### MERGE-3D-OV-CROP ###\n","[09:41:31.086226] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:31.086241] Minimum overlap selected: (0, 0, 0)\n","[09:41:31.086258] Padding: (8, 8, 8)\n","[09:41:31.086359] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:31.086380] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:31.086394] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:31.088810] **** New data shape is: (64, 64, 64, 1)\n","[09:41:31.088844] ### END MERGE-3D-OV-CROP ###\n","[09:41:31.088926] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.095623] Capturing the local maxima \n","[09:41:31.095674] Class 1\n","[09:41:31.112726] Removing close points . . .\n","[09:41:31.112760] Initial number of points: 145\n","[09:41:31.114146] Final number of points: 127\n","[09:41:31.114220] Creating the images with detected points . . .\n","[09:41:31.131154] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.151928] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.158206] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:31.158243] Its respective CSV file seems to be: /content/data/test/y/mask_025.csv\n","[09:41:31.158261] Reading GT data from: /content/data/test/y/mask_025.csv\n","[09:41:31.160083] Detection (class 1)\n","[09:41:31.165937] Points in ground truth: 330, Points in prediction: 127\n","[09:41:31.165972] True positives: 127, False positives: 0, False negatives: 203\n","[09:41:31.166010] Detection metrics: ['Precision', 1.0, 'Recall', 0.38484848484848483, 'F1', 0.5557986870897156]\n","[09:41:31.169058] All classes 1\n","[09:41:31.169098] Detection metrics: ['Precision', 1.0, 'Recall', 0.38484848484848483, 'F1', 0.5557986870897156]\n","[09:41:31.169121] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:31.302551] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.359617] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  1.95it/s]\u001b[A\n"," 96% 26/27 [00:15<00:00,  2.08it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A[09:41:31.363318] Processing image(s): ['vol_026.tif']\n","[09:41:31.363419] ### 3D-OV-CROP ###\n","[09:41:31.363442] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:31.363462] Minimum overlap selected: (0, 0, 0)\n","[09:41:31.363494] Padding: (8, 8, 8)\n","[09:41:31.364243] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:31.364291] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:31.364306] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:31.366520] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:31.366550] ### END 3D-OV-CROP ###\n","[09:41:31.366590] ### 3D-OV-CROP ###\n","[09:41:31.366612] Cropping (64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:31.366632] Minimum overlap selected: (0, 0, 0)\n","[09:41:31.366650] Padding: (8, 8, 8)\n","[09:41:31.367330] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:31.367382] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:31.367398] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:31.368051] **** New data shape is: (8, 64, 64, 64, 1)\n","[09:41:31.368088] ### END 3D-OV-CROP ###\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","100% 1/1 [00:00<00:00,  8.07it/s]\u001b[A\u001b[A\n","\n","                                 \u001b[A\u001b[A\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.601988] ### MERGE-3D-OV-CROP ###\n","[09:41:31.602041] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:31.602061] Minimum overlap selected: (0, 0, 0)\n","[09:41:31.602079] Padding: (8, 8, 8)\n","[09:41:31.602345] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:31.602372] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:31.602392] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:31.604598] **** New data shape is: (64, 64, 64, 1)\n","[09:41:31.604632] ### END MERGE-3D-OV-CROP ###\n","[09:41:31.604682] ### MERGE-3D-OV-CROP ###\n","[09:41:31.604703] Merging (8, 64, 64, 64, 1) images into (64, 64, 64, 1) with overlapping . . .\n","[09:41:31.604721] Minimum overlap selected: (0, 0, 0)\n","[09:41:31.604738] Padding: (8, 8, 8)\n","[09:41:31.604970] Real overlapping (%): (0.6666666666666666, 0.6666666666666666, 0.6666666666666666)\n","[09:41:31.604993] Real overlapping (pixels): (32.0, 32.0, 32.0)\n","[09:41:31.605004] (2, 2, 2) patches per (z,y,x) axis\n","[09:41:31.607077] **** New data shape is: (64, 64, 64, 1)\n","[09:41:31.607129] ### END MERGE-3D-OV-CROP ###\n","[09:41:31.607221] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.612597] Capturing the local maxima \n","[09:41:31.612638] Class 1\n","[09:41:31.623714] Removing close points . . .\n","[09:41:31.623770] Initial number of points: 10\n","[09:41:31.623993] Final number of points: 8\n","[09:41:31.624057] Creating the images with detected points . . .\n","[09:41:31.641082] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.663752] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.668894] WARNING: The CSV file seems to have different name than iamge. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n","[09:41:31.668930] Its respective CSV file seems to be: /content/data/test/y/mask_026.csv\n","[09:41:31.668945] Reading GT data from: /content/data/test/y/mask_026.csv\n","[09:41:31.670916] Detection (class 1)\n","[09:41:31.672918] Points in ground truth: 30, Points in prediction: 8\n","[09:41:31.672955] True positives: 8, False positives: 0, False negatives: 22\n","[09:41:31.672982] Detection metrics: ['Precision', 1.0, 'Recall', 0.26666666666666666, 'F1', 0.4210526315789474]\n","[09:41:31.674285] All classes 1\n","[09:41:31.674330] Detection metrics: ['Precision', 1.0, 'Recall', 0.26666666666666666, 'F1', 0.4210526315789474]\n","[09:41:31.674352] Creating the image with a summary of detected points and false positives with colors . . .\n","[09:41:31.700569] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A[09:41:31.763819] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n","\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","                         \u001b[A\u001b[A\n","100% 1/1 [00:00<00:00,  2.48it/s]\u001b[A\n","100% 27/27 [00:16<00:00,  1.68it/s]\n","[09:41:31.766986] Releasing memory . . .\n","[09:41:31.767017] #############\n","[09:41:31.767028] #  RESULTS  #\n","[09:41:31.767038] #############\n","[09:41:31.767269] Loss (per patch): 0.08728363447719151\n","[09:41:31.767302] Test Foreground IoU (per patch): 0.011195832300775995\n","[09:41:31.767320]  \n","[09:41:31.767342] Test Foreground IoU (merge patches): 0.09887532344565882\n","[09:41:31.767367] Test Overall IoU (merge patches): 0.5450062331212974\n","[09:41:31.767383]  \n","[09:41:31.767406] Detection specific metrics:\n","[09:41:31.767432] Detection - Test Precision (merge patches): 0.9958847736625515\n","[09:41:31.767450] Detection - Test Recall (merge patches): 0.39108882043577753\n","[09:41:31.767478] Detection - Test F1 (merge patches): 0.5537279586849364\n","[09:41:31.767526] FINISHED JOB my_3d_detection_1 !!\n"]}],"source":["#@markdown ### Play to run inference on test with the new parameters\n","\n","# Run the code\n","run_job(f'/content/{job_name}_inference.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a1d26fd7eb2b416a83a1e86c32f45722","66526343b35844098109bad72d976455","a41c168dd98e41e38bc476e459171ee5","d95eccdb0f484dd3bc1621359096770c","2b1ecb7a97bd4ed3be1eeef820b6da0f","78b974260e3f4a6f927379bd4c3b2f87","8e449b785cef45ce8ac157f3420fc2d7","5573ea5a782d483c80fa14e119ac7825","84e7e94a44c840c99782505ab29e3128","0822a521a6224fada38bdcc01337d0d3","05f6cfc2f0164c3abfb59d46e8d97b8f","f1c6a93ee8094ddcb13933a834970a8c","b0b84312cc65463fa11fcdcada0f7950","39afe89a195241888641ceeab98d9080","2ef34de4e51d46ff81f2f12d545d2208","c92893aa40c0427a97ebfe1766b3a67b","7e1637ffd7684bd1ac8d5b01cc435a40","3328cb75291e424ea89655646924c673","809054ede42d41e382ab3bb3eaf3e252","0c9cfda084b446d79b4d9524ea7be815","96d9fe65dd0c457b812bf1c4fc3193d0"]},"executionInfo":{"elapsed":2200,"status":"ok","timestamp":1696930895657,"user":{"displayName":"Daniel Franco-Barranco","userId":"13463799105703234009"},"user_tz":-120},"id":"pRJRFyLsNhB_","outputId":"4eeb590f-56de-4ed3-ba59-2049edb9bcf0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1d26fd7eb2b416a83a1e86c32f45722","version_major":2,"version_minor":0},"text/plain":["interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in…"]},"metadata":{"application/vnd.jupyter.widget-view+json":{"colab":{"custom_widget_manager":{"url":"https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"}}}},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39afe89a195241888641ceeab98d9080","version_major":2,"version_minor":0},"text/plain":["interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in…"]},"metadata":{"application/vnd.jupyter.widget-view+json":{"colab":{"custom_widget_manager":{"url":"https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"}}}},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"809054ede42d41e382ab3bb3eaf3e252","version_major":2,"version_minor":0},"text/plain":["interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in…"]},"metadata":{"application/vnd.jupyter.widget-view+json":{"colab":{"custom_widget_manager":{"url":"https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"}}}},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2500x500 with 4 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#@markdown ###Play to visualize results in 3D\n","#@markdown In the rightmost column, associations between predictions and ground truth are illustrated:\n","#@markdown - **Green**: True positives\n","#@markdown - **Red**: False negatives\n","#@markdown - **Blue**: False positives\n","\n","%matplotlib inline\n","import matplotlib\n","import numpy as np\n","from numpy.random import randint, seed\n","from matplotlib import pyplot as plt\n","from ipywidgets import interact, fixed\n","import ipywidgets as widgets\n","from google.colab import output\n","output.enable_custom_widget_manager()\n","\n","final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n","detection_results = os.path.join(final_results, \"per_image_local_max_check\")\n","assoc_results = os.path.join(final_results, \"point_associations\")\n","test_data_gt_path = \"/content/data/train/y_detection_masks\"\n","\n","# Show a few examples to check that they have been stored correctly\n","ids_pred = sorted(next(os.walk(detection_results))[2])\n","ids_pred = [x for x in ids_pred if not x.endswith('.csv') ]\n","ids_assoc = sorted(next(os.walk(assoc_results))[2])\n","ids_assoc = [x for x in ids_assoc if not x.endswith('.csv') ]\n","ids_assoc = [x for x in ids_assoc if \"_gt_ids\" not in x ]\n","ids_assoc = [x for x in ids_assoc if \"_pred_ids\" not in x ]\n","ids_input = sorted(next(os.walk(test_data_path))[2])\n","ids_gt = sorted(next(os.walk(test_data_gt_path))[2])\n","\n","samples_to_show = min(len(ids_input), 3)\n","chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n","seed(1)\n","\n","test_samples = []\n","test_sample_preds = []\n","test_sample_gt = []\n","test_sample_assoc = []\n","\n","# read 3D images again\n","for i in range(len(chosen_images)):\n","    aux = imread(os.path.join(test_data_path, ids_input[chosen_images[i]]))\n","    test_samples.append(np.squeeze(aux))\n","\n","    aux = imread(os.path.join(detection_results, ids_pred[chosen_images[i]])).astype(np.uint16)\n","    test_sample_preds.append(np.squeeze(aux))\n","\n","    aux = imread(os.path.join(test_data_gt_path, ids_gt[chosen_images[i]])).astype(np.uint16)\n","    test_sample_gt.append(np.squeeze(aux))\n","\n","    aux = imread(os.path.join(assoc_results, ids_assoc[chosen_images[i]]))\n","    test_sample_assoc.append(np.squeeze(aux))\n","\n","# function to show results in 3D within a widget\n","def scroll_in_z(z, j):\n","\n","    plt.figure(figsize=(25,5))\n","    # Source\n","    plt.subplot(1,4,1)\n","    plt.axis('off')\n","    plt.imshow(test_samples[j][z-1], cmap='gray')\n","    plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n","\n","    # Target (Ground-truth)\n","    plt.subplot(1,4,2)\n","    plt.axis('off')\n","    plt.imshow(test_sample_gt[j][z-1], cmap=cmap, interpolation='nearest')\n","    plt.title('Ground truth (z = ' + str(z) + ')', fontsize=15)\n","\n","    # Prediction\n","    plt.subplot(1,4,3)\n","    plt.axis('off')\n","    plt.imshow(test_sample_preds[j][z-1], cmap=cmap, interpolation='nearest')\n","    plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n","\n","    # Overlay\n","    plt.subplot(1,4,4)\n","    plt.axis('off')\n","    plt.imshow(test_sample_assoc[j][z-1], interpolation='nearest')\n","    plt.title('Associations (z = ' + str(z) + ')', fontsize=15)\n","\n","for j in range(samples_to_show):\n","    interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_sample_gt[j].shape[0], step=1, value=test_sample_gt[j].shape[0]//2), j=fixed(j));"]},{"cell_type":"markdown","metadata":{"id":"wAzTcs0wuR3d"},"source":["## **Acknowledgments**\n","---\n","\n","We extend our gratitude to the [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki) which have been a beacon of inspiration for our work. Specific elements, such as descriptions of metrics and parameters, as well as the 3D visualization widget code, have been incorporated from their [U-Net 3D notebook](https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb). Their contributions to the field have immensely enriched our endeavor.\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05f6cfc2f0164c3abfb59d46e8d97b8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0822a521a6224fada38bdcc01337d0d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ac71c7c1ece465abe04f3c8f30cb2e5":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_e59fb4c60658448db5d27c219852be36","msg_id":"","outputs":[]}},"0c9cfda084b446d79b4d9524ea7be815":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntSliderModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"z","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_2ef34de4e51d46ff81f2f12d545d2208","max":64,"min":1,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_c92893aa40c0427a97ebfe1766b3a67b","value":31}},"116efa2f2c8f4a1da5dc2e6784cb773e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntSliderModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"z","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_41de6ed4d5d6400b951d042e5c65f8fc","max":64,"min":1,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_28a039a75628480499e7295024ddad9c","value":32}},"28a039a75628480499e7295024ddad9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SliderStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"2b1ecb7a97bd4ed3be1eeef820b6da0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ef34de4e51d46ff81f2f12d545d2208":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3328cb75291e424ea89655646924c673":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39afe89a195241888641ceeab98d9080":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f1c6a93ee8094ddcb13933a834970a8c","IPY_MODEL_b0b84312cc65463fa11fcdcada0f7950"],"layout":"IPY_MODEL_0822a521a6224fada38bdcc01337d0d3"}},"41de6ed4d5d6400b951d042e5c65f8fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f9a2d4f9f454f3da117442061ca2d26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5573ea5a782d483c80fa14e119ac7825":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66526343b35844098109bad72d976455":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntSliderModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"z","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_2b1ecb7a97bd4ed3be1eeef820b6da0f","max":64,"min":1,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_78b974260e3f4a6f927379bd4c3b2f87","value":31}},"720e3800ea4a4946b45b9fcde630726f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"746e0d99c2a9419292baf56de051f3f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SliderStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"760ed0fcb3c64f77b0f3da60c9c4ef8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_116efa2f2c8f4a1da5dc2e6784cb773e","IPY_MODEL_fb59d1b43e3c4eb08515510741560681"],"layout":"IPY_MODEL_f954818d61ad4b50aa6bb8d2d9c5d844"}},"78b974260e3f4a6f927379bd4c3b2f87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SliderStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"78d58827cd31400cb6656d621de5614e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_d2a4ca39d9274771b8ad52aaca0aa2bc","IPY_MODEL_a42d291db45d425c91cd175ceabbd89b"],"layout":"IPY_MODEL_c3ae580c9f0d442f8662f9fa3746b557"}},"7e1637ffd7684bd1ac8d5b01cc435a40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e89179600d04a96a0e28127347acab3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SliderStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"7f31f2ebd3404642bac814f10659d8b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntSliderModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"z","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_ea76d7746cd342c6b6373cca75b4788e","max":64,"min":1,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_746e0d99c2a9419292baf56de051f3f2","value":32}},"7f7b34acb64f4e9abfd0e320a5af0d7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_7f31f2ebd3404642bac814f10659d8b2","IPY_MODEL_0ac71c7c1ece465abe04f3c8f30cb2e5"],"layout":"IPY_MODEL_80bebf64067f4e128468a1ac49b6bf42"}},"809054ede42d41e382ab3bb3eaf3e252":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_0c9cfda084b446d79b4d9524ea7be815","IPY_MODEL_96d9fe65dd0c457b812bf1c4fc3193d0"],"layout":"IPY_MODEL_7e1637ffd7684bd1ac8d5b01cc435a40"}},"80bebf64067f4e128468a1ac49b6bf42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84e7e94a44c840c99782505ab29e3128":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SliderStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"8e449b785cef45ce8ac157f3420fc2d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d9fe65dd0c457b812bf1c4fc3193d0":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_3328cb75291e424ea89655646924c673","msg_id":"","outputs":[]}},"a1d26fd7eb2b416a83a1e86c32f45722":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_66526343b35844098109bad72d976455","IPY_MODEL_a41c168dd98e41e38bc476e459171ee5"],"layout":"IPY_MODEL_d95eccdb0f484dd3bc1621359096770c"}},"a41c168dd98e41e38bc476e459171ee5":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_8e449b785cef45ce8ac157f3420fc2d7","msg_id":"","outputs":[]}},"a42d291db45d425c91cd175ceabbd89b":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_720e3800ea4a4946b45b9fcde630726f","msg_id":"","outputs":[]}},"b0b84312cc65463fa11fcdcada0f7950":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_05f6cfc2f0164c3abfb59d46e8d97b8f","msg_id":"","outputs":[]}},"bb964aa6be29492daf61e24e1c499fd0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ae580c9f0d442f8662f9fa3746b557":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c92893aa40c0427a97ebfe1766b3a67b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SliderStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"d2a4ca39d9274771b8ad52aaca0aa2bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntSliderModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"z","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_bb964aa6be29492daf61e24e1c499fd0","max":64,"min":1,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_7e89179600d04a96a0e28127347acab3","value":32}},"d95eccdb0f484dd3bc1621359096770c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e59fb4c60658448db5d27c219852be36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea76d7746cd342c6b6373cca75b4788e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c6a93ee8094ddcb13933a834970a8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntSliderModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"z","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5573ea5a782d483c80fa14e119ac7825","max":64,"min":1,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_84e7e94a44c840c99782505ab29e3128","value":31}},"f954818d61ad4b50aa6bb8d2d9c5d844":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59d1b43e3c4eb08515510741560681":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_4f9a2d4f9f454f3da117442061ca2d26","msg_id":"","outputs":[]}}}}},"nbformat":4,"nbformat_minor":0}
