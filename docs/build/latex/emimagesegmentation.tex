%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{How to run}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{0}



\title{EM Image Segmentation}
\date{Aug 24, 2021}
\release{}
\author{Daniel Franco}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


This documentation tries to explain better the code of the project \sphinxhref{https://github.com/danifranco/DeepLearning\_EM}{EM Image Segmentation}, which is used to make semantic segmentation for EM images. The code is based on Keras and TensorFlow as backend.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{seg}.gif}\hspace*{\fill}}


\chapter{Citation}
\label{\detokenize{index:citation}}
This repository is the base of the following work:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nd}{@misc}\PYG{p}{\PYGZob{}}\PYG{n}{francobarranco2021stable}\PYG{p}{,}
      \PYG{n}{title}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{Stable} \PYG{n}{deep} \PYG{n}{neural} \PYG{n}{network} \PYG{n}{architectures} \PYG{k}{for} \PYG{n}{mitochondria} \PYG{n}{segmentation} \PYG{n}{on} \PYG{n}{electron} \PYG{n}{microscopy} \PYG{n}{volumes}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{author}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{Daniel} \PYG{n}{Franco}\PYG{o}{\PYGZhy{}}\PYG{n}{Barranco} \PYG{o+ow}{and} \PYG{n}{Arrate} \PYG{n}{Muñoz}\PYG{o}{\PYGZhy{}}\PYG{n}{Barrutia} \PYG{o+ow}{and} \PYG{n}{Ignacio} \PYG{n}{Arganda}\PYG{o}{\PYGZhy{}}\PYG{n}{Carreras}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{year}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+m+mi}{2021}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{eprint}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+m+mf}{2104.03577}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{archivePrefix}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{arXiv}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{primaryClass}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{eess}\PYG{o}{.}\PYG{n}{IV}\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\section{Bash shell}
\label{\detokenize{how_to_run/bash:bash-shell}}\label{\detokenize{how_to_run/bash::doc}}

\subsection{Step 0: Prepare environment}
\label{\detokenize{how_to_run/bash:step-0-prepare-environment}}
Clone the \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation}{repository}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{danifranco}\PYG{o}{/}\PYG{n}{EM\PYGZus{}Image\PYGZus{}Segmentation}\PYG{o}{.}\PYG{n}{git}
\end{sphinxVerbatim}

You can set\sphinxhyphen{}up a development environment with all necessary dependencies creating
directly a \sphinxcode{\sphinxupquote{conda}} environment using the file located in \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/blob/master/utils/env/environment.yml}{utils/env/environment.yml}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{conda} \PYG{n}{env} \PYG{n}{create} \PYG{o}{\PYGZhy{}}\PYG{n}{f} \PYG{n}{utils}\PYG{o}{/}\PYG{n}{env}\PYG{o}{/}\PYG{n}{environment}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}


\subsection{Step 1: Data preparation}
\label{\detokenize{how_to_run/bash:step-1-data-preparation}}\phantomsection\label{\detokenize{how_to_run/bash:data-preparation}}
The data directory tree should be this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
dataset/
├── test
│   ├── x
│   │   ├── testing\PYGZhy{}0001.tif
│   │   ├── testing\PYGZhy{}0002.tif
│   │   ├── . . .
│   │   ├── testing\PYGZhy{}9999.tif
│   └── y
│       ├── testing\PYGZus{}groundtruth\PYGZhy{}0001.tif
│       ├── testing\PYGZus{}groundtruth\PYGZhy{}0002.tif
│       ├── . . .
│       ├── testing\PYGZus{}groundtruth\PYGZhy{}9999.tif
└── train
    ├── x
    │   ├── training\PYGZhy{}0001.tif
    │   ├── training\PYGZhy{}0002.tif
    │   ├── . . .
    │   ├── training\PYGZhy{}9999.tif
    └── y
        ├── training\PYGZus{}groundtruth\PYGZhy{}0001.tif
        ├── training\PYGZus{}groundtruth\PYGZhy{}0002.tif
        ├── . . .
        ├── training\PYGZus{}groundtruth\PYGZhy{}9999.tif
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
Ensure that images and their corresponding masks are sorted in the same way. A common approach is to fill with zeros the image number added to the filenames (as in the example).
\end{sphinxadmonition}

In case you use other directory distribution ensure to configure \sphinxcode{\sphinxupquote{DATA.TRAIN.PATH}}, \sphinxcode{\sphinxupquote{DATA.TRAIN.MASK\_PATH}}, \sphinxcode{\sphinxupquote{DATA.VAL.PATH}}, \sphinxcode{\sphinxupquote{DATA.VAL.MASK\_PATH}}, \sphinxcode{\sphinxupquote{DATA.TEST.PATH}} and \sphinxcode{\sphinxupquote{DATA.TEST.MASK\_PATH}} variables accordingly.


\subsection{Step 2: Choose a template}
\label{\detokenize{how_to_run/bash:step-2-choose-a-template}}
Choose a template from \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/blob/master/templates}{templates} directory and modify it for you specific case. Find \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/blob/master/config/config.py}{config.py} all configurable variables and their description.


\subsection{Step 3: Run the code}
\label{\detokenize{how_to_run/bash:step-3-run-the-code}}
Using, for instance, \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/master/templates/unet\_2d.yaml}{unet\_2d.yaml} template file, the code can be run as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Configuration file}
\PYG{n+nv}{job\PYGZus{}cfg\PYGZus{}file}\PYG{o}{=}/home/user/unet\PYGZus{}2d.yaml
\PYG{c+c1}{\PYGZsh{} Where the experiment output directory should be created}
\PYG{n+nv}{result\PYGZus{}dir}\PYG{o}{=}/data2/dfranco/exp\PYGZus{}results
\PYG{c+c1}{\PYGZsh{} Path to the dataset}
\PYG{n+nv}{data\PYGZus{}dir}\PYG{o}{=}/home/user/dataset
\PYG{c+c1}{\PYGZsh{} Just a name for the job}
\PYG{n+nv}{job\PYGZus{}name}\PYG{o}{=}unet\PYGZus{}basic\PYGZus{}experiment
\PYG{c+c1}{\PYGZsh{} Number that should be increased when one need to run the same job multiple times (reproducibility)}
\PYG{n+nv}{job\PYGZus{}counter}\PYG{o}{=}\PYG{l+m}{0}
\PYG{c+c1}{\PYGZsh{} Number of the GPU to run the job in (according to \PYGZsq{}nvidia\PYGZhy{}smi\PYGZsq{} command}
\PYG{n+nv}{gpu\PYGZus{}number}\PYG{o}{=}\PYG{l+m}{0}

\PYG{c+c1}{\PYGZsh{} Load the environment}
conda activate EM\PYGZus{}tools

python \PYGZhy{}u main.py \PYG{l+s+se}{\PYGZbs{}}
       \PYGZhy{}\PYGZhy{}config \PYG{n+nv}{\PYGZdl{}job\PYGZus{}cfg\PYGZus{}file} \PYG{l+s+se}{\PYGZbs{}}
       \PYGZhy{}\PYGZhy{}result\PYGZus{}dir \PYG{n+nv}{\PYGZdl{}result\PYGZus{}dir}  \PYG{l+s+se}{\PYGZbs{}}
       \PYGZhy{}\PYGZhy{}dataroot \PYG{n+nv}{\PYGZdl{}data\PYGZus{}dir}   \PYG{l+s+se}{\PYGZbs{}}
       \PYGZhy{}\PYGZhy{}name \PYG{n+nv}{\PYGZdl{}job\PYGZus{}name}    \PYG{l+s+se}{\PYGZbs{}}
       \PYGZhy{}\PYGZhy{}run\PYGZus{}id \PYG{n+nv}{\PYGZdl{}job\PYGZus{}counter}  \PYG{l+s+se}{\PYGZbs{}}
       \PYGZhy{}\PYGZhy{}gpu \PYG{n+nv}{\PYGZdl{}gpu\PYGZus{}number}
\end{sphinxVerbatim}


\section{Colab}
\label{\detokenize{how_to_run/colab:colab}}\label{\detokenize{how_to_run/colab::doc}}
The fastest and easiest way to run the code is to use directly our 2D U\sphinxhyphen{}Net template
for mitochondria segmentation in Colab: \sphinxhref{https://colab.research.google.com/github/danifranco/EM\_Image\_Segmentation/blob/master/templates/U-Net\_2D\_workflow.ipynb}{\sphinxincludegraphics{{/home/dfranco/Documentos/thesis/EM_Image_Segmentation/docs/build/doctrees/images/f6661fbeae369352aec99b38ea299ee813f5e736/colab-badge}.svg}}


\section{Docker container}
\label{\detokenize{how_to_run/docker:docker-container}}\label{\detokenize{how_to_run/docker::doc}}
Under construction …


\section{Singularity container}
\label{\detokenize{how_to_run/singularity:singularity-container}}\label{\detokenize{how_to_run/singularity::doc}}
Under construction …


\section{2D Mitochondria segmentation}
\label{\detokenize{tutorials/mitochondria:d-mitochondria-segmentation}}\label{\detokenize{tutorials/mitochondria:mito-tutorial}}\label{\detokenize{tutorials/mitochondria::doc}}

\subsection{Problem description}
\label{\detokenize{tutorials/mitochondria:problem-description}}
The goal is to segment automatically mitochondria in EM images. This is a
semantic segmentation problem where pairs of EM image and its corresponding
mitochodria mask are provided. Our purpose is to segment automatically other
mitochondria in images not used during train labeling each pixel with the
corresponding class: background or foreground. In this example,
\sphinxhref{https://www.epfl.ch/labs/cvlab/data/data-em/}{EPFL Hippocampus} dataset is
used, so the foreground class correspond to mitochondria.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics{{FIBSEM_test_02}.png}
\sphinxfigcaption{EM tissue image sample.}\label{\detokenize{tutorials/mitochondria:id3}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics{{FIBSEM_test_0_gt2}.png}
\sphinxfigcaption{Its corresponding mask.}\label{\detokenize{tutorials/mitochondria:id4}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Data preparation}
\label{\detokenize{tutorials/mitochondria:data-preparation}}
Prepare the data as described \sphinxhref{bash.html\#step-1-data-preparation}{here}.


\subsection{Choose a template}
\label{\detokenize{tutorials/mitochondria:choose-a-template}}
Refer to the code version \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/releases/tag/v1.0}{V1.0} in case you want to reproduce exact results of our paper. Once the code is cloned you can use any of the templates from \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/master/templates}{here}.


\subsection{Run}
\label{\detokenize{tutorials/mitochondria:run}}
Run the code as described \sphinxhref{bash.html\#step-3-run-the-code}{here}.


\section{3D Nuclei Instance Segmentation}
\label{\detokenize{tutorials/nucleus:d-nuclei-instance-segmentation}}\label{\detokenize{tutorials/nucleus:nucleus-tutorial}}\label{\detokenize{tutorials/nucleus::doc}}

\subsection{Problem description}
\label{\detokenize{tutorials/nucleus:problem-description}}
The goal is to segment and identify automatically each cell nuclei in EM images.
This is an instance segmentation problem, which is the next step of semantic
segmentation, as its requires identifying each blob unequivocally with a given
id. In this tutorial, pairs of EM 3D images (\sphinxcode{\sphinxupquote{X}}) with their corresponding instance
sementation annotations (\sphinxcode{\sphinxupquote{Y}}) are provided. Here NucMM\sphinxhyphen{}Z dataset {[}\hyperlink{cite.bibliography:id2}{LWP+21}{]}
is used:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.3]{{nucmm_z_paper_view}.png}
\caption{Overview of the NucMM\sphinxhyphen{}Z dataset volume. Electron microscopy (EM) volume
covering nearly a whole zebrafish brain. Modified image from {[}\hyperlink{cite.bibliography:id2}{LWP+21}{]}.}\label{\detokenize{tutorials/nucleus:id4}}\end{figure}

In this dataset 27 3D images of (64, 64, 64) are used for train while the test is
done over the whole Zebrafish volume. Here is a training sample and its ground
truth:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics{{nucmm_z_volume}.gif}
\sphinxfigcaption{EM tissue volume (\sphinxcode{\sphinxupquote{X}}).}\label{\detokenize{tutorials/nucleus:id5}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics{{nucmm_z_volume_mask}.gif}
\sphinxfigcaption{Corresponding instance labels (\sphinxcode{\sphinxupquote{Y}}).}\label{\detokenize{tutorials/nucleus:id6}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Data preparation}
\label{\detokenize{tutorials/nucleus:data-preparation}}
The data directory tree must follow the structure described \sphinxhref{bash.html\#step-1-data-preparation}{here}.


\subsection{Problem resolution}
\label{\detokenize{tutorials/nucleus:problem-resolution}}
To produce the nuclei instances two main steps are done:
\begin{itemize}
\item {} 
Firstly, new \(Y_2\) data representations are created from the original \sphinxcode{\sphinxupquote{Y}}. This new \sphinxcode{\sphinxupquote{Y\_\textasciicircum{}}} data is created with up to three channels (controlled by \sphinxcode{\sphinxupquote{DATA.CHANNELS}}). Binary segmentation (referred as \sphinxcode{\sphinxupquote{B}} in the code), contour (\sphinxcode{\sphinxupquote{C}}) and distances (\sphinxcode{\sphinxupquote{D}}). This way, the network will be trained with 27 image pairs provided in NucMM\sphinxhyphen{}Z, each containing an EM image and its \sphinxcode{\sphinxupquote{Y\_\textasciicircum{}}} new data representation.

\item {} 
These extra channels predicted by the network are used to create the final instance segmentation labels using a marked controlled watershed.

\end{itemize}


\subsection{Cfg file}
\label{\detokenize{tutorials/nucleus:cfg-file}}
To create the YAML file you can use the template \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/blob/master/templates/resunet\_3d\_instances.yaml}{resunet\_3d\_instances.yaml} which is prepared for this tutorial.


\subsection{Run}
\label{\detokenize{tutorials/nucleus:run}}
Run the code as described \sphinxhref{bash.html\#step-3-run-the-code}{here}.


\subsection{Results}
\label{\detokenize{tutorials/nucleus:results}}
The resulting instance segmentation should be something like this:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{nucmm_z_instances_medium}.gif}
\caption{Instance segmentation results on the whole dataset.}\label{\detokenize{tutorials/nucleus:id7}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{smallpart_nucmm_z_instances}.gif}
\caption{Zoom of a small region of the instance prediction.}\label{\detokenize{tutorials/nucleus:id8}}\end{figure}


\section{Stable DNN architectures for mitochondria segmentation}
\label{\detokenize{manuscripts/stable_mitochondria:stable-dnn-architectures-for-mitochondria-segmentation}}\label{\detokenize{manuscripts/stable_mitochondria::doc}}
This tutorial describes a how to reproduce the results reported in our paper to
make semantic segmentation of mitochondria in electron microscopy (EM) images:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nd}{@misc}\PYG{p}{\PYGZob{}}\PYG{n}{francobarranco2021stable}\PYG{p}{,}
      \PYG{n}{title}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{Stable} \PYG{n}{deep} \PYG{n}{neural} \PYG{n}{network} \PYG{n}{architectures} \PYG{k}{for} \PYG{n}{mitochondria} \PYG{n}{segmentation} \PYG{n}{on} \PYG{n}{electron} \PYG{n}{microscopy} \PYG{n}{volumes}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{author}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{Daniel} \PYG{n}{Franco}\PYG{o}{\PYGZhy{}}\PYG{n}{Barranco} \PYG{o+ow}{and} \PYG{n}{Arrate} \PYG{n}{Muñoz}\PYG{o}{\PYGZhy{}}\PYG{n}{Barrutia} \PYG{o+ow}{and} \PYG{n}{Ignacio} \PYG{n}{Arganda}\PYG{o}{\PYGZhy{}}\PYG{n}{Carreras}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{year}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+m+mi}{2021}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{eprint}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+m+mf}{2104.03577}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{archivePrefix}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{arXiv}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{n}{primaryClass}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{n}{eess}\PYG{o}{.}\PYG{n}{IV}\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Problem description}
\label{\detokenize{manuscripts/stable_mitochondria:problem-description}}
The goal is to segment automatically mitochondria in EM images as described in {\hyperref[\detokenize{tutorials/mitochondria:mito-tutorial}]{\sphinxcrossref{\DUrole{std,std-ref}{2D Mitochondria segmentation}}}}. This is a
semantic segmentation problem where pairs of EM image and its corresponding
mitochodria mask are provided. Our purpose is to segment automatically other
mitochondria in images not used during train labeling each pixel with the
corresponding class: background or foreground (mitochondria in this case). As an
example, belown are shown two images from EPFL Hippocampus dataset used in this
work:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics{{FIBSEM_test_01}.png}
\sphinxfigcaption{EM tissue image}\label{\detokenize{manuscripts/stable_mitochondria:id2}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics{{FIBSEM_test_0_gt1}.png}
\sphinxfigcaption{Corresponding mask}\label{\detokenize{manuscripts/stable_mitochondria:id3}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Data preparation}
\label{\detokenize{manuscripts/stable_mitochondria:data-preparation}}
There are differents datasets used on the above work:
\begin{itemize}
\item {} 
\sphinxhref{https://www.epfl.ch/labs/cvlab/data/data-em/}{EPFL Hippocampus/Lucchi}.

\item {} 
\sphinxhref{https://sites.google.com/view/connectomics/}{Lucchi++}.

\item {} 
\sphinxhref{https://sites.google.com/view/connectomics/}{Kasthuri++}.

\end{itemize}

Prepare the data as described \sphinxhref{bash.html\#step-1-data-preparation}{here}.


\subsection{Choose a template}
\label{\detokenize{manuscripts/stable_mitochondria:choose-a-template}}
Refer to the code version \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/releases/tag/v1.0}{V1.0} in case you want to reproduce exact results of our paper. Once the code is cloned you can use any of the templates from \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/templates}{templates folder}.

In case you are interested in reproducing one of the state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art works implemented in that work, you can use the template prepared on each case: \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/xiao\_2018/xiao\_template\_V1.py}{xiao\_template\_V1.py}, \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/cheng\_2017/cheng\_2D\_template\_V1.py}{cheng\_2D\_template.py}, \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/cheng\_2017/cheng\_3D\_template\_V1.py}{cheng\_3D\_template.py}, \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/oztel\_2017/oztel\_template\_V1.py}{oztel\_template\_V1.py} or \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/casser\_2018/casser\_template\_V1.py}{casser\_template\_V1.py}.

Find each work implementation here:
\begin{itemize}
\item {} 
\sphinxhref{casser.html}{Caseer et al.}

\item {} 
\sphinxhref{xiao.html}{Xiao et al.}

\item {} 
\sphinxhref{cheng.html}{Cheng et al.}

\item {} 
\sphinxhref{oztel.html}{Oztel et al.}

\end{itemize}


\subsection{Run}
\label{\detokenize{manuscripts/stable_mitochondria:run}}
Run the code as described \sphinxhref{quick\_start.html\#step-3-run-the-code}{here}.


\section{config}
\label{\detokenize{config/main_config:config}}\label{\detokenize{config/main_config::doc}}\label{\detokenize{config/main_config::doc}}

\subsection{Config}
\label{\detokenize{config/config:module-config.config}}\label{\detokenize{config/config:config}}\label{\detokenize{config/config::doc}}\index{module@\spxentry{module}!config.config@\spxentry{config.config}}\index{config.config@\spxentry{config.config}!module@\spxentry{module}}\index{Config (class in config.config)@\spxentry{Config}\spxextra{class in config.config}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{config/config:config.config.Config}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{config.config.}}\sphinxbfcode{\sphinxupquote{Config}}}{\emph{\DUrole{n}{job\_dir}}, \emph{\DUrole{n}{job\_identifier}}, \emph{\DUrole{n}{dataroot}}}{}
Bases: \sphinxcode{\sphinxupquote{object}}
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

{\hyperref[\detokenize{config/config:config.config.Config.get_cfg_defaults}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{get\_cfg\_defaults}}}}}()
&
Get a yacs CfgNode object with default values for my\_project.
\\
\hline
{\hyperref[\detokenize{config/config:config.config.Config.update_dependencies}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{update\_dependencies}}}}}()
&
Update some variables that depend of changes made after merge the .cfg file provide by the user.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}
\index{get\_cfg\_defaults() (config.config.Config method)@\spxentry{get\_cfg\_defaults()}\spxextra{config.config.Config method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{config/config:config.config.Config.get_cfg_defaults}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_cfg\_defaults}}}{}{}
Get a yacs CfgNode object with default values for my\_project.

\end{fulllineitems}

\index{update\_dependencies() (config.config.Config method)@\spxentry{update\_dependencies()}\spxextra{config.config.Config method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{config/config:config.config.Config.update_dependencies}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{update\_dependencies}}}{}{}
Update some variables that depend of changes made after merge the .cfg file provide by the user. That is,
this function should be called after YACS’s merge\_from\_file().

\end{fulllineitems}


\end{fulllineitems}



\section{data}
\label{\detokenize{data/data:data}}\label{\detokenize{data/data::doc}}

\subsection{Init}
\label{\detokenize{data/init:module-data}}\label{\detokenize{data/init:init}}\label{\detokenize{data/init::doc}}\index{module@\spxentry{module}!data@\spxentry{data}}\index{data@\spxentry{data}!module@\spxentry{module}}\index{create\_train\_val\_instance\_channels() (in module data)@\spxentry{create\_train\_val\_instance\_channels()}\spxextra{in module data}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/init:data.create_train_val_instance_channels}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.}}\sphinxbfcode{\sphinxupquote{create\_train\_val\_instance\_channels}}}{\emph{\DUrole{n}{cfg}}}{}
Create training and validation new data with appropiate channels based on \sphinxcode{\sphinxupquote{DATA.CHANNELS}} for instance
segmentation.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item[{Returns}] \leavevmode
\sphinxstylestrong{train\_filenames} \textendash{} Training image paths.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_test\_instance\_channels() (in module data)@\spxentry{create\_test\_instance\_channels()}\spxextra{in module data}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/init:data.create_test_instance_channels}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.}}\sphinxbfcode{\sphinxupquote{create\_test\_instance\_channels}}}{\emph{\DUrole{n}{cfg}}}{}
Create test new data with appropiate channels based on \sphinxcode{\sphinxupquote{DATA.CHANNELS}} for instance segmentation.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item[{Returns}] \leavevmode
\sphinxstylestrong{test\_filenames} \textendash{} Test image paths.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{2D Data manipulation}
\label{\detokenize{data/data_2d_manipulation:module-data.data_2D_manipulation}}\label{\detokenize{data/data_2d_manipulation:d-data-manipulation}}\label{\detokenize{data/data_2d_manipulation::doc}}\index{module@\spxentry{module}!data.data\_2D\_manipulation@\spxentry{data.data\_2D\_manipulation}}\index{data.data\_2D\_manipulation@\spxentry{data.data\_2D\_manipulation}!module@\spxentry{module}}\index{load\_and\_prepare\_2D\_train\_data() (in module data.data\_2D\_manipulation)@\spxentry{load\_and\_prepare\_2D\_train\_data()}\spxextra{in module data.data\_2D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.load_and_prepare_2D_train_data}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_2D\_manipulation.}}\sphinxbfcode{\sphinxupquote{load\_and\_prepare\_2D\_train\_data}}}{\emph{\DUrole{n}{train\_path}}, \emph{\DUrole{n}{train\_mask\_path}}, \emph{\DUrole{n}{val\_split}\DUrole{o}{=}\DUrole{default_value}{0.1}}, \emph{\DUrole{n}{seed}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{shuffle\_val}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{e\_d\_data}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}, \emph{\DUrole{n}{e\_d\_mask}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}, \emph{\DUrole{n}{e\_d\_data\_dim}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}, \emph{\DUrole{n}{num\_crops\_per\_dataset}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{random\_crops\_in\_DA}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{crop\_shape}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{ov}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{check\_crop}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{check\_crop\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}check\_crop\textquotesingle{}}}}{}
Load train and validation images from the given paths to create 2D data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{train\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to the training data.

\item {} 
\sphinxstylestrong{train\_mask\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to the training data masks.

\item {} 
\sphinxstylestrong{val\_split} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} \% of the train data used as validation (value between \sphinxcode{\sphinxupquote{0}} and \sphinxcode{\sphinxupquote{1}}).

\item {} 
\sphinxstylestrong{seed} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Seed value.

\item {} 
\sphinxstylestrong{shuffle\_val} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Take random training examples to create validation data.

\item {} 
\sphinxstylestrong{e\_d\_data} (\sphinxcode{\sphinxupquote{list}} of \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} List of paths where the extra data of other datasets are stored. If \sphinxcode{\sphinxupquote{make\_crops}} is not enabled, these
extra datasets must have the same image shape as the main dataset since they are going to be stacked in a
unique array.

\item {} 
\sphinxstylestrong{e\_d\_mask} (\sphinxcode{\sphinxupquote{list}} of \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} List of paths where the extra data mask of other datasets are stored. Same constraints as \sphinxcode{\sphinxupquote{e\_d\_data}}.

\item {} 
\sphinxstylestrong{e\_d\_data\_dim} (\sphinxcode{\sphinxupquote{list}} of \sphinxcode{\sphinxupquote{3D int tuple}}, \sphinxstyleemphasis{optional}) \textendash{} List of shapes of the extra datasets provided. Same constraints as \sphinxcode{\sphinxupquote{e\_d\_data}}.

\item {} 
\sphinxstylestrong{num\_crops\_per\_dataset} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of crops per extra dataset to take into account. Useful to ensure that all the datasets have the same
weight during network trainning.

\item {} 
\sphinxstylestrong{random\_crops\_in\_DA} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To advice the method that not preparation of the data must be done, as random subvolumes will be created on
DA, and the whole volume will be used for that.

\item {} 
\sphinxstylestrong{crop\_shape} (\sphinxcode{\sphinxupquote{3D int tuple}}, \sphinxstyleemphasis{optional}) \textendash{} Shape of the crops. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{ov} (\sphinxcode{\sphinxupquote{2 floats tuple}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x and y dimensions. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}} or
\sphinxcode{\sphinxupquote{99\%}} of overlap. E.g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24)}}

\item {} 
\sphinxstylestrong{check\_crop} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To save the crops made to ensure they are generating as one wish.

\item {} 
\sphinxstylestrong{check\_crop\_path} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to save the crop samples.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{X\_train} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Train images. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, channels)}}.

\item {} 
\sphinxstylestrong{Y\_train} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Train images’ mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, channels)}}.

\item {} 
\sphinxstylestrong{X\_val} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Validation images (\sphinxcode{\sphinxupquote{val\_split \textgreater{} 0}}). E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, channels)}}.

\item {} 
\sphinxstylestrong{Y\_val} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Validation images’ mask (\sphinxcode{\sphinxupquote{val\_split \textgreater{} 0}}). E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, channels)}}.

\item {} 
\sphinxstylestrong{filenames} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}) \textendash{} Loaded train filenames.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Case where we need to load the data (creating a validation split)}
\PYG{n}{train\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/x}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{train\PYGZus{}mask\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/y}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Original image shape is (1024, 768, 165), so each image shape should be this:}
\PYG{n}{img\PYGZus{}train\PYGZus{}shape} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{X\PYGZus{}val}\PYG{p}{,}
\PYG{n}{Y\PYGZus{}val}\PYG{p}{,} \PYG{n}{crops\PYGZus{}made} \PYG{o}{=} \PYG{n}{load\PYGZus{}and\PYGZus{}prepare\PYGZus{}2D\PYGZus{}data}\PYG{p}{(}\PYG{n}{train\PYGZus{}path}\PYG{p}{,} \PYG{n}{train\PYGZus{}mask\PYGZus{}path}\PYG{p}{,} \PYG{n}{img\PYGZus{}train\PYGZus{}shape}\PYG{p}{,} \PYG{n}{val\PYGZus{}split}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,}
    \PYG{n}{shuffle\PYGZus{}val}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{make\PYGZus{}crops}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shapes of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     *** Loaded train data shape is: (148, 768, 1024, 1)}
\PYG{c+c1}{\PYGZsh{}     *** Loaded validation data shape is: (17, 768, 1024, 1)}
\PYG{c+c1}{\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{} Notice height and width swap because of Numpy ndarray terminology}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} Same as the first example but creating patches of (256x256)}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{X\PYGZus{}val}\PYG{p}{,}
\PYG{n}{Y\PYGZus{}val}\PYG{p}{,} \PYG{n}{crops\PYGZus{}made} \PYG{o}{=} \PYG{n}{load\PYGZus{}and\PYGZus{}prepare\PYGZus{}2D\PYGZus{}data}\PYG{p}{(}\PYG{n}{train\PYGZus{}path}\PYG{p}{,} \PYG{n}{train\PYGZus{}mask\PYGZus{}path}\PYG{p}{,} \PYG{n}{img\PYGZus{}train\PYGZus{}shape}\PYG{p}{,} \PYG{n}{val\PYGZus{}split}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,}
    \PYG{n}{shuffle\PYGZus{}val}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{make\PYGZus{}crops}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{crop\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{check\PYGZus{}crop}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
    \PYG{n}{check\PYGZus{}crop\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{check\PYGZus{}folder}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shapes of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}    *** Loaded train data shape is: (1776, 256, 256, 1)}
\PYG{c+c1}{\PYGZsh{}    *** Loaded validation data shape is: (204, 256, 256, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 3}
\PYG{c+c1}{\PYGZsh{} Same as the first example but defining extra datasets to be loaded and stacked together}
\PYG{c+c1}{\PYGZsh{} with the main dataset. Extra variables to be defined:}
\PYG{n}{extra\PYGZus{}datasets\PYGZus{}data\PYGZus{}list}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/data2/train/x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{extra\PYGZus{}datasets\PYGZus{}mask\PYGZus{}list}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/data2/train/y}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{extra\PYGZus{}datasets\PYGZus{}data\PYGZus{}dim\PYGZus{}list}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{877}\PYG{p}{,} \PYG{l+m+mi}{967}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{X\PYGZus{}val}\PYG{p}{,}
\PYG{n}{Y\PYGZus{}val}\PYG{p}{,} \PYG{n}{crops\PYGZus{}made} \PYG{o}{=} \PYG{n}{load\PYGZus{}and\PYGZus{}prepare\PYGZus{}2D\PYGZus{}data}\PYG{p}{(}\PYG{n}{train\PYGZus{}path}\PYG{p}{,} \PYG{n}{train\PYGZus{}mask\PYGZus{}path}\PYG{p}{,} \PYG{n}{img\PYGZus{}train\PYGZus{}shape}\PYG{p}{,} \PYG{n}{val\PYGZus{}split}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,}
    \PYG{n}{shuffle\PYGZus{}val}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{make\PYGZus{}crops}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{crop\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{check\PYGZus{}crop}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
    \PYG{n}{check\PYGZus{}crop\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{check\PYGZus{}folder}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{e\PYGZus{}d\PYGZus{}data}\PYG{o}{=}\PYG{n}{extra\PYGZus{}datasets\PYGZus{}data\PYGZus{}list}\PYG{p}{,} \PYG{n}{e\PYGZus{}d\PYGZus{}mask}\PYG{o}{=}\PYG{n}{extra\PYGZus{}datasets\PYGZus{}mask\PYGZus{}list}\PYG{p}{,}
    \PYG{n}{e\PYGZus{}d\PYGZus{}data\PYGZus{}dim}\PYG{o}{=}\PYG{n}{extra\PYGZus{}datasets\PYGZus{}data\PYGZus{}dim\PYGZus{}list}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{crop\_data\_with\_overlap() (in module data.data\_2D\_manipulation)@\spxentry{crop\_data\_with\_overlap()}\spxextra{in module data.data\_2D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.crop_data_with_overlap}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_2D\_manipulation.}}\sphinxbfcode{\sphinxupquote{crop\_data\_with\_overlap}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{crop\_shape}}, \emph{\DUrole{n}{data\_mask}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{overlap}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
Crop data into small square pieces with overlap. The difference with \sphinxcode{\sphinxupquote{crop\_data()}} is that this function
allows you to create patches with overlap.

The opposite function is {\hyperref[\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.merge_data_with_overlap}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{merge\_data\_with\_overlap()}}}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to crop. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{crop\_shape} (\sphinxcode{\sphinxupquote{3 int tuple}}) \textendash{} Shape of the crops to create. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{data\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Data mask to crop. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{overlap} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x and y dimensions. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}} or
\sphinxcode{\sphinxupquote{99\%}} of overlap. E. g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24)}}.

\item {} 
\sphinxstylestrong{verbose} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To print information about the crop to be made.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{cropped\_data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Cropped image data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{cropped\_data\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Cropped image data masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Divide in crops of (256, 256) a given data with the minimum overlap}
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Notice that as the shape of the data has exact division with the wnanted crops shape so no overlap will be}
\PYG{c+c1}{\PYGZsh{} made. The function will print the following information:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0, 0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.0, 0.0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (0.0, 0.0)}
\PYG{c+c1}{\PYGZsh{}     (3, 4) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (1980, 256, 256, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} Same as example 1 but with 25\PYGZpc{} of overlap between crops}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the following information:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0.25, 0.25)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.33203125, 0.3984375)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (85.0, 102.0)}
\PYG{c+c1}{\PYGZsh{}     (4, 6) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (3960, 256, 256, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 3}
\PYG{c+c1}{\PYGZsh{} Same as example 1 but with 50\PYGZpc{} of overlap between crops}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the created array. In this example:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0.5, 0.5)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.59765625, 0.5703125)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (153.0, 146.0)}
\PYG{c+c1}{\PYGZsh{}     (6, 8) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (7920, 256, 256, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 4}
\PYG{c+c1}{\PYGZsh{} Same as example 2 but with 50\PYGZpc{} of overlap only in x axis}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the created array. In this example:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0.5, 0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.59765625, 0.0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (153.0, 0.0)}
\PYG{c+c1}{\PYGZsh{}     (6, 4) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (3960, 256, 256, 1)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{merge\_data\_with\_overlap() (in module data.data\_2D\_manipulation)@\spxentry{merge\_data\_with\_overlap()}\spxextra{in module data.data\_2D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.merge_data_with_overlap}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_2D\_manipulation.}}\sphinxbfcode{\sphinxupquote{merge\_data\_with\_overlap}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{original\_shape}}, \emph{\DUrole{n}{data\_mask}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{overlap}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{out\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{prefix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\textquotesingle{}}}}{}
Merge data with an amount of overlap.

The opposite function is {\hyperref[\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.crop_data_with_overlap}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{crop\_data\_with\_overlap()}}}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to merge. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{original\_shape} (\sphinxcode{\sphinxupquote{4D int tuple}}) \textendash{} Shape of the original data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}

\item {} 
\sphinxstylestrong{data\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Data mask to merge. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{overlap} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x, y and z dimensions. Should be the same as used in
{\hyperref[\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.crop_data_with_overlap}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{crop\_data\_with\_overlap()}}}}}. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}} or \sphinxcode{\sphinxupquote{99\%}} of
overlap. E. g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24)}}.

\item {} 
\sphinxstylestrong{verbose} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To print information about the crop to be made.

\item {} 
\sphinxstylestrong{out\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} If provided an image that represents the overlap made will be saved. The image will be colored as follows:
green region when \sphinxcode{\sphinxupquote{==2}} crops overlap, yellow when \sphinxcode{\sphinxupquote{2 \textless{} x \textless{} 6}} and red when \sphinxcode{\sphinxupquote{=\textless{}6}} or more crops are
merged.

\item {} 
\sphinxstylestrong{prefix} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Prefix to save overlap map with.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{merged\_data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Merged image data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{merged\_data\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Merged image data mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Merge the data of example 1 of \PYGZsq{}crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap\PYGZsq{} function}

\PYG{c+c1}{\PYGZsh{} 1) CROP}
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} 2) MERGE}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{merge\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n}{out\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{out\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the following information:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0, 0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.0, 0.0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (0.0, 0.0)}
\PYG{c+c1}{\PYGZsh{}     (3, 4) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (165, 768, 1024, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} Merge the data of example 2 of \PYGZsq{}crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap\PYGZsq{} function}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{merge\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}
     \PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{)}\PYG{p}{,} \PYG{n}{out\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{out\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the following information:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0.25, 0.25)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.33203125, 0.3984375)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (85.0, 102.0)}
\PYG{c+c1}{\PYGZsh{}     (3, 5) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (165, 768, 1024, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 3}
\PYG{c+c1}{\PYGZsh{} Merge the data of example 3 of \PYGZsq{}crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap\PYGZsq{} function}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{merge\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{out\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{out\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the created array. In this example:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0.5, 0.5)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.59765625, 0.5703125)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (153.0, 146.0)}
\PYG{c+c1}{\PYGZsh{}     (6, 8) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (165, 768, 1024, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 4}
\PYG{c+c1}{\PYGZsh{} Merge the data of example 1 of \PYGZsq{}crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap\PYGZsq{} function}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{merge\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n}{out\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{out\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the created array. In this example:}
\PYG{c+c1}{\PYGZsh{}     Minimum overlap selected: (0.5, 0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (\PYGZpc{}): (0.59765625, 0.0)}
\PYG{c+c1}{\PYGZsh{}     Real overlapping (pixels): (153.0, 0.0)}
\PYG{c+c1}{\PYGZsh{}     (6, 4) patches per (x,y) axis}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (165, 768, 1024, 1)}
\end{sphinxVerbatim}

As example of different overlap maps are presented below.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{merged_ov_map_0}.png}
\sphinxfigcaption{Example 1 overlapping map}\label{\detokenize{data/data_2d_manipulation:id1}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{merged_ov_map_0.25}.png}
\sphinxfigcaption{Example 2 overlapping map}\label{\detokenize{data/data_2d_manipulation:id2}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{merged_ov_map_0.5}.png}
\sphinxfigcaption{Example 3 overlapping map}\label{\detokenize{data/data_2d_manipulation:id3}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{merged_ov_map_0.5inx}.png}
\sphinxfigcaption{Example 4 overlapping map}\label{\detokenize{data/data_2d_manipulation:id4}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\end{fulllineitems}

\index{check\_crops() (in module data.data\_2D\_manipulation)@\spxentry{check\_crops()}\spxextra{in module data.data\_2D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.check_crops}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_2D\_manipulation.}}\sphinxbfcode{\sphinxupquote{check\_crops}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{original\_shape}}, \emph{\DUrole{n}{ov}}, \emph{\DUrole{n}{num\_examples}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{include\_crops}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{out\_dir}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}check\_crops\textquotesingle{}}}, \emph{\DUrole{n}{prefix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\textquotesingle{}}}}{}
Check cropped images by the function \sphinxcode{\sphinxupquote{crop\_data()}} and
{\hyperref[\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.crop_data_with_overlap}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{crop\_data\_with\_overlap()}}}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to crop. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{original\_shape} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{4 ints}}) \textendash{} Shape of the original data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{ov} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x and y dimensions. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}} or
\sphinxcode{\sphinxupquote{99\%}} of overlap. E. g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{num\_examples} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of examples to create.

\item {} 
\sphinxstylestrong{include\_crops} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To save cropped images or only the image to contruct.

\item {} 
\sphinxstylestrong{out\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Directory where the images will be save.

\item {} 
\sphinxstylestrong{prefix} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Prefix to save overlap map with.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Check crops made in the first example of \PYGZsq{}crop\PYGZus{}data\PYGZsq{} function}
\PYG{n}{original\PYGZus{}shape} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{)}
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{original\PYGZus{}shape}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{original\PYGZus{}shape}\PYG{p}{)}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{check\PYGZus{}crops}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{original\PYGZus{}shape}\PYG{p}{,} \PYG{n}{num\PYGZus{}examples}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{out\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{out}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

The example above will store 12 individual crops (4x3, height x width), and two images of the original shape:
data image and its mask. For instance:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{check_crop_data}.png}
\end{sphinxfigure-in-table}\relax

Original image (the grid should be each crop)
&\begin{sphinxfigure-in-table}
\centering

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{check_crop_mask}.png}
\end{sphinxfigure-in-table}\relax

Original mask (the grid should be each crop)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\end{fulllineitems}

\index{random\_crop() (in module data.data\_2D\_manipulation)@\spxentry{random\_crop()}\spxextra{in module data.data\_2D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_2d_manipulation:data.data_2D_manipulation.random_crop}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_2D\_manipulation.}}\sphinxbfcode{\sphinxupquote{random\_crop}}}{\emph{\DUrole{n}{image}}, \emph{\DUrole{n}{mask}}, \emph{\DUrole{n}{random\_crop\_size}}, \emph{\DUrole{n}{val}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{draw\_prob\_map\_points}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{img\_prob}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{weight\_map}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Random crop.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image} (\sphinxcode{\sphinxupquote{Numpy 3D array}}) \textendash{} Image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{Numpy 3D array}}) \textendash{} Image mask. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{random\_crop\_size} (\sphinxcode{\sphinxupquote{2 int tuple}}) \textendash{} Size of the crop. E.g. \sphinxcode{\sphinxupquote{(height, width)}}.

\item {} 
\sphinxstylestrong{val} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} If the image provided is going to be used in the validation data. This forces to crop from the origin,
e. g. \sphinxcode{\sphinxupquote{(0, 0)}} point.

\item {} 
\sphinxstylestrong{draw\_prob\_map\_points} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To return the pixel chosen to be the center of the crop.

\item {} 
\sphinxstylestrong{img\_prob} (\sphinxcode{\sphinxupquote{Numpy 3D array}}, \sphinxstyleemphasis{optional}) \textendash{} Probability of each pixel to be chosen as the center of the crop. E. .g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{weight\_map} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Weight map of the given image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{2D Numpy array}}) \textendash{} Crop of the given image. E.g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{weight\_map} (\sphinxcode{\sphinxupquote{2D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Crop of the given image’s weigth map. E.g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{ox} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} X coordinate in the complete image of the chose central pixel to make the crop.

\item {} 
\sphinxstylestrong{oy} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Y coordinate in the complete image of the chose central pixel to make the crop.

\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} X coordinate in the complete image where the crop starts.

\item {} 
\sphinxstylestrong{y} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Y coordinate in the complete image where the crop starts.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\subsection{3D Data manipulation}
\label{\detokenize{data/data_3d_manipulation:module-data.data_3D_manipulation}}\label{\detokenize{data/data_3d_manipulation:d-data-manipulation}}\label{\detokenize{data/data_3d_manipulation::doc}}\index{module@\spxentry{module}!data.data\_3D\_manipulation@\spxentry{data.data\_3D\_manipulation}}\index{data.data\_3D\_manipulation@\spxentry{data.data\_3D\_manipulation}!module@\spxentry{module}}\index{load\_and\_prepare\_3D\_data() (in module data.data\_3D\_manipulation)@\spxentry{load\_and\_prepare\_3D\_data()}\spxextra{in module data.data\_3D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.load_and_prepare_3D_data}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_3D\_manipulation.}}\sphinxbfcode{\sphinxupquote{load\_and\_prepare\_3D\_data}}}{\emph{\DUrole{n}{train\_path}}, \emph{\DUrole{n}{train\_mask\_path}}, \emph{\DUrole{n}{val\_split}\DUrole{o}{=}\DUrole{default_value}{0.1}}, \emph{\DUrole{n}{seed}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{shuffle\_val}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{crop\_shape}\DUrole{o}{=}\DUrole{default_value}{80, 80, 80, 1}}, \emph{\DUrole{n}{random\_crops\_in\_DA}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{ov}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}}{}
Load train and validation images from the given paths to create 3D data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{train\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to the training data.

\item {} 
\sphinxstylestrong{train\_mask\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to the training data masks.

\item {} 
\sphinxstylestrong{val\_split} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} \sphinxcode{\sphinxupquote{\%}} of the train data used as validation (value between \sphinxcode{\sphinxupquote{0}} and \sphinxcode{\sphinxupquote{1}}).

\item {} 
\sphinxstylestrong{seed} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Seed value.

\item {} 
\sphinxstylestrong{shuffle\_val} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Take random training examples to create validation data.

\item {} 
\sphinxstylestrong{crop\_shape} (\sphinxcode{\sphinxupquote{4D tuple}}) \textendash{} Shape of the train subvolumes to create. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{random\_crops\_in\_DA} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To advice the method that not preparation of the data must be done, as random subvolumes will be created on
DA, and the whole volume will be used for that.

\item {} 
\sphinxstylestrong{ov} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{3 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x, y and z dimensions. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}}
or \sphinxcode{\sphinxupquote{99\%}} of overlap. E. g. \sphinxcode{\sphinxupquote{(x, y, z)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y, z)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24, 24)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{X\_train} (\sphinxcode{\sphinxupquote{5D Numpy array}}) \textendash{} Train images. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, z, channels)}}.

\item {} 
\sphinxstylestrong{Y\_train} (\sphinxcode{\sphinxupquote{5D Numpy array}}) \textendash{} Train images’ mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, z, channels)}}.

\item {} 
\sphinxstylestrong{X\_val} (\sphinxcode{\sphinxupquote{5D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Validation images (\sphinxcode{\sphinxupquote{val\_split \textgreater{} 0}}). E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, z, channels)}}.

\item {} 
\sphinxstylestrong{Y\_val} (\sphinxcode{\sphinxupquote{5D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Validation images’ mask (\sphinxcode{\sphinxupquote{val\_split \textgreater{} 0}}). E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, z, channels)}}.

\item {} 
\sphinxstylestrong{filenames} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}) \textendash{} Loaded train filenames.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Case where we need to load the data and creating a validation split}
\PYG{n}{train\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/x}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{train\PYGZus{}mask\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/y}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Train data is (15, 1024, 1024, 91) where (number\PYGZus{}of\PYGZus{}images, x, y, z), so each image shape should be this:}
\PYG{n}{img\PYGZus{}train\PYGZus{}shape} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{91}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} 3D subvolume shape needed}
\PYG{n}{train\PYGZus{}3d\PYGZus{}shape} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{40}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{X\PYGZus{}val}\PYG{p}{,}
\PYG{n}{Y\PYGZus{}val}\PYG{p}{,} \PYG{n}{filenames} \PYG{o}{=} \PYG{n}{load\PYGZus{}and\PYGZus{}prepare\PYGZus{}3D\PYGZus{}data\PYGZus{}v2}\PYG{p}{(}\PYG{n}{train\PYGZus{}path}\PYG{p}{,} \PYG{n}{train\PYGZus{}mask\PYGZus{}path}\PYG{p}{,} \PYG{n}{train\PYGZus{}3d\PYGZus{}shape}\PYG{p}{,}
                                               \PYG{n}{val\PYGZus{}split}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{shuffle\PYGZus{}val}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{ov}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shapes of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     *** Loaded train data shape is: (315, 256, 256, 40, 1)}
\PYG{c+c1}{\PYGZsh{}     *** Loaded train mask shape is: (315, 256, 256, 40, 1)}
\PYG{c+c1}{\PYGZsh{}     *** Loaded validation data shape is: (35, 256, 256, 40, 1)}
\PYG{c+c1}{\PYGZsh{}     *** Loaded validation mask shape is: (35, 256, 256, 40, 1)}
\PYG{c+c1}{\PYGZsh{}}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{crop\_3D\_data\_with\_overlap() (in module data.data\_3D\_manipulation)@\spxentry{crop\_3D\_data\_with\_overlap()}\spxextra{in module data.data\_3D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.crop_3D_data_with_overlap}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_3D\_manipulation.}}\sphinxbfcode{\sphinxupquote{crop\_3D\_data\_with\_overlap}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{vol\_shape}}, \emph{\DUrole{n}{data\_mask}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{overlap}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{median\_padding}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Crop 3D data into smaller volumes with a defined overlap. The opposite function is {\hyperref[\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.merge_3D_data_with_overlap}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{merge\_3D\_data\_with\_overlap()}}}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to crop. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{vol\_shape} (\sphinxcode{\sphinxupquote{4D int tuple}}) \textendash{} Shape of the volumes to create. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{data\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Data mask to crop. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{overlap} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{3 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x, y and z dimensions. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}}
or \sphinxcode{\sphinxupquote{99\%}} of overlap. E.g. \sphinxcode{\sphinxupquote{(x, y, z)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y, z)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24, 24)}}.

\item {} 
\sphinxstylestrong{verbose} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To print information about the crop to be made.

\item {} 
\sphinxstylestrong{median\_padding} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{True}} the padding value is the median value. If \sphinxcode{\sphinxupquote{False}}, the added values are zeroes.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{cropped\_data} (\sphinxcode{\sphinxupquote{5D Numpy array}}) \textendash{} Cropped image data. E.g. \sphinxcode{\sphinxupquote{(vol\_number, x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{cropped\_data\_mask} (\sphinxcode{\sphinxupquote{5D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Cropped image data masks. E.g. \sphinxcode{\sphinxupquote{(vol\_number, x, y, z, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Following the example introduced in load\PYGZus{}and\PYGZus{}prepare\PYGZus{}3D\PYGZus{}data function, the cropping of a volume with shape}
\PYG{c+c1}{\PYGZsh{} (165, 1024, 765) should be done by the following call:}
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,}
                                             \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} The function will print the shape of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (2600, 80, 80, 80, 1)}
\end{sphinxVerbatim}

A visual explanation of the process:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{crop_3D_ov}.png}\hspace*{\fill}}

Note: this image do not respect the proportions.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} Same data crop but without overlap}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (390, 80, 80, 80, 1)}
\PYG{c+c1}{\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{} Notice how differs the amount of subvolumes created compared to the first example}

\PYG{c+c1}{\PYGZsh{}EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{}In the same way, if the addition of (64,64,64) padding is required, the call should be done as shown:}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}
     \PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{padding}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{,}\PYG{l+m+mi}{64}\PYG{p}{,}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{crop\_3D\_data() (in module data.data\_3D\_manipulation)@\spxentry{crop\_3D\_data()}\spxextra{in module data.data\_3D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.crop_3D_data}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_3D\_manipulation.}}\sphinxbfcode{\sphinxupquote{crop\_3D\_data}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{vol\_shape}}, \emph{\DUrole{n}{data\_mask}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{use\_rest}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
Crop 3D data into smaller volumes without overlap. If there is no exact division between the data shape and
\sphinxcode{\sphinxupquote{vol\_shape}} in a specific dimension it will be discarded or zeros will be added if \sphinxcode{\sphinxupquote{use\_rest}} is True.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{Numpy 4D array}}) \textendash{} Data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{vol\_shape} (\sphinxcode{\sphinxupquote{4D int tuple}}) \textendash{} Shape of the volumes to create. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{data\_mask} (\sphinxcode{\sphinxupquote{Numpy 4D array}}, \sphinxstyleemphasis{optional}) \textendash{} Mask data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{use\_rest} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Controls how the rest data will be processed. When there is no exact division between the data shape and
\sphinxcode{\sphinxupquote{vol\_shape}} in a specific dimension, the remainder data is not enough to create another subvolume. If True,
that data will be used completing the rest of the subvolume with zeros. If \sphinxcode{\sphinxupquote{False}}, that remainder will be
dropped (notice that this option will make the data impossible to reconstruct 100\% later on). See example 2
for more info.

\item {} 
\sphinxstylestrong{verbose} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To print information about the crop to be made.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{cropped\_data} (\sphinxcode{\sphinxupquote{Numpy 5D array}}) \textendash{} data data separated in different subvolumes with the provided shape. E.g. \sphinxcode{\sphinxupquote{(subvolume\_number, ) + shape}}.

\item {} 
\sphinxstylestrong{cropped\_data\_mask} (\sphinxcode{\sphinxupquote{Numpy 5D array}}) \textendash{} data\_mask data separated in different subvolumes with the provided shape. E.g. \sphinxcode{\sphinxupquote{(subvolume\_number, ) + shape}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Crop into subvolumes a volume with shape (165, 1024, 765)}

\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}3D}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the generated arrays and the data discarded on each axis ``(x,y,z)``,}
\PYG{c+c1}{\PYGZsh{} as use\PYGZus{}rest is False}
\PYG{c+c1}{\PYGZsh{}       [...]}
\PYG{c+c1}{\PYGZsh{}    Pixels dropped per dimension: (48,64,5)}
\PYG{c+c1}{\PYGZsh{}       [...]}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (216, 80, 80, 80, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} As the first example but using all the data}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}3D}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{use\PYGZus{}rest}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (390, 80, 80, 80, 1)}
\end{sphinxVerbatim}

A visual explanation of example 2:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{crop_3D}.png}\hspace*{\fill}}

As you may noticed, as \sphinxcode{\sphinxupquote{use\_rest=True}} the last subvolume is filled with zeros (black) instead of been
discarded. Thus, more subvolumes have been created.

Adding zeros to all the axis when they do not have an exact division could not be the best approach in all cases.
In example 2, the amount of pixels along x and y axis are not to much, however, for the z axis, that amount is high
considering that we only have about 165 slices. To notify the user, the method also prints the number of zeros
added per each axis \sphinxcode{\sphinxupquote{(x,y,z)}} as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}3D}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{use\PYGZus{}rest}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}       [...]}
\PYG{c+c1}{\PYGZsh{}     Zeros added per dimension: (32,16,75)}
\PYG{c+c1}{\PYGZsh{}       [...]}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (390, 80, 80, 80, 1)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{merge\_3D\_data\_with\_overlap() (in module data.data\_3D\_manipulation)@\spxentry{merge\_3D\_data\_with\_overlap()}\spxextra{in module data.data\_3D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.merge_3D_data_with_overlap}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_3D\_manipulation.}}\sphinxbfcode{\sphinxupquote{merge\_3D\_data\_with\_overlap}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{orig\_vol\_shape}}, \emph{\DUrole{n}{data\_mask}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{overlap}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
Merge 3D subvolumes in a 3D volume with a defined overlap.

The opposite function is {\hyperref[\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.crop_3D_data_with_overlap}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{crop\_3D\_data\_with\_overlap()}}}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{5D Numpy array}}) \textendash{} Data to crop. E.g. \sphinxcode{\sphinxupquote{(volume\_number, x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{orig\_vol\_shape} (\sphinxcode{\sphinxupquote{4D int tuple}}) \textendash{} Shape of the volumes to create.

\item {} 
\sphinxstylestrong{data\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Data mask to crop. E.g. \sphinxcode{\sphinxupquote{(volume\_number, x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{overlap} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{3 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x, y and z dimensions. Should be the same as used in
{\hyperref[\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.crop_3D_data_with_overlap}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{crop\_3D\_data\_with\_overlap()}}}}}. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}} or \sphinxcode{\sphinxupquote{99\%}} of
overlap. E.g. \sphinxcode{\sphinxupquote{(x, y, z)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y, z)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24, 24)}}.

\item {} 
\sphinxstylestrong{verbose} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To print information about the crop to be made.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{merged\_data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Cropped image data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{merged\_data\_mask} (\sphinxcode{\sphinxupquote{5D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Cropped image data masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Following the example introduced in crop\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap function, the merge after the cropping}
\PYG{c+c1}{\PYGZsh{} should be done as follows:}

\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{crop\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{merge\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (165, 768, 1024, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} In the same way, if no overlap in cropping was selected, the merge call}
\PYG{c+c1}{\PYGZsh{} should be as follows:}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{merge\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (165, 768, 1024, 1)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 3}
\PYG{c+c1}{\PYGZsh{} On the contrary, if no overlap in cropping was selected but a padding of shape}
\PYG{c+c1}{\PYGZsh{} (64,64,64) is needed, the merge call should be as follows:}

\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{merge\PYGZus{}3D\PYGZus{}data\PYGZus{}with\PYGZus{}overlap}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{data\PYGZus{}mask}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{padding}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{,}\PYG{l+m+mi}{64}\PYG{p}{,}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the generated arrays. In this example:}
\PYG{c+c1}{\PYGZsh{}     **** New data shape is: (165, 768, 1024, 1)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{random\_3D\_crop() (in module data.data\_3D\_manipulation)@\spxentry{random\_3D\_crop()}\spxextra{in module data.data\_3D\_manipulation}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/data_3d_manipulation:data.data_3D_manipulation.random_3D_crop}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.data\_3D\_manipulation.}}\sphinxbfcode{\sphinxupquote{random\_3D\_crop}}}{\emph{\DUrole{n}{vol}}, \emph{\DUrole{n}{vol\_mask}}, \emph{\DUrole{n}{random\_crop\_size}}, \emph{\DUrole{n}{val}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{vol\_prob}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{weight\_map}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{draw\_prob\_map\_points}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Extracts a random 3D patch from the given image and mask.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{vol} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to extract the patch from. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{vol\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data mask to extract the patch from. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{random\_crop\_size} (\sphinxcode{\sphinxupquote{3D int tuple}}) \textendash{} Shape of the patches to create. E.g. \sphinxcode{\sphinxupquote{(x, y, z)}}.

\item {} 
\sphinxstylestrong{val} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} If the image provided is going to be used in the validation data. This forces to crop from the origin, e.g.
\sphinxcode{\sphinxupquote{(0, 0)}} point.

\item {} 
\sphinxstylestrong{vol\_prob} (\sphinxcode{\sphinxupquote{Numpy 3D array}}, \sphinxstyleemphasis{optional}) \textendash{} Probability of each pixel to be chosen as the center of the crop. E. g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{weight\_map} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Weight map of the given image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{draw\_prob\_map\_points} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To return the voxel chosen to be the center of the crop.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Crop of the given image. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{weight\_map} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Crop of the given image’s weigth map. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{ox} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} X coordinate in the complete image of the chose central pixel to
make the crop.

\item {} 
\sphinxstylestrong{oy} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Y coordinate in the complete image of the chose central pixel to
make the crop.

\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} X coordinate in the complete image where the crop starts.

\item {} 
\sphinxstylestrong{y} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Y coordinate in the complete image where the crop starts.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\subsection{generators}
\label{\detokenize{data/generators/generators:generators}}\label{\detokenize{data/generators/generators::doc}}

\subsubsection{Init}
\label{\detokenize{data/generators/init:module-data.generators}}\label{\detokenize{data/generators/init:init}}\label{\detokenize{data/generators/init::doc}}\index{module@\spxentry{module}!data.generators@\spxentry{data.generators}}\index{data.generators@\spxentry{data.generators}!module@\spxentry{module}}\index{create\_train\_val\_augmentors() (in module data.generators)@\spxentry{create\_train\_val\_augmentors()}\spxextra{in module data.generators}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/init:data.generators.create_train_val_augmentors}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.}}\sphinxbfcode{\sphinxupquote{create\_train\_val\_augmentors}}}{\emph{\DUrole{n}{cfg}}, \emph{\DUrole{n}{X\_train}}, \emph{\DUrole{n}{Y\_train}}, \emph{\DUrole{n}{X\_val}}, \emph{\DUrole{n}{Y\_val}}}{}
Create training and validation generators.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item {} 
\sphinxstylestrong{X\_train} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Training data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y\_train} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Training data mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, 1)}}.

\item {} 
\sphinxstylestrong{X\_val} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Validation data mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y\_val} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Validation data mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, 1)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{train\_generator} (\sphinxcode{\sphinxupquote{ImageDataGenerator (2D)}} or \sphinxcode{\sphinxupquote{VoxelDataGenerator (3D)}}) \textendash{} Training data generator.

\item {} 
\sphinxstylestrong{val\_generator} (\sphinxcode{\sphinxupquote{ImageDataGenerator (2D)}} or \sphinxcode{\sphinxupquote{VoxelDataGenerator (3D)}}) \textendash{} Validation data generator.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{create\_test\_augmentor() (in module data.generators)@\spxentry{create\_test\_augmentor()}\spxextra{in module data.generators}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/init:data.generators.create_test_augmentor}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.}}\sphinxbfcode{\sphinxupquote{create\_test\_augmentor}}}{\emph{\DUrole{n}{cfg}}, \emph{\DUrole{n}{X\_test}}, \emph{\DUrole{n}{Y\_test}}}{}
Create test data generator.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item {} 
\sphinxstylestrong{X\_test} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Test data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y\_test} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Test data mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, 1)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{test\_generator} \textendash{} Test data generator.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{ImageDataGenerator (2D)}} or \sphinxcode{\sphinxupquote{VoxelDataGenerator (3D)}}

\end{description}\end{quote}

\end{fulllineitems}

\index{check\_generator\_consistence() (in module data.generators)@\spxentry{check\_generator\_consistence()}\spxextra{in module data.generators}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/init:data.generators.check_generator_consistence}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.}}\sphinxbfcode{\sphinxupquote{check\_generator\_consistence}}}{\emph{\DUrole{n}{gen}}, \emph{\DUrole{n}{data\_out\_dir}}, \emph{\DUrole{n}{mask\_out\_dir}}, \emph{\DUrole{n}{filenames}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Save all data of a generator in the given path.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{gen} (\sphinxcode{\sphinxupquote{ImageDataGenerator (2D)}} or \sphinxcode{\sphinxupquote{VoxelDataGenerator (3D)}}) \textendash{} Generator to extract the data from.

\item {} 
\sphinxstylestrong{data\_out\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to store the generator data samples.

\item {} 
\sphinxstylestrong{mask\_out\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to store the generator data mask samples.

\item {} 
\sphinxstylestrong{Filenames} (\sphinxcode{\sphinxupquote{List}}, \sphinxstyleemphasis{optional}) \textendash{} Filenames that should be used when saving each image.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{2D generator}
\label{\detokenize{data/generators/2d_generator:module-data.generators.data_2D_generator}}\label{\detokenize{data/generators/2d_generator:d-generator}}\label{\detokenize{data/generators/2d_generator::doc}}\index{module@\spxentry{module}!data.generators.data\_2D\_generator@\spxentry{data.generators.data\_2D\_generator}}\index{data.generators.data\_2D\_generator@\spxentry{data.generators.data\_2D\_generator}!module@\spxentry{module}}\index{ImageDataGenerator (class in data.generators.data\_2D\_generator)@\spxentry{ImageDataGenerator}\spxextra{class in data.generators.data\_2D\_generator}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/2d_generator:data.generators.data_2D_generator.ImageDataGenerator}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{data.generators.data\_2D\_generator.}}\sphinxbfcode{\sphinxupquote{ImageDataGenerator}}}{\emph{\DUrole{n}{X}}, \emph{\DUrole{n}{Y}}, \emph{\DUrole{n}{batch\_size}\DUrole{o}{=}\DUrole{default_value}{32}}, \emph{\DUrole{n}{seed}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{shuffle\_each\_epoch}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{in\_memory}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{data\_paths}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{da}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{da\_prob}\DUrole{o}{=}\DUrole{default_value}{0.5}}, \emph{\DUrole{n}{rotation90}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{rand\_rot}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{rnd\_rot\_range}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 180, 180}}, \emph{\DUrole{n}{shear}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{shear\_range}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 20, 20}}, \emph{\DUrole{n}{zoom}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{zoom\_range}\DUrole{o}{=}\DUrole{default_value}{0.8, 1.2}}, \emph{\DUrole{n}{shift}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{shift\_range}\DUrole{o}{=}\DUrole{default_value}{0.1, 0.2}}, \emph{\DUrole{n}{vflip}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{hflip}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{elastic}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{e\_alpha}\DUrole{o}{=}\DUrole{default_value}{240, 250}}, \emph{\DUrole{n}{e\_sigma}\DUrole{o}{=}\DUrole{default_value}{25}}, \emph{\DUrole{n}{e\_mode}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}constant\textquotesingle{}}}, \emph{\DUrole{n}{g\_blur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{g\_sigma}\DUrole{o}{=}\DUrole{default_value}{1.0, 2.0}}, \emph{\DUrole{n}{median\_blur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{mb\_kernel}\DUrole{o}{=}\DUrole{default_value}{3, 7}}, \emph{\DUrole{n}{motion\_blur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{motb\_k\_range}\DUrole{o}{=}\DUrole{default_value}{3, 8}}, \emph{\DUrole{n}{gamma\_contrast}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{gc\_gamma}\DUrole{o}{=}\DUrole{default_value}{1.25, 1.75}}, \emph{\DUrole{n}{brightness}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{brightness\_factor}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{contrast}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{contrast\_factor}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{drop\_range}\DUrole{o}{=}\DUrole{default_value}{0, 0.2}}, \emph{\DUrole{n}{cutout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cout\_nb\_iterations}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{cout\_size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{cout\_cval}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{cout\_apply\_to\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cutblur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cblur\_size}\DUrole{o}{=}\DUrole{default_value}{0.1, 0.5}}, \emph{\DUrole{n}{cblur\_down\_range}\DUrole{o}{=}\DUrole{default_value}{2, 8}}, \emph{\DUrole{n}{cblur\_inside}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{cutmix}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cmix\_size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{cutnoise}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cnoise\_scale}\DUrole{o}{=}\DUrole{default_value}{0.1, 0.2}}, \emph{\DUrole{n}{cnoise\_nb\_iterations}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{cnoise\_size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{misalignment}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{ms\_displacement}\DUrole{o}{=}\DUrole{default_value}{16}}, \emph{\DUrole{n}{ms\_rotate\_ratio}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{missing\_parts}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{missp\_iterations}\DUrole{o}{=}\DUrole{default_value}{30, 40}}, \emph{\DUrole{n}{random\_crops\_in\_DA}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{shape}\DUrole{o}{=}\DUrole{default_value}{256, 256, 1}}, \emph{\DUrole{n}{prob\_map}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{val}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{out\_number}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{extra\_data\_factor}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.utils.data\_utils.Sequence}}

Custom 2D ImageDataGenerator based on \sphinxhref{https://github.com/aleju/imgaug-doc}{imgaug}
and our own \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/blob/master/generators/augmentors.py}{augmentors.py}
transformations.

Based on \sphinxhref{https://github.com/czbiohub/microDL}{microDL} and
\sphinxhref{https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly}{Shervine’s blog}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Mask data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, 1)}}.

\item {} 
\sphinxstylestrong{batch\_size} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Size of the batches.

\item {} 
\sphinxstylestrong{shuffle\_each\_epoch} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To decide if the indexes will be shuffled after every epoch.

\item {} 
\sphinxstylestrong{in\_memory} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{True}} data used will be \sphinxcode{\sphinxupquote{X}} and \sphinxcode{\sphinxupquote{Y}}. If \sphinxcode{\sphinxupquote{False}} it will be loaded directly from disk using
\sphinxcode{\sphinxupquote{data\_paths}}.

\item {} 
\sphinxstylestrong{data\_paths} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{in\_memory}} is \sphinxcode{\sphinxupquote{True}} this list should contain the paths to load data and masks. \sphinxcode{\sphinxupquote{data\_paths{[}0{]}}}
should be data path and \sphinxcode{\sphinxupquote{data\_paths{[}1{]}}} masks path.

\item {} 
\sphinxstylestrong{da} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To activate the data augmentation.

\item {} 
\sphinxstylestrong{da\_prob} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Probability of doing each transformation.

\item {} 
\sphinxstylestrong{rotation90} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make square (90, 180,270) degree rotations.

\item {} 
\sphinxstylestrong{rand\_rot} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make random degree range rotations.

\item {} 
\sphinxstylestrong{rnd\_rot\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Range of random rotations. E. g. \sphinxcode{\sphinxupquote{(\sphinxhyphen{}180, 180)}}.

\item {} 
\sphinxstylestrong{shear} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make shear transformations.

\item {} 
\sphinxstylestrong{shear\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Degree range to make shear. E. g. \sphinxcode{\sphinxupquote{(\sphinxhyphen{}20, 20)}}.

\item {} 
\sphinxstylestrong{zoom} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make zoom on images.

\item {} 
\sphinxstylestrong{zoom\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Zoom range to apply. E. g. \sphinxcode{\sphinxupquote{(0.8, 1.2)}}.

\item {} 
\sphinxstylestrong{shift} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} To make shifts.

\item {} 
\sphinxstylestrong{shift\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Range to make a shift. E. g. \sphinxcode{\sphinxupquote{(0.1, 0.2)}}.

\item {} 
\sphinxstylestrong{vflip} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To activate vertical flips.

\item {} 
\sphinxstylestrong{hflip} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To activate horizontal flips.

\item {} 
\sphinxstylestrong{elastic} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make elastic deformations.

\item {} 
\sphinxstylestrong{e\_alpha} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Strength of the distortion field. E. g. \sphinxcode{\sphinxupquote{(240, 250)}}.

\item {} 
\sphinxstylestrong{e\_sigma} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Standard deviation of the gaussian kernel used to smooth the distortion fields.

\item {} 
\sphinxstylestrong{e\_mode} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Parameter that defines the handling of newly created pixels with the elastic transformation.

\item {} 
\sphinxstylestrong{g\_blur} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To insert gaussian blur on the images.

\item {} 
\sphinxstylestrong{g\_sigma} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Standard deviation of the gaussian kernel. E. g. \sphinxcode{\sphinxupquote{(1.0, 2.0)}}.

\item {} 
\sphinxstylestrong{median\_blur} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To blur an image by computing median values over neighbourhoods.

\item {} 
\sphinxstylestrong{mb\_kernel} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Median blur kernel size. E. g. \sphinxcode{\sphinxupquote{(3, 7)}}.

\item {} 
\sphinxstylestrong{motion\_blur} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Blur images in a way that fakes camera or object movements.

\item {} 
\sphinxstylestrong{motb\_k\_range} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel size to use in motion blur.

\item {} 
\sphinxstylestrong{gamma\_contrast} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To insert gamma constrast changes on images.

\item {} 
\sphinxstylestrong{gc\_gamma} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Exponent for the contrast adjustment. Higher values darken the image. E. g. \sphinxcode{\sphinxupquote{(1.25, 1.75)}}.

\item {} 
\sphinxstylestrong{brightness} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To aply brightness to the images.

\item {} 
\sphinxstylestrong{brightness\_factor} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Strength of the brightness range, with valid values being \sphinxcode{\sphinxupquote{0 \textless{}= brightness\_factor \textless{}= 1}}. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.3)}}.

\item {} 
\sphinxstylestrong{contrast} (\sphinxcode{\sphinxupquote{boolen}}, \sphinxstyleemphasis{optional}) \textendash{} To apply contrast changes to the images.

\item {} 
\sphinxstylestrong{contrast\_factor} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Strength of the contrast change range, with valid values being \sphinxcode{\sphinxupquote{0 \textless{}= contrast\_factor \textless{}= 1}}. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.3)}}.

\item {} 
\sphinxstylestrong{dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To set a certain fraction of pixels in images to zero.

\item {} 
\sphinxstylestrong{drop\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to take a probability \sphinxcode{\sphinxupquote{p}} to drop pixels. E.g. \sphinxcode{\sphinxupquote{(0, 0.2)}} will take a \sphinxcode{\sphinxupquote{p}} folowing \sphinxcode{\sphinxupquote{0\textless{}=p\textless{}=0.2}}
and then drop \sphinxcode{\sphinxupquote{p}} percent of all pixels in the image (i.e. convert them to black pixels).

\item {} 
\sphinxstylestrong{cutout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To fill one or more rectangular areas in an image using a fill mode.

\item {} 
\sphinxstylestrong{cout\_nb\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Range of number of areas to fill the image with. E. g. \sphinxcode{\sphinxupquote{(1, 3)}}.

\item {} 
\sphinxstylestrong{cout\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to select the size of the areas in \% of the corresponding image size. Values between \sphinxcode{\sphinxupquote{0}} and \sphinxcode{\sphinxupquote{1}}.
E. g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{cout\_cval} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Value to fill the area of cutout with.

\item {} 
\sphinxstylestrong{cout\_apply\_to\_mask} (\sphinxcode{\sphinxupquote{boolen}}, \sphinxstyleemphasis{optional}) \textendash{} Wheter to apply cutout to the mask.

\item {} 
\sphinxstylestrong{cutblur} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Blur a rectangular area of the image by downsampling and upsampling it again.

\item {} 
\sphinxstylestrong{cblur\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to select the size of the area to apply cutblur on. E. g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{cblur\_inside} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{True}} only the region inside will be modified (cut LR into HR image). If \sphinxcode{\sphinxupquote{False}} the \sphinxcode{\sphinxupquote{50\%}} of the
times the region inside will be modified (cut LR into HR image) and the other \sphinxcode{\sphinxupquote{50\%}} the inverse will be
done (cut HR into LR image). See Figure 1 of the official \sphinxhref{https://arxiv.org/pdf/2004.00448.pdf}{paper}.

\item {} 
\sphinxstylestrong{cutmix} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Combine two images pasting a region of one image to another.

\item {} 
\sphinxstylestrong{cmix\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to select the size of the area to paste one image into another. E. g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{cnoise} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Randomly add noise to a cuboid region in the image.

\item {} 
\sphinxstylestrong{cnoise\_scale} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Scale of the random noise. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.2)}}.

\item {} 
\sphinxstylestrong{cnoise\_nb\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Number of areas with noise to create. E.g. \sphinxcode{\sphinxupquote{(1, 3)}}.

\item {} 
\sphinxstylestrong{cnoise\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to choose the size of the areas to transform. E.g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{misalignment} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} To add miss\sphinxhyphen{}aligment augmentation.

\item {} 
\sphinxstylestrong{ms\_displacement} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Maximum pixel displacement in \sphinxtitleref{xy}\sphinxhyphen{}plane for misalignment.

\item {} 
\sphinxstylestrong{ms\_rotate\_ratio} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Ratio of rotation\sphinxhyphen{}based mis\sphinxhyphen{}alignment

\item {} 
\sphinxstylestrong{missing\_parts} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Augment the image by creating a black line in a random position.

\item {} 
\sphinxstylestrong{missp\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 ints}}, \sphinxstyleemphasis{optional}) \textendash{} Iterations to dilate the missing line with. E.g. \sphinxcode{\sphinxupquote{(30, 40)}}.

\item {} 
\sphinxstylestrong{random\_crops\_in\_DA} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Decide to make random crops in DA (before transformations).

\item {} 
\sphinxstylestrong{shape} (\sphinxcode{\sphinxupquote{3D int tuple}}, \sphinxstyleemphasis{optional}) \textendash{} Shape of the desired images when using ‘random\_crops\_in\_DA’.

\item {} 
\sphinxstylestrong{prob\_map} (\sphinxcode{\sphinxupquote{4D Numpy array}} or \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} If it is an array, it should represent the probability map used to make random crops when
\sphinxcode{\sphinxupquote{random\_crops\_in\_DA}} is set. If str given should be the path to read these maps from.

\item {} 
\sphinxstylestrong{val} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Advise the generator that the images will be to validate the model to not make random crops (as the val.
data must be the same on each epoch). Valid when \sphinxcode{\sphinxupquote{random\_crops\_in\_DA}} is set.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes. If \sphinxcode{\sphinxupquote{\textgreater{} 1}} one\sphinxhyphen{}hot encoding will be done on the ground truth.

\item {} 
\sphinxstylestrong{out\_number} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of output returned by the network. Used to produce same number of ground truth data on each batch.

\item {} 
\sphinxstylestrong{extra\_data\_factor} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Factor to multiply the batches yielded in a epoch. It acts as if \sphinxcode{\sphinxupquote{X}} and \sphinxcode{\sphinxupquote{Y\textasciigrave{}}} where concatenated
\sphinxcode{\sphinxupquote{extra\_data\_factor}} times.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Define train and val generators to make random rotations between 0 and}
\PYG{c+c1}{\PYGZsh{} 180 degrees. Notice that DA is disabled in val data}

\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1776}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1776}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{X\PYGZus{}val} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{204}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}val} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{204}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{data\PYGZus{}gen\PYGZus{}args} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{X}\PYG{o}{=}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{shuffle\PYGZus{}each\PYGZus{}epoch}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{rand\PYGZus{}rot}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{vflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
                     \PYG{n}{hflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{data\PYGZus{}gen\PYGZus{}val\PYGZus{}args} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{X}\PYG{o}{=}\PYG{n}{X\PYGZus{}val}\PYG{p}{,} \PYG{n}{Y}\PYG{o}{=}\PYG{n}{Y\PYGZus{}val}\PYG{p}{,} \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{shuffle\PYGZus{}each\PYGZus{}epoch}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{da}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{val}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{train\PYGZus{}generator} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{data\PYGZus{}gen\PYGZus{}args}\PYG{p}{)}
\PYG{n}{val\PYGZus{}generator} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{data\PYGZus{}gen\PYGZus{}val\PYGZus{}args}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} Generate random crops on DA\PYGZhy{}time. To allow that notice that the}
\PYG{c+c1}{\PYGZsh{} data in this case is bigger in width and height than example 1, to}
\PYG{c+c1}{\PYGZsh{} allow a (256, 256) random crop extraction}

\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{148}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{148}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{X\PYGZus{}val} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{17}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}val} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{17}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Create a prbobability map for each image. Here we define foreground}
\PYG{c+c1}{\PYGZsh{} probability much higher than the background simulating a class inbalance}
\PYG{c+c1}{\PYGZsh{} With this, the probability of take the center pixel of the random crop}
\PYG{c+c1}{\PYGZsh{} that corresponds to the foreground class will be so high}
\PYG{n}{prob\PYGZus{}map} \PYG{o}{=} \PYG{n}{calculate\PYGZus{}2D\PYGZus{}volume\PYGZus{}prob\PYGZus{}map}\PYG{p}{(}
     \PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{l+m+mf}{0.94}\PYG{p}{,} \PYG{l+m+mf}{0.06}\PYG{p}{,} \PYG{n}{save\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{prob\PYGZus{}map.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n}{data\PYGZus{}gen\PYGZus{}args} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{X}\PYG{o}{=}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{shuffle\PYGZus{}each\PYGZus{}epoch}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{rand\PYGZus{}rot}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{vflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
                     \PYG{n}{hflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{random\PYGZus{}crops\PYGZus{}in\PYGZus{}DA}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{prob\PYGZus{}map}\PYG{o}{=}\PYG{n}{prob\PYGZus{}map}\PYG{p}{)}

\PYG{n}{data\PYGZus{}gen\PYGZus{}val\PYGZus{}args} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{X}\PYG{o}{=}\PYG{n}{X\PYGZus{}val}\PYG{p}{,} \PYG{n}{Y}\PYG{o}{=}\PYG{n}{Y\PYGZus{}val}\PYG{p}{,} \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{random\PYGZus{}crops\PYGZus{}in\PYGZus{}DA}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
                         \PYG{n}{shuffle\PYGZus{}each\PYGZus{}epoch}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{da}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{val}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{train\PYGZus{}generator} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{data\PYGZus{}gen\PYGZus{}args}\PYG{p}{)}
\PYG{n}{val\PYGZus{}generator} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{data\PYGZus{}gen\PYGZus{}val\PYGZus{}args}\PYG{p}{)}
\end{sphinxVerbatim}
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

{\hyperref[\detokenize{data/generators/2d_generator:data.generators.data_2D_generator.ImageDataGenerator.apply_transform}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{apply\_transform}}}}}(image, mask{[}, e\_im, e\_mask{]})
&
Transform the input image and its mask at the same time with one of the selected choices based on a probability.
\\
\hline
{\hyperref[\detokenize{data/generators/2d_generator:data.generators.data_2D_generator.ImageDataGenerator.get_transformed_samples}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{get\_transformed\_samples}}}}}(num\_examples{[}, …{]})
&
Apply selected transformations to a defined number of images from the dataset.
\\
\hline
{\hyperref[\detokenize{data/generators/2d_generator:data.generators.data_2D_generator.ImageDataGenerator.on_epoch_end}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_epoch\_end}}}}}()
&
Updates indexes after each epoch.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}
\index{on\_epoch\_end() (data.generators.data\_2D\_generator.ImageDataGenerator method)@\spxentry{on\_epoch\_end()}\spxextra{data.generators.data\_2D\_generator.ImageDataGenerator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/2d_generator:data.generators.data_2D_generator.ImageDataGenerator.on_epoch_end}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_epoch\_end}}}{}{}
Updates indexes after each epoch.

\end{fulllineitems}

\index{apply\_transform() (data.generators.data\_2D\_generator.ImageDataGenerator method)@\spxentry{apply\_transform()}\spxextra{data.generators.data\_2D\_generator.ImageDataGenerator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/2d_generator:data.generators.data_2D_generator.ImageDataGenerator.apply_transform}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_transform}}}{\emph{\DUrole{n}{image}}, \emph{\DUrole{n}{mask}}, \emph{\DUrole{n}{e\_im}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{e\_mask}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Transform the input image and its mask at the same time with one of the selected choices based on a
probability.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Mask to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{e\_img} (\sphinxcode{\sphinxupquote{D Numpy array}}) \textendash{} Extra image to help transforming \sphinxcode{\sphinxupquote{image}}. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{e\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Extra mask to help transforming \sphinxcode{\sphinxupquote{mask}}. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{trans\_image} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{trans\_mask} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed image mask. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{get\_transformed\_samples() (data.generators.data\_2D\_generator.ImageDataGenerator method)@\spxentry{get\_transformed\_samples()}\spxextra{data.generators.data\_2D\_generator.ImageDataGenerator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/2d_generator:data.generators.data_2D_generator.ImageDataGenerator.get_transformed_samples}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_transformed\_samples}}}{\emph{\DUrole{n}{num\_examples}}, \emph{\DUrole{n}{save\_to\_dir}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{out\_dir}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}aug\textquotesingle{}}}, \emph{\DUrole{n}{save\_prefix}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{train}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{random\_images}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
Apply selected transformations to a defined number of images from the dataset.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{num\_examples} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of examples to generate.

\item {} 
\sphinxstylestrong{save\_to\_dir} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Save the images generated. The purpose of this variable is to check the images generated by data
augmentation.

\item {} 
\sphinxstylestrong{out\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Name of the folder where the examples will be stored. If any provided the examples will be generated
under a folder \sphinxcode{\sphinxupquote{aug}}.

\item {} 
\sphinxstylestrong{save\_prefix} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Prefix to add to the generated examples’ name.

\item {} 
\sphinxstylestrong{train} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To avoid drawing a grid on the generated images. This should be set when the samples will be used for
training.

\item {} 
\sphinxstylestrong{random\_images} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Randomly select images from the dataset. If \sphinxcode{\sphinxupquote{False}} the examples will be generated from the start of
the dataset.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{batch\_x} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Batch of data. E.g. \sphinxcode{\sphinxupquote{(num\_examples, x, y, channels)}}.

\item {} 
\sphinxstylestrong{batch\_y} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Batch of data mask. E.g. \sphinxcode{\sphinxupquote{(num\_examples, x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Generate 10 samples following with the example 1 of the class definition}
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1776}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Y\PYGZus{}train} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1776}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{data\PYGZus{}gen\PYGZus{}args} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{X}\PYG{o}{=}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{shuffle\PYGZus{}each\PYGZus{}epoch}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
                     \PYG{n}{rotation\PYGZus{}range}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{vflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{train\PYGZus{}generator} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{data\PYGZus{}gen\PYGZus{}args}\PYG{p}{)}

\PYG{n}{train\PYGZus{}generator}\PYG{o}{.}\PYG{n}{get\PYGZus{}transformed\PYGZus{}samples}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{save\PYGZus{}to\PYGZus{}dir}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{train}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{out\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{da\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} If random crop in DA\PYGZhy{}time is choosen, as the example 2 of the class definition, the call should be the}
\PYG{c+c1}{\PYGZsh{} same but two more images will be stored: img and mask representing the random crop extracted. There a}
\PYG{c+c1}{\PYGZsh{} red point is painted representing the pixel choosen to be the center of the random crop and a blue}
\PYG{c+c1}{\PYGZsh{} square which delimits crop boundaries}

\PYG{n}{prob\PYGZus{}map} \PYG{o}{=} \PYG{n}{calculate\PYGZus{}2D\PYGZus{}volume\PYGZus{}prob\PYGZus{}map}\PYG{p}{(}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{l+m+mf}{0.94}\PYG{p}{,} \PYG{l+m+mf}{0.06}\PYG{p}{,} \PYG{n}{save\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{prob\PYGZus{}map.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n}{data\PYGZus{}gen\PYGZus{}args} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{X}\PYG{o}{=}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{Y}\PYG{o}{=}\PYG{n}{Y\PYGZus{}train}\PYG{p}{,} \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{shuffle\PYGZus{}each\PYGZus{}epoch}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
                     \PYG{n}{rotation\PYGZus{}range}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{vflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hflip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{random\PYGZus{}crops\PYGZus{}in\PYGZus{}DA}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{prob\PYGZus{}map}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
                     \PYG{n}{prob\PYGZus{}map}\PYG{o}{=}\PYG{n}{prob\PYGZus{}map}\PYG{p}{)}
\PYG{n}{train\PYGZus{}generator} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{data\PYGZus{}gen\PYGZus{}args}\PYG{p}{)}

\PYG{n}{train\PYGZus{}generator}\PYG{o}{.}\PYG{n}{get\PYGZus{}transformed\PYGZus{}samples}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{save\PYGZus{}to\PYGZus{}dir}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{train}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{out\PYGZus{}dir}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{da\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

Example 2 will store two additional images as the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{rd_crop_2d}.png}
\sphinxfigcaption{Original crop}\label{\detokenize{data/generators/2d_generator:id1}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{rd_crop_mask_2d}.png}
\sphinxfigcaption{Original crop mask}\label{\detokenize{data/generators/2d_generator:id2}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Together with these images another pair of images will be stored: the crop made and a transformed version of
it, which is really the generator output.

For instance, setting \sphinxcode{\sphinxupquote{elastic=True}} the above extracted crop should be transformed as follows:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{original_crop_2d}.png}
\sphinxfigcaption{Original crop}\label{\detokenize{data/generators/2d_generator:id3}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{original_crop_mask_2d}.png}
\sphinxfigcaption{Original crop mask}\label{\detokenize{data/generators/2d_generator:id4}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{elastic_crop_2d}.png}
\sphinxfigcaption{Elastic transformation applied}\label{\detokenize{data/generators/2d_generator:id5}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{elastic_crop_mask_2d}.png}
\sphinxfigcaption{Elastic transformation applied}\label{\detokenize{data/generators/2d_generator:id6}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid is only painted if \sphinxcode{\sphinxupquote{train=False}} which should be used just to display transformations made.
Selecting random rotations between 0 and 180 degrees should generate the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{original_rd_rot_crop_2d}.png}
\sphinxfigcaption{Original crop}\label{\detokenize{data/generators/2d_generator:id7}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{original_rd_rot_crop_mask_2d}.png}
\sphinxfigcaption{Original crop mask}\label{\detokenize{data/generators/2d_generator:id8}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{rd_rot_crop_2d}.png}
\sphinxfigcaption{Random rotation {[}0, 180{]} applied}\label{\detokenize{data/generators/2d_generator:id9}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{rd_rot_crop_mask_2d}.png}
\sphinxfigcaption{Random rotation {[}0, 180{]} applied}\label{\detokenize{data/generators/2d_generator:id10}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\end{fulllineitems}


\end{fulllineitems}



\subsubsection{3D generator}
\label{\detokenize{data/generators/3d_generator:module-data.generators.data_3D_generator}}\label{\detokenize{data/generators/3d_generator:d-generator}}\label{\detokenize{data/generators/3d_generator::doc}}\index{module@\spxentry{module}!data.generators.data\_3D\_generator@\spxentry{data.generators.data\_3D\_generator}}\index{data.generators.data\_3D\_generator@\spxentry{data.generators.data\_3D\_generator}!module@\spxentry{module}}\index{VoxelDataGenerator (class in data.generators.data\_3D\_generator)@\spxentry{VoxelDataGenerator}\spxextra{class in data.generators.data\_3D\_generator}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/3d_generator:data.generators.data_3D_generator.VoxelDataGenerator}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{data.generators.data\_3D\_generator.}}\sphinxbfcode{\sphinxupquote{VoxelDataGenerator}}}{\emph{\DUrole{n}{X}}, \emph{\DUrole{n}{Y}}, \emph{\DUrole{n}{in\_memory}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{data\_paths}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{random\_crops\_in\_DA}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{shape}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{prob\_map}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{seed}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{shuffle\_each\_epoch}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{batch\_size}\DUrole{o}{=}\DUrole{default_value}{32}}, \emph{\DUrole{n}{da}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{da\_prob}\DUrole{o}{=}\DUrole{default_value}{0.5}}, \emph{\DUrole{n}{rotation90}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{rand\_rot}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{rnd\_rot\_range}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 180, 180}}, \emph{\DUrole{n}{shear}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{shear\_range}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 20, 20}}, \emph{\DUrole{n}{zoom}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{zoom\_range}\DUrole{o}{=}\DUrole{default_value}{0.8, 1.2}}, \emph{\DUrole{n}{shift}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{shift\_range}\DUrole{o}{=}\DUrole{default_value}{0.1, 0.2}}, \emph{\DUrole{n}{vflip}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{hflip}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{zflip}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{elastic}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{e\_alpha}\DUrole{o}{=}\DUrole{default_value}{240, 250}}, \emph{\DUrole{n}{e\_sigma}\DUrole{o}{=}\DUrole{default_value}{25}}, \emph{\DUrole{n}{e\_mode}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}constant\textquotesingle{}}}, \emph{\DUrole{n}{g\_blur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{g\_sigma}\DUrole{o}{=}\DUrole{default_value}{1.0, 2.0}}, \emph{\DUrole{n}{median\_blur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{mb\_kernel}\DUrole{o}{=}\DUrole{default_value}{3, 7}}, \emph{\DUrole{n}{motion\_blur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{motb\_k\_range}\DUrole{o}{=}\DUrole{default_value}{3, 8}}, \emph{\DUrole{n}{gamma\_contrast}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{gc\_gamma}\DUrole{o}{=}\DUrole{default_value}{1.25, 1.75}}, \emph{\DUrole{n}{brightness}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{brightness\_factor}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{contrast}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{contrast\_factor}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{drop\_range}\DUrole{o}{=}\DUrole{default_value}{0, 0.2}}, \emph{\DUrole{n}{cutout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cout\_nb\_iterations}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{cout\_size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{cout\_cval}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{cout\_apply\_to\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cutblur}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cblur\_size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{cblur\_down\_range}\DUrole{o}{=}\DUrole{default_value}{2, 8}}, \emph{\DUrole{n}{cblur\_inside}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{cutmix}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cmix\_size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{cutnoise}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cnoise\_scale}\DUrole{o}{=}\DUrole{default_value}{0.1, 0.2}}, \emph{\DUrole{n}{cnoise\_nb\_iterations}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{cnoise\_size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{misalignment}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{ms\_displacement}\DUrole{o}{=}\DUrole{default_value}{16}}, \emph{\DUrole{n}{ms\_rotate\_ratio}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{missing\_parts}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{missp\_iterations}\DUrole{o}{=}\DUrole{default_value}{30, 40}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{out\_number}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{val}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{extra\_data\_factor}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.utils.data\_utils.Sequence}}

Custom 3D ImageDataGenerator based on \sphinxhref{https://github.com/aleju/imgaug-doc}{imgaug} and our own
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/blob/master/generators/augmentors.py}{augmentors.py}
transformations.

Based on \sphinxhref{https://github.com/czbiohub/microDL}{microDL} and
\sphinxhref{https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly}{Shervine’s blog}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{Numpy 5D array}}) \textendash{} Data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{Y} (\sphinxcode{\sphinxupquote{Numpy 5D array}}) \textendash{} Mask data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{in\_memory} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{True}} data used will be \sphinxcode{\sphinxupquote{X}} and \sphinxcode{\sphinxupquote{Y}}. If \sphinxcode{\sphinxupquote{False}} it will be loaded directly from disk using
\sphinxcode{\sphinxupquote{data\_paths}}.

\item {} 
\sphinxstylestrong{data\_paths} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{in\_memory}} is \sphinxcode{\sphinxupquote{True}} this list should contain the paths to load data and masks. \sphinxcode{\sphinxupquote{data\_paths{[}0{]}}}
should be data path and \sphinxcode{\sphinxupquote{data\_paths{[}1{]}}} masks path.

\item {} 
\sphinxstylestrong{random\_crops\_in\_DA} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To extract random subvolumes from the given data. If not, the data must be 5D and is assumed that the
subvolumes are prepared.

\item {} 
\sphinxstylestrong{shape} (\sphinxcode{\sphinxupquote{4D tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Shape of the subvolume to be extracted randomly from the data. E. g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{prob\_map} (\sphinxcode{\sphinxupquote{5D Numpy array}} or \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} If it is an array, it should represent the probability map used to make random crops when
\sphinxcode{\sphinxupquote{random\_crops\_in\_DA}} is set. If \sphinxcode{\sphinxupquote{str}} is given it should be the path to read these maps from.

\item {} 
\sphinxstylestrong{seed} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Seed for random functions.

\item {} 
\sphinxstylestrong{shuffle\_each\_epoch} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To shuffle data after each epoch.

\item {} 
\sphinxstylestrong{batch\_size} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Size of the batches.

\item {} 
\sphinxstylestrong{da} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To activate the data augmentation.

\item {} 
\sphinxstylestrong{da\_prob} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Probability of doing each transformation.

\item {} 
\sphinxstylestrong{rotation90} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make square (90, 180,270) degree rotations.

\item {} 
\sphinxstylestrong{rand\_rot} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make random degree range rotations.

\item {} 
\sphinxstylestrong{rnd\_rot\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Range of random rotations. E. g. \sphinxcode{\sphinxupquote{(\sphinxhyphen{}180, 180)}}.

\item {} 
\sphinxstylestrong{shear} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make shear transformations.

\item {} 
\sphinxstylestrong{shear\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Degree range to make shear. E. g. \sphinxcode{\sphinxupquote{(\sphinxhyphen{}20, 20)}}.

\item {} 
\sphinxstylestrong{zoom} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make zoom on images.

\item {} 
\sphinxstylestrong{zoom\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Zoom range to apply. E. g. \sphinxcode{\sphinxupquote{(0.8, 1.2)}}.

\item {} 
\sphinxstylestrong{shift} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} To make shifts.

\item {} 
\sphinxstylestrong{shift\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Range to make a shift. E. g. \sphinxcode{\sphinxupquote{(0.1, 0.2)}}.

\item {} 
\sphinxstylestrong{vflip} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To activate vertical flips.

\item {} 
\sphinxstylestrong{hflip} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To activate horizontal flips.

\item {} 
\sphinxstylestrong{zflip} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To activate flips in z dimension.

\item {} 
\sphinxstylestrong{elastic} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To make elastic deformations.

\item {} 
\sphinxstylestrong{e\_alpha} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Strength of the distortion field. E. g. \sphinxcode{\sphinxupquote{(240, 250)}}.

\item {} 
\sphinxstylestrong{e\_sigma} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Standard deviation of the gaussian kernel used to smooth the distortion fields.

\item {} 
\sphinxstylestrong{e\_mode} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Parameter that defines the handling of newly created pixels with the elastic transformation.

\item {} 
\sphinxstylestrong{g\_blur} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To insert gaussian blur on the images.

\item {} 
\sphinxstylestrong{g\_sigma} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Standard deviation of the gaussian kernel. E. g. \sphinxcode{\sphinxupquote{(1.0, 2.0)}}.

\item {} 
\sphinxstylestrong{median\_blur} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To blur an image by computing median values over neighbourhoods.

\item {} 
\sphinxstylestrong{mb\_kernel} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Median blur kernel size. E. g. \sphinxcode{\sphinxupquote{(3, 7)}}.

\item {} 
\sphinxstylestrong{motion\_blur} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Blur images in a way that fakes camera or object movements.

\item {} 
\sphinxstylestrong{motb\_k\_range} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel size to use in motion blur.

\item {} 
\sphinxstylestrong{gamma\_contrast} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To insert gamma constrast changes on images.

\item {} 
\sphinxstylestrong{gc\_gamma} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Exponent for the contrast adjustment. Higher values darken the image. E. g. \sphinxcode{\sphinxupquote{(1.25, 1.75)}}.

\item {} 
\sphinxstylestrong{brightness} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To aply brightness to the images.

\item {} 
\sphinxstylestrong{brightness\_factor} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Strength of the brightness range, with valid values being \sphinxcode{\sphinxupquote{0 \textless{}= brightness\_factor \textless{}= 1}}. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.3)}}.

\item {} 
\sphinxstylestrong{contrast} (\sphinxcode{\sphinxupquote{boolen}}, \sphinxstyleemphasis{optional}) \textendash{} To apply contrast changes to the images.

\item {} 
\sphinxstylestrong{contrast\_factor} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Strength of the contrast change range, with valid values being \sphinxcode{\sphinxupquote{0 \textless{}= contrast\_factor \textless{}= 1}}.
E.g. \sphinxcode{\sphinxupquote{(0.1, 0.3)}}.

\item {} 
\sphinxstylestrong{dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To set a certain fraction of pixels in images to zero.

\item {} 
\sphinxstylestrong{drop\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to take a probability \sphinxcode{\sphinxupquote{p}} to drop pixels. E.g. \sphinxcode{\sphinxupquote{(0, 0.2)}} will take a \sphinxcode{\sphinxupquote{p}} folowing \sphinxcode{\sphinxupquote{0\textless{}=p\textless{}=0.2}}
and then drop \sphinxcode{\sphinxupquote{p}} percent of all pixels in the image (i.e. convert them to black pixels).

\item {} 
\sphinxstylestrong{cutout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To fill one or more rectangular areas in an image using a fill mode.

\item {} 
\sphinxstylestrong{cout\_nb\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Range of number of areas to fill the image with. E. g. \sphinxcode{\sphinxupquote{(1, 3)}}.

\item {} 
\sphinxstylestrong{cout\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to select the size of the areas in \% of the corresponding
image size. Values between \sphinxcode{\sphinxupquote{0}} and \sphinxcode{\sphinxupquote{1}}. E. g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{cout\_cval} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Value to fill the area of cutout with.

\item {} 
\sphinxstylestrong{cout\_apply\_to\_mask} (\sphinxcode{\sphinxupquote{boolen}}, \sphinxstyleemphasis{optional}) \textendash{} Wheter to apply cutout to the mask.

\item {} 
\sphinxstylestrong{cutblur} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Blur a rectangular area of the image by downsampling and upsampling it again.

\item {} 
\sphinxstylestrong{cblur\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to select the size of the area to apply cutblur on. E. g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{cblur\_inside} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{True}} only the region inside will be modified (cut LR into HR image). If \sphinxcode{\sphinxupquote{False}} the \sphinxcode{\sphinxupquote{50\%}} of the
times the region inside will be modified (cut LR into HR image) and the other \sphinxcode{\sphinxupquote{50\%}} the inverse will be
done (cut HR into LR image). See Figure 1 of the official \sphinxhref{https://arxiv.org/pdf/2004.00448.pdf}{paper}.

\item {} 
\sphinxstylestrong{cutmix} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Combine two images pasting a region of one image to another.

\item {} 
\sphinxstylestrong{cmix\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to select the size of the area to paste one image into another. E. g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{cnoise} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Randomly add noise to a cuboid region in the image.

\item {} 
\sphinxstylestrong{cnoise\_scale} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Scale of the random noise. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.2)}}.

\item {} 
\sphinxstylestrong{cnoise\_nb\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Number of areas with noise to create. E.g. \sphinxcode{\sphinxupquote{(1, 3)}}.

\item {} 
\sphinxstylestrong{cnoise\_size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to choose the size of the areas to transform. E.g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\item {} 
\sphinxstylestrong{misalignment} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} To add miss\sphinxhyphen{}aligment augmentation.

\item {} 
\sphinxstylestrong{ms\_displacement} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Maximum pixel displacement in \sphinxtitleref{xy}\sphinxhyphen{}plane for misalignment.

\item {} 
\sphinxstylestrong{ms\_rotate\_ratio} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Ratio of rotation\sphinxhyphen{}based mis\sphinxhyphen{}alignment

\item {} 
\sphinxstylestrong{missing\_parts} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Augment the image by creating a black line in a random position.

\item {} 
\sphinxstylestrong{missp\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 ints}}, \sphinxstyleemphasis{optional}) \textendash{} Iterations to dilate the missing line with. E.g. \sphinxcode{\sphinxupquote{(30, 40)}}.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes. If \sphinxcode{\sphinxupquote{\textgreater{} 1}} one\sphinxhyphen{}hot encoding will be done on the ground truth.

\item {} 
\sphinxstylestrong{out\_number} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of output returned by the network. Used to produce same number of ground truth data on each batch.

\item {} 
\sphinxstylestrong{val} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Advice the generator that the volumes will be used to validate the model to not make random crops (as the
validation data must be the same on each epoch). Valid when \sphinxcode{\sphinxupquote{random\_crops\_in\_DA}}
is set.

\item {} 
\sphinxstylestrong{extra\_data\_factor} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Factor to multiply the batches yielded in a epoch. It acts as if \sphinxcode{\sphinxupquote{X}} and \sphinxcode{\sphinxupquote{Y\textasciigrave{}}} where concatenated
\sphinxcode{\sphinxupquote{extra\_data\_factor}} times.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

{\hyperref[\detokenize{data/generators/3d_generator:data.generators.data_3D_generator.VoxelDataGenerator.apply_transform}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{apply\_transform}}}}}(image, mask{[}, e\_im, e\_mask{]})
&
Transform the input image and its mask at the same time with one of the selected choices based on a probability.
\\
\hline
{\hyperref[\detokenize{data/generators/3d_generator:data.generators.data_3D_generator.VoxelDataGenerator.get_transformed_samples}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{get\_transformed\_samples}}}}}(num\_examples{[}, …{]})
&
Apply selected transformations to a defined number of images from the dataset.
\\
\hline
{\hyperref[\detokenize{data/generators/3d_generator:data.generators.data_3D_generator.VoxelDataGenerator.on_epoch_end}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_epoch\_end}}}}}()
&
Updates indexes after each epoch.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}
\index{on\_epoch\_end() (data.generators.data\_3D\_generator.VoxelDataGenerator method)@\spxentry{on\_epoch\_end()}\spxextra{data.generators.data\_3D\_generator.VoxelDataGenerator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/3d_generator:data.generators.data_3D_generator.VoxelDataGenerator.on_epoch_end}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_epoch\_end}}}{}{}
Updates indexes after each epoch.

\end{fulllineitems}

\index{apply\_transform() (data.generators.data\_3D\_generator.VoxelDataGenerator method)@\spxentry{apply\_transform()}\spxextra{data.generators.data\_3D\_generator.VoxelDataGenerator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/3d_generator:data.generators.data_3D_generator.VoxelDataGenerator.apply_transform}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_transform}}}{\emph{\DUrole{n}{image}}, \emph{\DUrole{n}{mask}}, \emph{\DUrole{n}{e\_im}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{e\_mask}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Transform the input image and its mask at the same time with one of the selected choices based on a
probability.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Mask to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{e\_img} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Extra image to help transforming \sphinxcode{\sphinxupquote{image}}. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{e\_mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Extra mask to help transforming \sphinxcode{\sphinxupquote{mask}}. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{image} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Transformed image mask. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{get\_transformed\_samples() (data.generators.data\_3D\_generator.VoxelDataGenerator method)@\spxentry{get\_transformed\_samples()}\spxextra{data.generators.data\_3D\_generator.VoxelDataGenerator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/3d_generator:data.generators.data_3D_generator.VoxelDataGenerator.get_transformed_samples}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_transformed\_samples}}}{\emph{\DUrole{n}{num\_examples}}, \emph{\DUrole{n}{random\_images}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{save\_to\_dir}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{out\_dir}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}aug\_3d\textquotesingle{}}}, \emph{\DUrole{n}{train}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Apply selected transformations to a defined number of images from the dataset.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{num\_examples} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of examples to generate.

\item {} 
\sphinxstylestrong{random\_images} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Randomly select images from the dataset. If \sphinxcode{\sphinxupquote{False}} the examples will be generated from the start of
the dataset.

\item {} 
\sphinxstylestrong{save\_to\_dir} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Save the images generated. The purpose of this variable is to check the images generated by data
augmentation.

\item {} 
\sphinxstylestrong{out\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Name of the folder where the examples will be stored.

\item {} 
\sphinxstylestrong{train} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To avoid drawing a grid on the generated images. This should be set when the samples will be used for
training.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{sample\_x} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Transformed images. E.g. list of \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{sample\_y} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Transformed image mask. E.g. list of \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsubsection{Augmentors}
\label{\detokenize{data/generators/augmentors:module-data.generators.augmentors}}\label{\detokenize{data/generators/augmentors:augmentors}}\label{\detokenize{data/generators/augmentors::doc}}\index{module@\spxentry{module}!data.generators.augmentors@\spxentry{data.generators.augmentors}}\index{data.generators.augmentors@\spxentry{data.generators.augmentors}!module@\spxentry{module}}\index{cutout() (in module data.generators.augmentors)@\spxentry{cutout()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.cutout}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{cutout}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{mask}}, \emph{\DUrole{n}{nb\_iterations}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{cval}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{apply\_to\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Cutout data augmentation presented in \sphinxhref{https://arxiv.org/pdf/1708.04552.pdf}{Improved Regularization of Convolutional Neural Networks with Cutout}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Mask to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{nb\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Number of areas to fill the image with. E.g. \sphinxcode{\sphinxupquote{(1, 3)}}.

\item {} 
\sphinxstylestrong{size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to choose the size of the areas to create.

\item {} 
\sphinxstylestrong{cval} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Value to fill the area with.

\item {} 
\sphinxstylestrong{apply\_to\_mask} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} To apply cutout to the mask.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{out} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed mask. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{nb\_iterations=(1,3)}}, \sphinxcode{\sphinxupquote{size=(0.05,0.3)}},
\sphinxcode{\sphinxupquote{apply\_to\_mask=False}} may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutout}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id2}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutout_mask}.png}
\sphinxfigcaption{Corresponding mask}\label{\detokenize{data/generators/augmentors:id3}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutout}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id4}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutout_mask}.png}
\sphinxfigcaption{Augmented mask}\label{\detokenize{data/generators/augmentors:id5}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid is painted for visualization purposes.

\end{fulllineitems}

\index{cutblur() (in module data.generators.augmentors)@\spxentry{cutblur()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.cutblur}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{cutblur}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}, \emph{\DUrole{n}{down\_ratio\_range}\DUrole{o}{=}\DUrole{default_value}{2, 8}}, \emph{\DUrole{n}{only\_inside}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
CutBlur data augmentation introduced in \sphinxhref{https://arxiv.org/pdf/2004.00448.pdf}{Rethinking Data Augmentation for Image Super\sphinxhyphen{}resolution: A Comprehensive
Analysis and a New Strategy} and adapted from
\sphinxurl{https://github.com/clovaai/cutblur} .
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{size} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Size of the region to transform.

\item {} 
\sphinxstylestrong{down\_ratio\_range} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Downsampling ratio range to be applied. E.g. \sphinxcode{\sphinxupquote{(2, 8)}}.

\item {} 
\sphinxstylestrong{only\_inside} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{True}} only the region inside will be modified (cut LR into HR image). If \sphinxcode{\sphinxupquote{False}} the \sphinxcode{\sphinxupquote{50\%}} of the
times the region inside will be modified (cut LR into HR image) and the other \sphinxcode{\sphinxupquote{50\%}} the inverse will be
done (cut HR into LR image). See Figure 1 of the official \sphinxhref{https://arxiv.org/pdf/2004.00448.pdf}{paper}.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{3D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{size=(0.2,0.4)}}, \sphinxcode{\sphinxupquote{down\_ratio\_range=(2,8)}},
\sphinxcode{\sphinxupquote{only\_inside=True}} may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutblur}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id6}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutblur}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id7}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutblur2}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id8}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutblur2}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id9}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid and the red square are painted for visualization purposes.

\end{fulllineitems}

\index{cutmix() (in module data.generators.augmentors)@\spxentry{cutmix()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.cutmix}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{cutmix}}}{\emph{\DUrole{n}{im1}}, \emph{\DUrole{n}{im2}}, \emph{\DUrole{n}{mask1}}, \emph{\DUrole{n}{mask2}}, \emph{\DUrole{n}{size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}}{}
Cutmix augmentation introduced in \sphinxhref{https://arxiv.org/abs/1905.04899}{CutMix: Regularization Strategy to Train Strong Classifiers with Localizable
Features}. With this augmentation a region of the image sample is filled
with a given second image. This implementation is used for semantic segmentation so the masks of the images are
also needed. It assumes that the images are of the same shape.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{im1} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{im2} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to paste into the region of \sphinxcode{\sphinxupquote{im1}}. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask1} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Mask to transform (belongs to \sphinxcode{\sphinxupquote{im1}}). E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask2} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Mask to paste into the region of \sphinxcode{\sphinxupquote{mask1}}. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{size} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range to choose the size of the areas to transform. E.g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{out} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{m\_out} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed mask. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{size=(0.2,0.4)}} may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutmix}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id10}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutmix_mask}.png}
\sphinxfigcaption{Corresponding mask}\label{\detokenize{data/generators/augmentors:id11}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutmix}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id12}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutmix_mask}.png}
\sphinxfigcaption{Augmented mask}\label{\detokenize{data/generators/augmentors:id13}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid is painted for visualization purposes.

\end{fulllineitems}

\index{cutnoise() (in module data.generators.augmentors)@\spxentry{cutnoise()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.cutnoise}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{cutnoise}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{scale}\DUrole{o}{=}\DUrole{default_value}{0.1, 0.2}}, \emph{\DUrole{n}{nb\_iterations}\DUrole{o}{=}\DUrole{default_value}{1, 3}}, \emph{\DUrole{n}{size}\DUrole{o}{=}\DUrole{default_value}{0.2, 0.4}}}{}
Cutnoise data augmentation. Randomly add noise to a cuboid region in the image to force the model to learn
denoising when making predictions.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{scale} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Scale of the random noise. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.2)}}.

\item {} 
\sphinxstylestrong{nb\_iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Number of areas with noise to create. E.g. \sphinxcode{\sphinxupquote{(1, 3)}}.

\item {} 
\sphinxstylestrong{size} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Range to choose the size of the areas to transform. E.g. \sphinxcode{\sphinxupquote{(0.2, 0.4)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{3D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{scale=(0.1,0.2)}}, \sphinxcode{\sphinxupquote{nb\_iterations=(1,3)}} and
\sphinxcode{\sphinxupquote{size=(0.2,0.4)}} may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutnoise}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id14}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutnoise}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id15}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_cutnoise2}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id16}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{cutnoise2}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id17}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid and the red squares are painted for visualization purposes.

\end{fulllineitems}

\index{misalignment() (in module data.generators.augmentors)@\spxentry{misalignment()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.misalignment}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{misalignment}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{mask}}, \emph{\DUrole{n}{displacement}\DUrole{o}{=}\DUrole{default_value}{16}}, \emph{\DUrole{n}{rotate\_ratio}\DUrole{o}{=}\DUrole{default_value}{0.0}}}{}
Mis\sphinxhyphen{}alignment data augmentation of image stacks. This augmentation is applied to both images and masks.

Implementation based on \sphinxhref{https://github.com/zudi-lin/pytorch\_connectomics/blob/master/connectomics/data/augmentation/misalign.py}{PyTorch Connectomics’ misalign.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Mask to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}

\item {} 
\sphinxstylestrong{displacement} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Maximum pixel displacement in \sphinxcode{\sphinxupquote{xy}}\sphinxhyphen{}plane.

\item {} 
\sphinxstylestrong{rotate\_ratio} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Ratio of rotation\sphinxhyphen{}based mis\sphinxhyphen{}alignment.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{out} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{m\_out} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Transformed mask. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{displacement=16}} and \sphinxcode{\sphinxupquote{rotate\_ratio=0.5}} may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_miss}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id18}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_miss_mask}.png}
\sphinxfigcaption{Corresponding mask}\label{\detokenize{data/generators/augmentors:id19}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{miss}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id20}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{miss_mask}.png}
\sphinxfigcaption{Augmented mask}\label{\detokenize{data/generators/augmentors:id21}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid is painted for visualization purposes.

\end{fulllineitems}

\index{random\_rotate\_matrix() (in module data.generators.augmentors)@\spxentry{random\_rotate\_matrix()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.random_rotate_matrix}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{random\_rotate\_matrix}}}{\emph{\DUrole{n}{height}}, \emph{\DUrole{n}{displacement}}}{}
Auxiliary function for missaligmnet.

\end{fulllineitems}

\index{brightness() (in module data.generators.augmentors)@\spxentry{brightness()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.brightness}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{brightness}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{brightness\_factor}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{mode}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}mix\textquotesingle{}}}, \emph{\DUrole{n}{invert}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{invert\_p}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
Grayscale intensity augmentation. Randomly adjust contrast/brightness, randomly invert the color space and apply
gamma correction. The input image will be divided by \sphinxcode{\sphinxupquote{255}}.

Implementation based on \sphinxhref{https://github.com/zudi-lin/pytorch\_connectomics/blob/master/connectomics/data/augmentation/grayscale.py}{PyTorch Connectomics’ grayscale.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{brightness\_factor} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range of brightness’ intensity. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.3)}}.

\item {} 
\sphinxstylestrong{mode} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} One of \sphinxcode{\sphinxupquote{2D}}, \sphinxcode{\sphinxupquote{3D}} or \sphinxcode{\sphinxupquote{mix}}.

\item {} 
\sphinxstylestrong{invert} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Whether to invert the images.

\item {} 
\sphinxstylestrong{invert\_p} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Probability of inverting the images.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{image} \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{3D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{brightness\_factor=(0.1,0.3)}}, \sphinxcode{\sphinxupquote{mode=\textquotesingle{}mix\textquotesingle{}}}, \sphinxcode{\sphinxupquote{invert=False}} and \sphinxcode{\sphinxupquote{invert\_p=0}}
may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_bright}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id22}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{bright}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id23}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_bright2}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id24}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{bright2}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id25}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid is painted for visualization purposes.

\end{fulllineitems}

\index{contrast() (in module data.generators.augmentors)@\spxentry{contrast()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.contrast}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{contrast}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{contrast\_factor}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{mode}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}mix\textquotesingle{}}}, \emph{\DUrole{n}{invert}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{invert\_p}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
Contrast augmentation. Randomly invert the color space and apply gamma correction. The input image will be
divided by \sphinxcode{\sphinxupquote{255}}.

Implementation based on \sphinxhref{https://github.com/zudi-lin/pytorch\_connectomics/blob/master/connectomics/data/augmentation/grayscale.py}{PyTorch Connectomics’ grayscale.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{contrast\_factor} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Range of contrast’s intensity. E.g. \sphinxcode{\sphinxupquote{(0.1, 0.3)}}.

\item {} 
\sphinxstylestrong{mode} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} One of \sphinxcode{\sphinxupquote{2D}}, \sphinxcode{\sphinxupquote{3D}} or \sphinxcode{\sphinxupquote{mix}}.

\item {} 
\sphinxstylestrong{invert} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Whether to invert the image.

\item {} 
\sphinxstylestrong{invert\_p} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Probability of inverting the image.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{image} \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{3D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{contrast\_factor=(0.1,0.3)}}, \sphinxcode{\sphinxupquote{mode=\textquotesingle{}mix\textquotesingle{}}}, \sphinxcode{\sphinxupquote{invert=False}} and \sphinxcode{\sphinxupquote{invert\_p=0}}
may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_contrast}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id26}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{contrast}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id27}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_contrast2}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id28}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{contrast2}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id29}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid is painted for visualization purposes.

\end{fulllineitems}

\index{missing\_parts() (in module data.generators.augmentors)@\spxentry{missing\_parts()}\spxextra{in module data.generators.augmentors}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/augmentors:data.generators.augmentors.missing_parts}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.generators.augmentors.}}\sphinxbfcode{\sphinxupquote{missing\_parts}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{iterations}\DUrole{o}{=}\DUrole{default_value}{30, 40}}}{}
Augment the image by creating a black line in a random position.

Implementation based on \sphinxhref{https://github.com/zudi-lin/pytorch\_connectomics/blob/master/connectomics/data/augmentation/missing\_parts.py}{PyTorch Connectomics’ missing\_parts.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Image to transform. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{iterations} (\sphinxcode{\sphinxupquote{tuple}} of \sphinxcode{\sphinxupquote{2 ints}}, \sphinxstyleemphasis{optional}) \textendash{} Iterations to dilate the missing line with. E.g. \sphinxcode{\sphinxupquote{(30, 40)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Transformed image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{3D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with \sphinxcode{\sphinxupquote{iterations=(30,40)}} may result in:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_missing}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id30}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{missing}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id31}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{orig_missing2}.png}
\sphinxfigcaption{Input image}\label{\detokenize{data/generators/augmentors:id32}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{missing2}.png}
\sphinxfigcaption{Augmented image}\label{\detokenize{data/generators/augmentors:id33}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The grid is painted for visualization purposes.

\end{fulllineitems}



\subsubsection{Simple generator}
\label{\detokenize{data/generators/simple_generator:module-data.generators.simple_data_generators}}\label{\detokenize{data/generators/simple_generator:simple-generator}}\label{\detokenize{data/generators/simple_generator::doc}}\index{module@\spxentry{module}!data.generators.simple\_data\_generators@\spxentry{data.generators.simple\_data\_generators}}\index{data.generators.simple\_data\_generators@\spxentry{data.generators.simple\_data\_generators}!module@\spxentry{module}}\index{simple\_3D\_data\_generator (class in data.generators.simple\_data\_generators)@\spxentry{simple\_3D\_data\_generator}\spxextra{class in data.generators.simple\_data\_generators}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/simple_generator:data.generators.simple_data_generators.simple_3D_data_generator}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{data.generators.simple\_data\_generators.}}\sphinxbfcode{\sphinxupquote{simple\_3D\_data\_generator}}}{\emph{\DUrole{n}{X}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{d\_path}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{batch\_size}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{seed}\DUrole{o}{=}\DUrole{default_value}{42}}, \emph{\DUrole{n}{shuffle\_each\_epoch}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.utils.data\_utils.Sequence}}

3D ImageDataGenerator.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{d\_path} (\sphinxcode{\sphinxupquote{Str}}) \textendash{} Path to load the data from.

\item {} 
\sphinxstylestrong{seed} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Seed for random functions.

\item {} 
\sphinxstylestrong{batch\_size} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Size of the batches.

\item {} 
\sphinxstylestrong{shuffle\_each\_epoch} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To shuffle data after each epoch.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

{\hyperref[\detokenize{data/generators/simple_generator:data.generators.simple_data_generators.simple_3D_data_generator.on_epoch_end}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_epoch\_end}}}}}()
&
Updates indexes after each epoch.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}
\index{on\_epoch\_end() (data.generators.simple\_data\_generators.simple\_3D\_data\_generator method)@\spxentry{on\_epoch\_end()}\spxextra{data.generators.simple\_data\_generators.simple\_3D\_data\_generator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/generators/simple_generator:data.generators.simple_data_generators.simple_3D_data_generator.on_epoch_end}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_epoch\_end}}}{}{}
Updates indexes after each epoch.

\end{fulllineitems}


\end{fulllineitems}



\subsection{post\_processing}
\label{\detokenize{data/post_processing/main_post_proc:post-processing}}\label{\detokenize{data/post_processing/main_post_proc::doc}}

\subsubsection{Init}
\label{\detokenize{data/post_processing/init:module-data.post_processing}}\label{\detokenize{data/post_processing/init:init}}\label{\detokenize{data/post_processing/init::doc}}\index{module@\spxentry{module}!data.post\_processing@\spxentry{data.post\_processing}}\index{data.post\_processing@\spxentry{data.post\_processing}!module@\spxentry{module}}\index{apply\_post\_processing() (in module data.post\_processing)@\spxentry{apply\_post\_processing()}\spxextra{in module data.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/init:data.post_processing.apply_post_processing}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.}}\sphinxbfcode{\sphinxupquote{apply\_post\_processing}}}{\emph{\DUrole{n}{cfg}}, \emph{\DUrole{n}{data}}, \emph{\DUrole{n}{Y}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Create training and validation generators.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to apply post\_proccessing. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y} (\sphinxcode{\sphinxupquote{4D Numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Data GT to calculate the metrics. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{iou\_post} (\sphinxcode{\sphinxupquote{float}}) \textendash{} Foreground IoU of \sphinxcode{\sphinxupquote{data}} compared with \sphinxcode{\sphinxupquote{Y}} after post\sphinxhyphen{}processing.

\item {} 
\sphinxstylestrong{ov\_iou\_post} (\sphinxcode{\sphinxupquote{float}}) \textendash{} Overall IoU of \sphinxcode{\sphinxupquote{data}} compared with \sphinxcode{\sphinxupquote{Y}} after post\sphinxhyphen{}processing.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{Post processing}
\label{\detokenize{data/post_processing/post_processing:module-data.post_processing.post_processing}}\label{\detokenize{data/post_processing/post_processing:post-processing}}\label{\detokenize{data/post_processing/post_processing::doc}}\index{module@\spxentry{module}!data.post\_processing.post\_processing@\spxentry{data.post\_processing.post\_processing}}\index{data.post\_processing.post\_processing@\spxentry{data.post\_processing.post\_processing}!module@\spxentry{module}}\index{boundary\_refinement\_watershed() (in module data.post\_processing.post\_processing)@\spxentry{boundary\_refinement\_watershed()}\spxextra{in module data.post\_processing.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/post_processing:data.post_processing.post_processing.boundary_refinement_watershed}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.post\_processing.}}\sphinxbfcode{\sphinxupquote{boundary\_refinement\_watershed}}}{\emph{\DUrole{n}{X}}, \emph{\DUrole{n}{Y\_pred}}, \emph{\DUrole{n}{erode}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{save\_marks\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Apply watershed to the given predictions with the goal of refine the boundaries of the artifacts.

Based on \sphinxurl{https://docs.opencv.org/master/d3/db4/tutorial\_py\_watershed.html}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Original data to guide the watershed. E.g. \sphinxcode{\sphinxupquote{(img\_number, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y\_pred} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Predicted data to refine the boundaries. E.g. \sphinxcode{\sphinxupquote{(img\_number, x, y, channels)}}.

\item {} 
\sphinxstylestrong{erode} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To extract the sure foreground eroding the artifacts instead of doing with distanceTransform.

\item {} 
\sphinxstylestrong{save\_marks\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Directory to save the markers used to make the watershed. Useful for debugging.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{Array} \textendash{} Refined boundaries of the predictions. E.g. \sphinxcode{\sphinxupquote{(img\_number, x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{4D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Examples}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{FIBSEM_test_0}.png}
\sphinxfigcaption{Original image}\label{\detokenize{data/post_processing/post_processing:id2}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{FIBSEM_test_0_gt}.png}
\sphinxfigcaption{Ground truth}\label{\detokenize{data/post_processing/post_processing:id3}}\end{sphinxfigure-in-table}\relax
\\
\hline\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{FIBSEM_test_0_pred}.png}
\sphinxfigcaption{Predicted image}\label{\detokenize{data/post_processing/post_processing:id4}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{FIBSEM_test_0_wa}.png}
\sphinxfigcaption{Watershed ouput}\label{\detokenize{data/post_processing/post_processing:id5}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The marks used to guide the watershed is this example are these:
\begin{quote}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.700\linewidth]{{watershed2_marks_test0}.png}\hspace*{\fill}}
\end{quote}

\end{fulllineitems}

\index{boundary\_refinement\_watershed2() (in module data.post\_processing.post\_processing)@\spxentry{boundary\_refinement\_watershed2()}\spxextra{in module data.post\_processing.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/post_processing:data.post_processing.post_processing.boundary_refinement_watershed2}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.post\_processing.}}\sphinxbfcode{\sphinxupquote{boundary\_refinement\_watershed2}}}{\emph{\DUrole{n}{X}}, \emph{\DUrole{n}{Y\_pred}}, \emph{\DUrole{n}{save\_marks\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Apply watershed to the given predictions with the goal of refine the boundaries of the artifacts. This function
was implemented using scikit instead of opencv as \sphinxcode{\sphinxupquote{post\_processing.boundary\_refinement\_watershed()}}.

Based on \sphinxurl{https://scikit-image.org/docs/dev/auto\_examples/segmentation/plot\_watershed.html}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Original data to guide the watershed. E.g. \sphinxcode{\sphinxupquote{(img\_number, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y\_pred} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Predicted data to refine the boundaries. E.g. \sphinxcode{\sphinxupquote{(img\_number, x, y, channels)}}.

\item {} 
\sphinxstylestrong{save\_marks\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Directory to save the markers used to make the watershed. Useful for debugging.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{Array} \textendash{} Refined boundaries of the predictions. E.g. \sphinxcode{\sphinxupquote{(img\_number, x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{4D Numpy array}}

\end{description}\end{quote}

\end{fulllineitems}

\index{bc\_watershed() (in module data.post\_processing.post\_processing)@\spxentry{bc\_watershed()}\spxextra{in module data.post\_processing.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/post_processing:data.post_processing.post_processing.bc_watershed}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.post\_processing.}}\sphinxbfcode{\sphinxupquote{bc\_watershed}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{thres1}\DUrole{o}{=}\DUrole{default_value}{0.9}}, \emph{\DUrole{n}{thres2}\DUrole{o}{=}\DUrole{default_value}{0.8}}, \emph{\DUrole{n}{thres3}\DUrole{o}{=}\DUrole{default_value}{0.85}}, \emph{\DUrole{n}{thres\_small}\DUrole{o}{=}\DUrole{default_value}{128}}, \emph{\DUrole{n}{save\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Convert binary foreground probability maps and instance contours to instance masks via watershed segmentation
algorithm.

Implementation based on \sphinxhref{https://github.com/zudi-lin/pytorch\_connectomics/blob/master/connectomics/utils/process.py}{PyTorch Connectomics’ process.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Binary foreground labels and contours data to apply watershed into. E.g. \sphinxcode{\sphinxupquote{(397, 1450, 2000, 2)}}.

\item {} 
\sphinxstylestrong{thres1} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the semantic mask to create watershed seeds.

\item {} 
\sphinxstylestrong{thres2} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the contours to create watershed seeds.

\item {} 
\sphinxstylestrong{thres3} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the semantic mask to create the foreground mask.

\item {} 
\sphinxstylestrong{thres\_small} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Theshold to remove small objects created by the watershed.

\item {} 
\sphinxstylestrong{save\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Directory to save watershed output into.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{bcd\_watershed() (in module data.post\_processing.post\_processing)@\spxentry{bcd\_watershed()}\spxextra{in module data.post\_processing.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/post_processing:data.post_processing.post_processing.bcd_watershed}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.post\_processing.}}\sphinxbfcode{\sphinxupquote{bcd\_watershed}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{thres1}\DUrole{o}{=}\DUrole{default_value}{0.9}}, \emph{\DUrole{n}{thres2}\DUrole{o}{=}\DUrole{default_value}{0.8}}, \emph{\DUrole{n}{thres3}\DUrole{o}{=}\DUrole{default_value}{0.85}}, \emph{\DUrole{n}{thres4}\DUrole{o}{=}\DUrole{default_value}{0.5}}, \emph{\DUrole{n}{thres5}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{thres\_small}\DUrole{o}{=}\DUrole{default_value}{128}}, \emph{\DUrole{n}{save\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Convert binary foreground probability maps, instance contours to instance masks via watershed segmentation
algorithm.

Implementation based on \sphinxhref{https://github.com/zudi-lin/pytorch\_connectomics/blob/master/connectomics/utils/process.py}{PyTorch Connectomics’ process.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Binary foreground labels and contours data to apply watershed into. E.g. \sphinxcode{\sphinxupquote{(397, 1450, 2000, 2)}}.

\item {} 
\sphinxstylestrong{thres1} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the semantic mask to create watershed seeds.

\item {} 
\sphinxstylestrong{thres2} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the contours to create watershed seeds.

\item {} 
\sphinxstylestrong{thres3} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the semantic mask to create the foreground mask.

\item {} 
\sphinxstylestrong{thres4} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the distances to create watershed seeds.

\item {} 
\sphinxstylestrong{thres5} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold used in the distances to create the foreground mask.

\item {} 
\sphinxstylestrong{thres\_small} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Theshold to remove small objects created by the watershed.

\item {} 
\sphinxstylestrong{save\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Directory to save watershed output into.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{calculate\_z\_filtering() (in module data.post\_processing.post\_processing)@\spxentry{calculate\_z\_filtering()}\spxextra{in module data.post\_processing.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/post_processing:data.post_processing.post_processing.calculate_z_filtering}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.post\_processing.}}\sphinxbfcode{\sphinxupquote{calculate\_z\_filtering}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{mf\_size}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
Applies a median filtering in the z dimension of the provided data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to apply the filter to. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{mf\_size} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Size of the median filter. Must be an odd number.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{Array} \textendash{} Z filtered data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{4D Numpy array}}

\end{description}\end{quote}

\end{fulllineitems}

\index{ensemble8\_2d\_predictions() (in module data.post\_processing.post\_processing)@\spxentry{ensemble8\_2d\_predictions()}\spxextra{in module data.post\_processing.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/post_processing:data.post_processing.post_processing.ensemble8_2d_predictions}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.post\_processing.}}\sphinxbfcode{\sphinxupquote{ensemble8\_2d\_predictions}}}{\emph{\DUrole{n}{o\_img}}, \emph{\DUrole{n}{pred\_func}}, \emph{\DUrole{n}{batch\_size\_value}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Outputs the mean prediction of a given image generating its 8 possible rotations and flips.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{o\_img} (\sphinxcode{\sphinxupquote{3D Numpy array}}) \textendash{} Input image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{pred\_func} (\sphinxcode{\sphinxupquote{function}}) \textendash{} Function to make predictions.

\item {} 
\sphinxstylestrong{batch\_size\_value} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Batch size value.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Output image ensembled. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{3D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Apply ensemble to each image of X\PYGZus{}test}
\PYG{n}{X\PYGZus{}test} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{out\PYGZus{}X\PYGZus{}test} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{,} \PYG{n}{dtype}\PYG{o}{=}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{tqdm}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{pred\PYGZus{}ensembled} \PYG{o}{=} \PYG{n}{ensemble8\PYGZus{}2d\PYGZus{}predictions}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,}
        \PYG{n}{pred\PYGZus{}func}\PYG{o}{=}\PYG{p}{(}\PYG{k}{lambda} \PYG{n}{img\PYGZus{}batch\PYGZus{}subdiv}\PYG{p}{:} \PYG{n}{model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img\PYGZus{}batch\PYGZus{}subdiv}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{n\PYGZus{}classes}\PYG{o}{=}\PYG{n}{n\PYGZus{}classes}\PYG{p}{)}
    \PYG{n}{out\PYGZus{}X\PYGZus{}test}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{pred\PYGZus{}ensembled}

\PYG{c+c1}{\PYGZsh{} Notice that here pred\PYGZus{}func is created based on model.predict function of Keras}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{ensemble16\_3d\_predictions() (in module data.post\_processing.post\_processing)@\spxentry{ensemble16\_3d\_predictions()}\spxextra{in module data.post\_processing.post\_processing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/post_processing:data.post_processing.post_processing.ensemble16_3d_predictions}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.post\_processing.}}\sphinxbfcode{\sphinxupquote{ensemble16\_3d\_predictions}}}{\emph{\DUrole{n}{vol}}, \emph{\DUrole{n}{pred\_func}}, \emph{\DUrole{n}{batch\_size\_value}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Outputs the mean prediction of a given image generating its 16 possible rotations and flips.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{o\_img} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Input image. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{pred\_func} (\sphinxcode{\sphinxupquote{function}}) \textendash{} Function to make predictions.

\item {} 
\sphinxstylestrong{batch\_size\_value} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Batch size value.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Output image ensembled. E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{4D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Apply ensemble to each image of X\PYGZus{}test}
\PYG{n}{X\PYGZus{}test} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{165}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{out\PYGZus{}X\PYGZus{}test} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{,} \PYG{n}{dtype}\PYG{o}{=}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{tqdm}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{pred\PYGZus{}ensembled} \PYG{o}{=} \PYG{n}{ensemble8\PYGZus{}2d\PYGZus{}predictions}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,}
        \PYG{n}{pred\PYGZus{}func}\PYG{o}{=}\PYG{p}{(}\PYG{k}{lambda} \PYG{n}{img\PYGZus{}batch\PYGZus{}subdiv}\PYG{p}{:} \PYG{n}{model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img\PYGZus{}batch\PYGZus{}subdiv}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{n\PYGZus{}classes}\PYG{o}{=}\PYG{n}{n\PYGZus{}classes}\PYG{p}{)}
    \PYG{n}{out\PYGZus{}X\PYGZus{}test}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{pred\PYGZus{}ensembled}

\PYG{c+c1}{\PYGZsh{} Notice that here pred\PYGZus{}func is created based on model.predict function of Keras}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsubsection{Smooth tiled predictions}
\label{\detokenize{data/post_processing/smooth_tiled_predictions:module-data.post_processing.smooth_tiled_predictions}}\label{\detokenize{data/post_processing/smooth_tiled_predictions:smooth-tiled-predictions}}\label{\detokenize{data/post_processing/smooth_tiled_predictions::doc}}\index{module@\spxentry{module}!data.post\_processing.smooth\_tiled\_predictions@\spxentry{data.post\_processing.smooth\_tiled\_predictions}}\index{data.post\_processing.smooth\_tiled\_predictions@\spxentry{data.post\_processing.smooth\_tiled\_predictions}!module@\spxentry{module}}
Do smooth predictions on an image from tiled prediction patches.
\index{create\_gen() (in module data.post\_processing.smooth\_tiled\_predictions)@\spxentry{create\_gen()}\spxextra{in module data.post\_processing.smooth\_tiled\_predictions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/smooth_tiled_predictions:data.post_processing.smooth_tiled_predictions.create_gen}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.smooth\_tiled\_predictions.}}\sphinxbfcode{\sphinxupquote{create\_gen}}}{\emph{\DUrole{n}{subdivs}}, \emph{\DUrole{n}{subdivs\_m}}, \emph{\DUrole{n}{subdivs\_w}}}{}~
\end{fulllineitems}

\index{predict\_img\_with\_smooth\_windowing() (in module data.post\_processing.smooth\_tiled\_predictions)@\spxentry{predict\_img\_with\_smooth\_windowing()}\spxextra{in module data.post\_processing.smooth\_tiled\_predictions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/smooth_tiled_predictions:data.post_processing.smooth_tiled_predictions.predict_img_with_smooth_windowing}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.smooth\_tiled\_predictions.}}\sphinxbfcode{\sphinxupquote{predict\_img\_with\_smooth\_windowing}}}{\emph{\DUrole{n}{input\_img}}, \emph{\DUrole{n}{window\_size}}, \emph{\DUrole{n}{subdivisions}}, \emph{\DUrole{n}{n\_classes}}, \emph{\DUrole{n}{pred\_func}}}{}
Apply the \sphinxtitleref{pred\_func} function to square patches of the image, and overlap
the predictions to merge them smoothly.
See 6th, 7th and 8th idea here:
\sphinxurl{http://blog.kaggle.com/2017/05/09/dstl-satellite-imagery-competition-3rd-place-winners-interview-vladimir-sergey/}

\end{fulllineitems}

\index{predict\_img\_with\_overlap() (in module data.post\_processing.smooth\_tiled\_predictions)@\spxentry{predict\_img\_with\_overlap()}\spxextra{in module data.post\_processing.smooth\_tiled\_predictions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/smooth_tiled_predictions:data.post_processing.smooth_tiled_predictions.predict_img_with_overlap}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.smooth\_tiled\_predictions.}}\sphinxbfcode{\sphinxupquote{predict\_img\_with\_overlap}}}{\emph{\DUrole{n}{input\_img}}, \emph{\DUrole{n}{window\_size}}, \emph{\DUrole{n}{subdivisions}}, \emph{\DUrole{n}{n\_classes}}, \emph{\DUrole{n}{pred\_func}}}{}
Based on predict\_img\_with\_smooth\_windowing but works just with the
original image instead of creating 8 new ones.

\end{fulllineitems}

\index{predict\_img\_with\_overlap\_weighted() (in module data.post\_processing.smooth\_tiled\_predictions)@\spxentry{predict\_img\_with\_overlap\_weighted()}\spxextra{in module data.post\_processing.smooth\_tiled\_predictions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/smooth_tiled_predictions:data.post_processing.smooth_tiled_predictions.predict_img_with_overlap_weighted}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.smooth\_tiled\_predictions.}}\sphinxbfcode{\sphinxupquote{predict\_img\_with\_overlap\_weighted}}}{\emph{\DUrole{n}{input\_img}}, \emph{\DUrole{n}{input\_mask}}, \emph{\DUrole{n}{weight\_map}}, \emph{\DUrole{n}{batch\_size\_value}}, \emph{\DUrole{n}{window\_size}}, \emph{\DUrole{n}{subdivisions}}, \emph{\DUrole{n}{n\_classes}}, \emph{\DUrole{n}{pred\_func}}}{}
Based on predict\_img\_with\_smooth\_windowing but works just with the
original image (adding a weight map) instead of creating 8 new ones.

\end{fulllineitems}

\index{cheap\_tiling\_prediction() (in module data.post\_processing.smooth\_tiled\_predictions)@\spxentry{cheap\_tiling\_prediction()}\spxextra{in module data.post\_processing.smooth\_tiled\_predictions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/smooth_tiled_predictions:data.post_processing.smooth_tiled_predictions.cheap_tiling_prediction}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.smooth\_tiled\_predictions.}}\sphinxbfcode{\sphinxupquote{cheap\_tiling\_prediction}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{window\_size}}, \emph{\DUrole{n}{n\_classes}}, \emph{\DUrole{n}{pred\_func}}}{}
Does predictions on an image without tiling.

\end{fulllineitems}

\index{get\_dummy\_img() (in module data.post\_processing.smooth\_tiled\_predictions)@\spxentry{get\_dummy\_img()}\spxextra{in module data.post\_processing.smooth\_tiled\_predictions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/smooth_tiled_predictions:data.post_processing.smooth_tiled_predictions.get_dummy_img}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.smooth\_tiled\_predictions.}}\sphinxbfcode{\sphinxupquote{get\_dummy\_img}}}{\emph{\DUrole{n}{xy\_size}\DUrole{o}{=}\DUrole{default_value}{128}}, \emph{\DUrole{n}{nb\_channels}\DUrole{o}{=}\DUrole{default_value}{3}}}{}
Create a random image with different luminosity in the corners.

Returns an array of shape (xy\_size, xy\_size, nb\_channels).

\end{fulllineitems}

\index{round\_predictions() (in module data.post\_processing.smooth\_tiled\_predictions)@\spxentry{round\_predictions()}\spxextra{in module data.post\_processing.smooth\_tiled\_predictions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{data/post_processing/smooth_tiled_predictions:data.post_processing.smooth_tiled_predictions.round_predictions}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{data.post\_processing.smooth\_tiled\_predictions.}}\sphinxbfcode{\sphinxupquote{round\_predictions}}}{\emph{\DUrole{n}{prd}}, \emph{\DUrole{n}{nb\_channels\_out}}, \emph{\DUrole{n}{thresholds}}}{}
From a threshold list \sphinxtitleref{thresholds} containing one threshold per output
channel for comparison, the predictions are converted to a binary mask.

\end{fulllineitems}



\section{engine}
\label{\detokenize{engine/engine:engine}}\label{\detokenize{engine/engine::doc}}

\subsection{Init}
\label{\detokenize{engine/init:module-engine}}\label{\detokenize{engine/init:init}}\label{\detokenize{engine/init::doc}}\index{module@\spxentry{module}!engine@\spxentry{engine}}\index{engine@\spxentry{engine}!module@\spxentry{module}}\index{prepare\_optimizer() (in module engine)@\spxentry{prepare\_optimizer()}\spxextra{in module engine}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/init:engine.prepare_optimizer}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.}}\sphinxbfcode{\sphinxupquote{prepare\_optimizer}}}{\emph{\DUrole{n}{cfg}}, \emph{\DUrole{n}{model}}}{}
Select the optimizer, loss and metrics for the given model.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item {} 
\sphinxstylestrong{model} (\sphinxcode{\sphinxupquote{Keras model}}) \textendash{} Model to be compiled with the selected options.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{build\_callbacks() (in module engine)@\spxentry{build\_callbacks()}\spxextra{in module engine}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/init:engine.build_callbacks}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.}}\sphinxbfcode{\sphinxupquote{build\_callbacks}}}{\emph{\DUrole{n}{cfg}}}{}
Create training and validation generators.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item[{Returns}] \leavevmode
\sphinxstylestrong{callbacks} \textendash{} All callbacks to be applied to a model.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{callbacks}}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Metrics}
\label{\detokenize{engine/metrics:module-engine.metrics}}\label{\detokenize{engine/metrics:metrics}}\label{\detokenize{engine/metrics::doc}}\index{module@\spxentry{module}!engine.metrics@\spxentry{engine.metrics}}\index{engine.metrics@\spxentry{engine.metrics}!module@\spxentry{module}}\index{jaccard\_index\_numpy() (in module engine.metrics)@\spxentry{jaccard\_index\_numpy()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.jaccard_index_numpy}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{jaccard\_index\_numpy}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}}{}
Define Jaccard index.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{N dim Numpy array}}) \textendash{} Ground truth masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}} for 2D images or
\sphinxcode{\sphinxupquote{(volume\_number, z, x, y, channels)}} for 3D volumes.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{N dim Numpy array}}) \textendash{} Predicted masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}} for 2D images or
\sphinxcode{\sphinxupquote{(volume\_number, z, x, y, channels)}} for 3D volumes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{jac} \textendash{} Jaccard index value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{float}}

\end{description}\end{quote}

\end{fulllineitems}

\index{jaccard\_index\_numpy\_without\_background() (in module engine.metrics)@\spxentry{jaccard\_index\_numpy\_without\_background()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.jaccard_index_numpy_without_background}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{jaccard\_index\_numpy\_without\_background}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}}{}
Define Jaccard index excluding the background class (first channel).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{N dim Numpy array}}) \textendash{} Ground truth masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}} for 2D images or
\sphinxcode{\sphinxupquote{(volume\_number, z, x, y, channels)}} for 3D volumes.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{N dim Numpy array}}) \textendash{} Predicted masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}} for 2D images or
\sphinxcode{\sphinxupquote{(volume\_number, z, x, y, channels)}} for 3D volumes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{jac} \textendash{} Jaccard index value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{float}}

\end{description}\end{quote}

\end{fulllineitems}

\index{jaccard\_index() (in module engine.metrics)@\spxentry{jaccard\_index()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.jaccard_index}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{jaccard\_index}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}, \emph{\DUrole{n}{t}\DUrole{o}{=}\DUrole{default_value}{0.5}}}{}
Define Jaccard index.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Ground truth masks.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Predicted masks.

\item {} 
\sphinxstylestrong{t} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold to be applied.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{jac} \textendash{} Jaccard index value

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{jaccard\_index\_without\_background() (in module engine.metrics)@\spxentry{jaccard\_index\_without\_background()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.jaccard_index_without_background}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{jaccard\_index\_without\_background}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}, \emph{\DUrole{n}{t}\DUrole{o}{=}\DUrole{default_value}{0.5}}}{}
Define Jaccard index.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Ground truth masks.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Predicted masks.

\item {} 
\sphinxstylestrong{t} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold to be applied.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{jac} \textendash{} Jaccard index value

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{jaccard\_index\_softmax() (in module engine.metrics)@\spxentry{jaccard\_index\_softmax()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.jaccard_index_softmax}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{jaccard\_index\_softmax}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}, \emph{\DUrole{n}{t}\DUrole{o}{=}\DUrole{default_value}{0.5}}}{}
Define Jaccard index.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Ground truth masks.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Predicted masks.

\item {} 
\sphinxstylestrong{t} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold to be applied.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{jac} \textendash{} Jaccard index value

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{jaccard\_index\_instances() (in module engine.metrics)@\spxentry{jaccard\_index\_instances()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.jaccard_index_instances}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{jaccard\_index\_instances}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}, \emph{\DUrole{n}{t}\DUrole{o}{=}\DUrole{default_value}{0.5}}}{}
Define Jaccard index. It only applies for the first two segmentation
channels.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Ground truth masks.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Predicted masks.

\item {} 
\sphinxstylestrong{t} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold to be applied.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{jac} \textendash{} Jaccard index value

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{jaccard\_loss() (in module engine.metrics)@\spxentry{jaccard\_loss()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.jaccard_loss}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{jaccard\_loss}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}}{}
Define Jaccard index.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true Tensor} \textendash{} Ground truth masks.

\item {} 
\sphinxstylestrong{y\_pred Tensor} \textendash{} Predicted masks.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{jac} \textendash{} Jaccard loss score.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{float}}

\end{description}\end{quote}

\end{fulllineitems}

\index{dice\_coeff() (in module engine.metrics)@\spxentry{dice\_coeff()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.dice_coeff}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{dice\_coeff}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}}{}
Dice coefficient.

Based on \sphinxhref{https://colab.research.google.com/github/tensorflow/models/blob/master/samples/outreach/blogs/segmentation\_blogpost/image\_segmentation.ipynb}{image\_segmentation.ipynb}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Ground truth masks.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Predicted masks.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{score} \textendash{} Dice coefficient value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{dice\_loss() (in module engine.metrics)@\spxentry{dice\_loss()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.dice_loss}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{dice\_loss}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}}{}
Dice loss.

Based on \sphinxhref{https://colab.research.google.com/github/tensorflow/models/blob/master/samples/outreach/blogs/segmentation\_blogpost/image\_segmentation.ipynb}{image\_segmentation.ipynb}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Ground truth masks.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{Tensor}}) \textendash{} Predicted masks.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{loss} \textendash{} Loss value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{bce\_dice\_loss() (in module engine.metrics)@\spxentry{bce\_dice\_loss()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.bce_dice_loss}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{bce\_dice\_loss}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}}{}
Loss function based on the combination of BCE and Dice.

Based on \sphinxhref{https://colab.research.google.com/github/tensorflow/models/blob/master/samples/outreach/blogs/segmentation\_blogpost/image\_segmentation.ipynb}{image\_segmentation.ipynb}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{Numpy array}}) \textendash{} Ground truth.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{Numpy array}}) \textendash{} Predictions.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{loss} \textendash{} Loss value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{weighted\_bce\_dice\_loss() (in module engine.metrics)@\spxentry{weighted\_bce\_dice\_loss()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.weighted_bce_dice_loss}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{weighted\_bce\_dice\_loss}}}{\emph{\DUrole{n}{w\_dice}\DUrole{o}{=}\DUrole{default_value}{0.5}}, \emph{\DUrole{n}{w\_bce}\DUrole{o}{=}\DUrole{default_value}{0.5}}}{}
Loss function based on the combination of BCE and Dice weighted.

Inspired by \sphinxhref{https://medium.com/@Bloomore/how-to-write-a-custom-loss-function-with-additional-arguments-in-keras-5f193929f7a0}{https://medium.com/@Bloomore post}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{w\_dice} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Weight to be applied to Dice loss.

\item {} 
\sphinxstylestrong{w\_bce} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Weight to be applied to BCE.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{loss} \textendash{} Loss value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{voc\_calculation() (in module engine.metrics)@\spxentry{voc\_calculation()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.voc_calculation}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{voc\_calculation}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}, \emph{\DUrole{n}{foreground}}}{}
Calculate VOC metric value.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Ground truth masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Predicted masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{foreground} (\sphinxcode{\sphinxupquote{float}}) \textendash{} Foreground Jaccard index score.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{voc} \textendash{} VOC score value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{float}}

\end{description}\end{quote}

\end{fulllineitems}

\index{DET\_calculation() (in module engine.metrics)@\spxentry{DET\_calculation()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.DET_calculation}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{DET\_calculation}}}{\emph{\DUrole{n}{Y\_test}}, \emph{\DUrole{n}{preds\_test}}, \emph{\DUrole{n}{ge\_path}}, \emph{\DUrole{n}{eval\_path}}, \emph{\DUrole{n}{det\_bin}}, \emph{\DUrole{n}{n\_dig}}, \emph{\DUrole{n}{job\_id}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}0\textquotesingle{}}}}{}
Cell tracking challenge detection accuracy (DET) calculation. This function uses the binary provided by the
challenge to detect the cell and it needs to store the images into some folders.

To obtain more info please visit the following link:
\begin{quote}

\sphinxurl{http://celltrackingchallenge.net/evaluation-methodology/}
\end{quote}

The name of the folders that are here created follow the conventions listed
in this \sphinxhref{https://public.celltrackingchallenge.net/documents/Naming\%20and\%20file\%20content\%20conventions.pdf}{link}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{Y\_test} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Ground truth mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{preds\_test} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Predicted mask. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{ge\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path where the ground truth is stored. If the folder does not exist it will be created with the \sphinxcode{\sphinxupquote{Y\_test}}
ground truth.

\item {} 
\sphinxstylestrong{eval\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path where the evaluation of the metric will be done.

\item {} 
\sphinxstylestrong{det\_bin} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to the DET binary provided by the cell tracking challenge.

\item {} 
\sphinxstylestrong{n\_dig} (\sphinxcode{\sphinxupquote{int}}) \textendash{} The number of digits used for encoding temporal indices (e.g., \sphinxcode{\sphinxupquote{3}}). Used by the DET calculation binary,
more info \sphinxhref{https://public.celltrackingchallenge.net/documents/Evaluation\%20software.pdf}{here}.

\item {} 
\sphinxstylestrong{job\_id} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Id of the job. Necessary to store the images on a location based on this string.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{det} \textendash{} DET accuracy.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{float}}

\end{description}\end{quote}

\end{fulllineitems}

\index{binary\_crossentropy\_weighted() (in module engine.metrics)@\spxentry{binary\_crossentropy\_weighted()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.binary_crossentropy_weighted}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{binary\_crossentropy\_weighted}}}{\emph{\DUrole{n}{weights}}}{}
Custom binary cross entropy loss. The weights are used to multiply the results of the usual cross\sphinxhyphen{}entropy loss
in order to give more weight to areas between cells close to one another.

Based on \sphinxhref{https://github.com/deepimagej/python4deepimagej/blob/master/unet/py\_files/unet\_weights.py}{unet\_weights.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{weights} (\sphinxcode{\sphinxupquote{float}}) \textendash{} Weigth to multiply the BCE value by.

\item[{Returns}] \leavevmode
\sphinxstylestrong{loss} \textendash{} Loss value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}

\index{instance\_segmentation\_loss() (in module engine.metrics)@\spxentry{instance\_segmentation\_loss()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.instance_segmentation_loss}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{instance\_segmentation\_loss}}}{\emph{\DUrole{n}{weights}\DUrole{o}{=}\DUrole{default_value}{1, 0.2}}, \emph{\DUrole{n}{out\_channels}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}BC\textquotesingle{}}}}{}
Custom loss that mixed BCE and MSE depending on the \sphinxcode{\sphinxupquote{out\_channels}} variable.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{weights} (\sphinxcode{\sphinxupquote{2 float tuple}}, \sphinxstyleemphasis{optional}) \textendash{} Weights to be applied to segmentation (binary and contours) and to distances respectively. E.g. \sphinxcode{\sphinxupquote{(1, 0.2)}},
\sphinxcode{\sphinxupquote{1}} should be multipled by \sphinxcode{\sphinxupquote{BCE}} for the first two channels and \sphinxcode{\sphinxupquote{0.2}} to \sphinxcode{\sphinxupquote{MSE}} for the last channel.

\item {} 
\sphinxstylestrong{out\_channels} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Channels to operate with. Possible values: \sphinxcode{\sphinxupquote{BC}} and \sphinxcode{\sphinxupquote{BCD}}. \sphinxcode{\sphinxupquote{BC}} corresponds to use binary
segmentation+contour. \sphinxcode{\sphinxupquote{BCD}} stands for binary segmentation+contour+distances.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{masked\_mse() (in module engine.metrics)@\spxentry{masked\_mse()}\spxextra{in module engine.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/metrics:engine.metrics.masked_mse}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{engine.metrics.}}\sphinxbfcode{\sphinxupquote{masked\_mse}}}{\emph{\DUrole{n}{y\_true}}, \emph{\DUrole{n}{y\_pred}}, \emph{\DUrole{n}{mask}}}{}
Apply MSE just in the pixels denoted by \sphinxcode{\sphinxupquote{mask}} variable.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{y\_true} (\sphinxcode{\sphinxupquote{4D Tensor}}) \textendash{} Ground truth masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{y\_pred} (\sphinxcode{\sphinxupquote{4D Tensor}}) \textendash{} Predicted masks. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{4F Tensor}}) \textendash{} Mask with True values on the pixels that will be involved in MSE calculation.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{value} \textendash{} MSE value.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Tensor}}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Trainer}
\label{\detokenize{engine/trainer:module-engine.trainer}}\label{\detokenize{engine/trainer:trainer}}\label{\detokenize{engine/trainer::doc}}\index{module@\spxentry{module}!engine.trainer@\spxentry{engine.trainer}}\index{engine.trainer@\spxentry{engine.trainer}!module@\spxentry{module}}\index{Trainer (class in engine.trainer)@\spxentry{Trainer}\spxextra{class in engine.trainer}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/trainer:engine.trainer.Trainer}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{engine.trainer.}}\sphinxbfcode{\sphinxupquote{Trainer}}}{\emph{\DUrole{n}{cfg}}, \emph{\DUrole{n}{job\_identifier}}}{}
Bases: \sphinxcode{\sphinxupquote{object}}
\subsubsection*{Methods}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{test}
&\\
\hline
\sphinxstylestrong{train}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\index{train() (engine.trainer.Trainer method)@\spxentry{train()}\spxextra{engine.trainer.Trainer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/trainer:engine.trainer.Trainer.train}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train}}}{}{}~
\end{fulllineitems}

\index{test() (engine.trainer.Trainer method)@\spxentry{test()}\spxextra{engine.trainer.Trainer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/trainer:engine.trainer.Trainer.test}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{test}}}{}{}~
\end{fulllineitems}


\end{fulllineitems}



\subsection{schedulers}
\label{\detokenize{engine/schedulers/schedulers:schedulers}}\label{\detokenize{engine/schedulers/schedulers::doc}}

\subsubsection{Cosine Decay}
\label{\detokenize{engine/schedulers/cosine_decay:module-engine.schedulers.cosine_decay}}\label{\detokenize{engine/schedulers/cosine_decay:cosine-decay}}\label{\detokenize{engine/schedulers/cosine_decay::doc}}\index{module@\spxentry{module}!engine.schedulers.cosine\_decay@\spxentry{engine.schedulers.cosine\_decay}}\index{engine.schedulers.cosine\_decay@\spxentry{engine.schedulers.cosine\_decay}!module@\spxentry{module}}
Code adapted from \sphinxurl{https://scorrea92.medium.com/cosine-learning-rate-decay-e8b50aa455b}
\index{WarmUpCosineDecayScheduler (class in engine.schedulers.cosine\_decay)@\spxentry{WarmUpCosineDecayScheduler}\spxextra{class in engine.schedulers.cosine\_decay}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{engine.schedulers.cosine\_decay.}}\sphinxbfcode{\sphinxupquote{WarmUpCosineDecayScheduler}}}{\emph{\DUrole{n}{learning\_rate\_base}}, \emph{\DUrole{n}{global\_step\_init}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{warmup\_learning\_rate}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{warmup\_epoch}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{hold\_base\_rate\_steps}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{learning\_rate\_final}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{stop\_epoch}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{batch\_size}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.callbacks.Callback}}

Cosine decay with warmup learning rate scheduler
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

{\hyperref[\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.cosine_decay_with_warmup}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{cosine\_decay\_with\_warmup}}}}}(global\_step, …{[}, …{]})
&
Cosine decay schedule with warm up period. Cosine annealing learning rate as described in     Loshchilov and Hutter, SGDR: Stochastic Gradient Descent with Warm Restarts. ICLR 2017. \sphinxurl{https://arxiv.org/abs/1608.03983} In this schedule, the learning rate grows linearly from warmup\_learning\_rate to learning\_rate\_base for warmup\_steps, then transitions to a cosine decay schedule. Arguments:     global\_step \{int\} \textendash{} global step. learning\_rate\_base \{float\} \textendash{} base learning rate. total\_steps \{int\} \textendash{} total number of training steps. Keyword Arguments:     warmup\_learning\_rate \{float\} \textendash{} initial learning rate for warm up. (default: \{0.0\})     warmup\_steps \{int\} \textendash{} number of warmup steps. (default: \{0\})     hold\_base\_rate\_steps \{int\} \textendash{} Optional number of steps to hold base learning rate                                 before decaying. (default: \{0\}) Returns:     a float representing learning rate. Raises:     ValueError: if warmup\_learning\_rate is larger than learning\_rate\_base,     or if warmup\_steps is larger than total\_steps.
\\
\hline
{\hyperref[\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.on_batch_begin}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_batch\_begin}}}}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_begin}.
\\
\hline
{\hyperref[\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.on_batch_end}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_batch\_end}}}}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_end}.
\\
\hline
{\hyperref[\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.on_epoch_begin}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_epoch\_begin}}}}}(epoch{[}, logs{]})
&
Called at the start of an epoch.
\\
\hline
\sphinxcode{\sphinxupquote{on\_epoch\_end}}(epoch{[}, logs{]})
&
Called at the end of an epoch.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_begin}}({[}logs{]})
&
Called at the beginning of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_end}}({[}logs{]})
&
Called at the end of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_begin}}({[}logs{]})
&
Called at the beginning of evaluation or validation.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_end}}({[}logs{]})
&
Called at the end of evaluation or validation.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_begin}}({[}logs{]})
&
Called at the beginning of training.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_end}}({[}logs{]})
&
Called at the end of training.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{set\_model}
&\\
\hline
\sphinxstylestrong{set\_params}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\index{on\_epoch\_begin() (engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method)@\spxentry{on\_epoch\_begin()}\spxextra{engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.on_epoch_begin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_epoch\_begin}}}{\emph{\DUrole{n}{epoch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Called at the start of an epoch.

Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.
\begin{description}
\item[{Arguments:}] \leavevmode
epoch: integer, index of epoch.
logs: dict. Currently no data is passed to this argument for this method
\begin{quote}

but that may change in the future.
\end{quote}

\end{description}

\end{fulllineitems}

\index{on\_batch\_end() (engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method)@\spxentry{on\_batch\_end()}\spxextra{engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.on_batch_end}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_batch\_end}}}{\emph{\DUrole{n}{batch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_end}.

\end{fulllineitems}

\index{on\_batch\_begin() (engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method)@\spxentry{on\_batch\_begin()}\spxextra{engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.on_batch_begin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_batch\_begin}}}{\emph{\DUrole{n}{batch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_begin}.

\end{fulllineitems}

\index{cosine\_decay\_with\_warmup() (engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method)@\spxentry{cosine\_decay\_with\_warmup()}\spxextra{engine.schedulers.cosine\_decay.WarmUpCosineDecayScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/cosine_decay:engine.schedulers.cosine_decay.WarmUpCosineDecayScheduler.cosine_decay_with_warmup}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{cosine\_decay\_with\_warmup}}}{\emph{\DUrole{n}{global\_step}}, \emph{\DUrole{n}{learning\_rate\_base}}, \emph{\DUrole{n}{total\_steps}}, \emph{\DUrole{n}{warmup\_learning\_rate}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{warmup\_steps}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{hold\_base\_rate\_steps}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
Cosine decay schedule with warm up period.
Cosine annealing learning rate as described in
\begin{quote}

Loshchilov and Hutter, SGDR: Stochastic Gradient Descent with Warm Restarts.
ICLR 2017. \sphinxurl{https://arxiv.org/abs/1608.03983}
\end{quote}

In this schedule, the learning rate grows linearly from warmup\_learning\_rate
to learning\_rate\_base for warmup\_steps, then transitions to a cosine decay
schedule.
Arguments:
\begin{quote}

global\_step \{int\} \textendash{} global step.
learning\_rate\_base \{float\} \textendash{} base learning rate.
total\_steps \{int\} \textendash{} total number of training steps.
\end{quote}
\begin{description}
\item[{Keyword Arguments:}] \leavevmode
warmup\_learning\_rate \{float\} \textendash{} initial learning rate for warm up. (default: \{0.0\})
warmup\_steps \{int\} \textendash{} number of warmup steps. (default: \{0\})
hold\_base\_rate\_steps \{int\} \textendash{} Optional number of steps to hold base learning rate
\begin{quote}

before decaying. (default: \{0\})
\end{quote}

\item[{Returns:}] \leavevmode
a float representing learning rate.

\item[{Raises:}] \leavevmode
ValueError: if warmup\_learning\_rate is larger than learning\_rate\_base,
or if warmup\_steps is larger than total\_steps.

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\subsubsection{One Cycle}
\label{\detokenize{engine/schedulers/one_cycle:module-engine.schedulers.one_cycle}}\label{\detokenize{engine/schedulers/one_cycle:one-cycle}}\label{\detokenize{engine/schedulers/one_cycle::doc}}\index{module@\spxentry{module}!engine.schedulers.one\_cycle@\spxentry{engine.schedulers.one\_cycle}}\index{engine.schedulers.one\_cycle@\spxentry{engine.schedulers.one\_cycle}!module@\spxentry{module}}
Super\sphinxhyphen{}convergence with one\sphinxhyphen{}cycle policy.
Original code by Andrich van Wyk: \sphinxurl{https://www.avanwyk.com/tensorflow-2-super-convergence-with-the-1cycle-policy/}

Example of application (simply add it as a callback when calling model.fit(…)):
\begin{quote}

epochs = 3
lr = 5e\sphinxhyphen{}3
steps = np.ceil(len(x\_train) / batch\_size) * epochs
lr\_schedule = OneCycleScheduler(lr, steps)

model = build\_model()
optimizer = tf.keras.optimizers.Adam( learning\_rate=lr )
model.compile(optimizer=optimizer, loss=’sparse\_categorical\_crossentropy’, metrics={[}‘accuracy’{]})

model.fit(train\_ds,epochs=epochs, callbacks={[}lr\_schedule{]})
\end{quote}
\index{CosineAnnealer (class in engine.schedulers.one\_cycle)@\spxentry{CosineAnnealer}\spxextra{class in engine.schedulers.one\_cycle}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.CosineAnnealer}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{engine.schedulers.one\_cycle.}}\sphinxbfcode{\sphinxupquote{CosineAnnealer}}}{\emph{\DUrole{n}{start}}, \emph{\DUrole{n}{end}}, \emph{\DUrole{n}{steps}}}{}
Bases: \sphinxcode{\sphinxupquote{object}}
\subsubsection*{Methods}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{step}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\index{step() (engine.schedulers.one\_cycle.CosineAnnealer method)@\spxentry{step()}\spxextra{engine.schedulers.one\_cycle.CosineAnnealer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.CosineAnnealer.step}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{step}}}{}{}~
\end{fulllineitems}


\end{fulllineitems}

\index{OneCycleScheduler (class in engine.schedulers.one\_cycle)@\spxentry{OneCycleScheduler}\spxextra{class in engine.schedulers.one\_cycle}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{engine.schedulers.one\_cycle.}}\sphinxbfcode{\sphinxupquote{OneCycleScheduler}}}{\emph{\DUrole{n}{lr\_max}}, \emph{\DUrole{n}{steps}}, \emph{\DUrole{n}{mom\_min}\DUrole{o}{=}\DUrole{default_value}{0.85}}, \emph{\DUrole{n}{mom\_max}\DUrole{o}{=}\DUrole{default_value}{0.95}}, \emph{\DUrole{n}{phase\_1\_pct}\DUrole{o}{=}\DUrole{default_value}{0.3}}, \emph{\DUrole{n}{div\_factor}\DUrole{o}{=}\DUrole{default_value}{25.0}}}{}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.callbacks.Callback}}

\sphinxtitleref{Callback} that schedules the learning rate on a 1cycle policy as per Leslie Smith’s paper(\sphinxurl{https://arxiv.org/pdf/1803.09820.pdf}).
If the model supports a momentum parameter, it will also be adapted by the schedule.
The implementation adopts additional improvements as per the fastai library: \sphinxurl{https://docs.fast.ai/callbacks.one\_cycle.html}, where
only two phases are used and the adaptation is done using cosine annealing.
In phase 1 the LR increases from \sphinxtitleref{lr\_max / div\_factor} to \sphinxtitleref{lr\_max} and momentum decreases from \sphinxtitleref{mom\_max} to \sphinxtitleref{mom\_min}.
In the second phase the LR decreases from \sphinxtitleref{lr\_max} to \sphinxtitleref{lr\_max / (div\_factor * 1e4)} and momemtum from \sphinxtitleref{mom\_max} to \sphinxtitleref{mom\_min}.
By default the phases are not of equal length, with the phase 1 percentage controlled by the parameter \sphinxtitleref{phase\_1\_pct}.
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxcode{\sphinxupquote{on\_batch\_begin}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_begin}.
\\
\hline
\sphinxcode{\sphinxupquote{on\_batch\_end}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_end}.
\\
\hline
\sphinxcode{\sphinxupquote{on\_epoch\_begin}}(epoch{[}, logs{]})
&
Called at the start of an epoch.
\\
\hline
\sphinxcode{\sphinxupquote{on\_epoch\_end}}(epoch{[}, logs{]})
&
Called at the end of an epoch.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_begin}}({[}logs{]})
&
Called at the beginning of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_end}}({[}logs{]})
&
Called at the end of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_begin}}({[}logs{]})
&
Called at the beginning of evaluation or validation.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_end}}({[}logs{]})
&
Called at the end of evaluation or validation.
\\
\hline
{\hyperref[\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.on_train_batch_begin}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_train\_batch\_begin}}}}}(batch{[}, logs{]})
&
Called at the beginning of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
{\hyperref[\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.on_train_batch_end}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_train\_batch\_end}}}}}(batch{[}, logs{]})
&
Called at the end of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
{\hyperref[\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.on_train_begin}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_train\_begin}}}}}({[}logs{]})
&
Called at the beginning of training.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_end}}({[}logs{]})
&
Called at the end of training.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{get\_lr}
&\\
\hline
\sphinxstylestrong{get\_momentum}
&\\
\hline
\sphinxstylestrong{lr\_schedule}
&\\
\hline
\sphinxstylestrong{mom\_schedule}
&\\
\hline
\sphinxstylestrong{plot}
&\\
\hline
\sphinxstylestrong{set\_lr}
&\\
\hline
\sphinxstylestrong{set\_model}
&\\
\hline
\sphinxstylestrong{set\_momentum}
&\\
\hline
\sphinxstylestrong{set\_params}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\index{on\_train\_begin() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{on\_train\_begin()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.on_train_begin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_train\_begin}}}{\emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Called at the beginning of training.

Subclasses should override for any actions to run.
\begin{description}
\item[{Arguments:}] \leavevmode\begin{description}
\item[{logs: dict. Currently no data is passed to this argument for this method}] \leavevmode
but that may change in the future.

\end{description}

\end{description}

\end{fulllineitems}

\index{on\_train\_batch\_begin() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{on\_train\_batch\_begin()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.on_train_batch_begin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_train\_batch\_begin}}}{\emph{\DUrole{n}{batch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Called at the beginning of a training batch in \sphinxtitleref{fit} methods.

Subclasses should override for any actions to run.
\begin{description}
\item[{Arguments:}] \leavevmode
batch: integer, index of batch within the current epoch.
logs: dict. Has keys \sphinxtitleref{batch} and \sphinxtitleref{size} representing the current batch
\begin{quote}

number and the size of the batch.
\end{quote}

\end{description}

\end{fulllineitems}

\index{on\_train\_batch\_end() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{on\_train\_batch\_end()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.on_train_batch_end}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_train\_batch\_end}}}{\emph{\DUrole{n}{batch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Called at the end of a training batch in \sphinxtitleref{fit} methods.

Subclasses should override for any actions to run.
\begin{description}
\item[{Arguments:}] \leavevmode
batch: integer, index of batch within the current epoch.
logs: dict. Metric results for this batch.

\end{description}

\end{fulllineitems}

\index{get\_lr() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{get\_lr()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.get_lr}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_lr}}}{}{}~
\end{fulllineitems}

\index{get\_momentum() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{get\_momentum()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.get_momentum}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_momentum}}}{}{}~
\end{fulllineitems}

\index{set\_lr() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{set\_lr()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.set_lr}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_lr}}}{\emph{\DUrole{n}{lr}}}{}~
\end{fulllineitems}

\index{set\_momentum() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{set\_momentum()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.set_momentum}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_momentum}}}{\emph{\DUrole{n}{mom}}}{}~
\end{fulllineitems}

\index{lr\_schedule() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{lr\_schedule()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.lr_schedule}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{lr\_schedule}}}{}{}~
\end{fulllineitems}

\index{mom\_schedule() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{mom\_schedule()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.mom_schedule}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{mom\_schedule}}}{}{}~
\end{fulllineitems}

\index{plot() (engine.schedulers.one\_cycle.OneCycleScheduler method)@\spxentry{plot()}\spxextra{engine.schedulers.one\_cycle.OneCycleScheduler method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{engine/schedulers/one_cycle:engine.schedulers.one_cycle.OneCycleScheduler.plot}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{plot}}}{}{}~
\end{fulllineitems}


\end{fulllineitems}



\section{models}
\label{\detokenize{models/models:models}}\label{\detokenize{models/models::doc}}

\subsection{Init}
\label{\detokenize{models/init:module-models}}\label{\detokenize{models/init:init}}\label{\detokenize{models/init::doc}}\index{module@\spxentry{module}!models@\spxentry{models}}\index{models@\spxentry{models}!module@\spxentry{module}}\index{build\_model() (in module models)@\spxentry{build\_model()}\spxextra{in module models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/init:models.build_model}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.}}\sphinxbfcode{\sphinxupquote{build\_model}}}{\emph{\DUrole{n}{cfg}}, \emph{\DUrole{n}{job\_identifier}}}{}
Build selected model
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{cfg} (\sphinxcode{\sphinxupquote{YACS CN object}}) \textendash{} Configuration.

\item {} 
\sphinxstylestrong{job\_identifier} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Job name.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Selected model.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{2D U\sphinxhyphen{}Net}
\label{\detokenize{models/unet2d:d-u-net}}\label{\detokenize{models/unet2d::doc}}

\subsubsection{2D U\sphinxhyphen{}Net}
\label{\detokenize{models/unet:module-models.unet}}\label{\detokenize{models/unet:d-u-net}}\label{\detokenize{models/unet::doc}}\index{module@\spxentry{module}!models.unet@\spxentry{models.unet}}\index{models.unet@\spxentry{models.unet}!module@\spxentry{module}}\index{U\_Net\_2D() (in module models.unet)@\spxentry{U\_Net\_2D()}\spxextra{in module models.unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/unet:models.unet.U_Net_2D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.unet.}}\sphinxbfcode{\sphinxupquote{U\_Net\_2D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}16, 32, 64, 128, 256{]}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.2, 0.2, 0.3{]}}}, \emph{\DUrole{n}{spatial\_dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 2D U\sphinxhyphen{}Net.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{2D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed. If no value is provided the default behaviour will be to select a piramidal value
starting from \sphinxcode{\sphinxupquote{0.1}} and reaching \sphinxcode{\sphinxupquote{0.3}} value.

\item {} 
\sphinxstylestrong{spatial\_dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use spatial dropout instead of the \sphinxtitleref{normal} dropout.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Make batch normalization.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following  network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{unet}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}



\subsubsection{2D Residual U\sphinxhyphen{}Net}
\label{\detokenize{models/resunet:module-models.resunet}}\label{\detokenize{models/resunet:d-residual-u-net}}\label{\detokenize{models/resunet::doc}}\index{module@\spxentry{module}!models.resunet@\spxentry{models.resunet}}\index{models.resunet@\spxentry{models.resunet}!module@\spxentry{module}}\index{ResUNet\_2D() (in module models.resunet)@\spxentry{ResUNet\_2D()}\spxextra{in module models.resunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/resunet:models.resunet.ResUNet_2D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.resunet.}}\sphinxbfcode{\sphinxupquote{ResUNet\_2D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.1, 0.1, 0.1{]}}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}16, 32, 64, 128, 256{]}}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 2D Residual\_U\sphinxhyphen{}Net.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{3 int}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available kernel initializer type.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use batch normalization.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{resunet}.png}\hspace*{\fill}}

Where each green layer represents a residual block as the following:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.450\linewidth]{{res_block}.png}\hspace*{\fill}}

Images created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}

\index{level\_block() (in module models.resunet)@\spxentry{level\_block()}\spxextra{in module models.resunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/resunet:models.resunet.level_block}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.resunet.}}\sphinxbfcode{\sphinxupquote{level\_block}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{depth}}, \emph{\DUrole{n}{f\_maps}}, \emph{\DUrole{n}{f\_size}}, \emph{\DUrole{n}{activation}}, \emph{\DUrole{n}{k\_init}}, \emph{\DUrole{n}{drop\_values}}, \emph{\DUrole{n}{batch\_norm}}, \emph{\DUrole{n}{first\_block}}}{}
Produces a level of the network. It calls itself recursively.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer of the block.

\item {} 
\sphinxstylestrong{depth} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Depth of the network. This value determines how many times the function will be called recursively.

\item {} 
\sphinxstylestrong{f\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}) \textendash{} Feature maps to use.

\item {} 
\sphinxstylestrong{f\_size} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Convolution window.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available kernel initializer type.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use batch normalization.

\item {} 
\sphinxstylestrong{first\_block} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} To advice the function that it is the first residual block of the network, which avoids Full Pre\sphinxhyphen{}Activation
layers (more info of Full Pre\sphinxhyphen{}Activation in \sphinxhref{https://arxiv.org/pdf/1603.05027.pdf}{Identity Mappings in Deep Residual Networks}).

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} last layer of the levels.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}

\index{residual\_block() (in module models.resunet)@\spxentry{residual\_block()}\spxextra{in module models.resunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/resunet:models.resunet.residual_block}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.resunet.}}\sphinxbfcode{\sphinxupquote{residual\_block}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{f\_maps}}, \emph{\DUrole{n}{f\_size}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{drop\_value}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{bn}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{first\_block}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Residual block.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer of the block.

\item {} 
\sphinxstylestrong{f\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}) \textendash{} Feature maps to use.

\item {} 
\sphinxstylestrong{f\_size} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Convolution window.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available kernel initializer type.

\item {} 
\sphinxstylestrong{drop\_value} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{bn} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use batch normalization.

\item {} 
\sphinxstylestrong{first\_block} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} To advice the function that it is the first residual block of the network, which avoids Full Pre\sphinxhyphen{}Activation
layers (more info of Full Pre\sphinxhyphen{}Activation in \sphinxhref{https://arxiv.org/pdf/1603.05027.pdf}{Identity Mappings in Deep Residual Networks}).

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} Last layer of the block.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{2D Attention U\sphinxhyphen{}Net}
\label{\detokenize{models/att_unet_2d:module-models.attention_unet}}\label{\detokenize{models/att_unet_2d:d-attention-u-net}}\label{\detokenize{models/att_unet_2d::doc}}\index{module@\spxentry{module}!models.attention\_unet@\spxentry{models.attention\_unet}}\index{models.attention\_unet@\spxentry{models.attention\_unet}!module@\spxentry{module}}\index{Attention\_U\_Net\_2D() (in module models.attention\_unet)@\spxentry{Attention\_U\_Net\_2D()}\spxextra{in module models.attention\_unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/att_unet_2d:models.attention_unet.Attention_U_Net_2D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.attention\_unet.}}\sphinxbfcode{\sphinxupquote{Attention\_U\_Net\_2D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}16, 32, 64, 128, 256{]}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.2, 0.2, 0.3{]}}}, \emph{\DUrole{n}{spatial\_dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 2D U\sphinxhyphen{}Net with Attention blocks.

Based on \sphinxhref{https://arxiv.org/abs/1804.03999}{Attention U\sphinxhyphen{}Net: Learning Where to Look for the Pancreas}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{2D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed. If no value is provided the default behaviour will be to select a piramidal value
starting from \sphinxcode{\sphinxupquote{0.1}} and reaching \sphinxcode{\sphinxupquote{0.3}} value.

\item {} 
\sphinxstylestrong{spatial\_dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use spatial dropout instead of the \sphinxtitleref{normal} dropout.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Make batch normalization.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the Attention U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}
\subsubsection*{Example}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{unet}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

That networks incorporates in skip connecions Attention Gates (AG), which
can be seen as follows:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{attention_gate}.png}\hspace*{\fill}}

Image extracted from \sphinxhref{https://arxiv.org/abs/1804.03999}{Attention U\sphinxhyphen{}Net: Learning Where to Look for the Pancreas}.

\end{fulllineitems}

\index{AttentionBlock() (in module models.attention\_unet)@\spxentry{AttentionBlock()}\spxextra{in module models.attention\_unet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/att_unet_2d:models.attention_unet.AttentionBlock}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.attention\_unet.}}\sphinxbfcode{\sphinxupquote{AttentionBlock}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{shortcut}}, \emph{\DUrole{n}{filters}}, \emph{\DUrole{n}{batch\_norm}}}{}
Attention block.

Extracted from \sphinxhref{https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/64367}{Kaggle}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer.

\item {} 
\sphinxstylestrong{shortcut} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input skip connection.

\item {} 
\sphinxstylestrong{filters} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Feature maps to define on the Conv layers.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To use batch normalization.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Last layer of the Attention block.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{2D SE U\sphinxhyphen{}Net}
\label{\detokenize{models/se_unet_2d:module-models.se_unet_2d}}\label{\detokenize{models/se_unet_2d:d-se-u-net}}\label{\detokenize{models/se_unet_2d::doc}}\index{module@\spxentry{module}!models.se\_unet\_2d@\spxentry{models.se\_unet\_2d}}\index{models.se\_unet\_2d@\spxentry{models.se\_unet\_2d}!module@\spxentry{module}}\index{SE\_U\_Net\_2D() (in module models.se\_unet\_2d)@\spxentry{SE\_U\_Net\_2D()}\spxextra{in module models.se\_unet\_2d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/se_unet_2d:models.se_unet_2d.SE_U_Net_2D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.se\_unet\_2d.}}\sphinxbfcode{\sphinxupquote{SE\_U\_Net\_2D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}16, 32, 64, 128, 256{]}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.2, 0.2, 0.3{]}}}, \emph{\DUrole{n}{spatial\_dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 2D U\sphinxhyphen{}Net with squeeze\sphinxhyphen{}excite blocks.

Reference \sphinxhref{https://arxiv.org/abs/1709.01507}{Squeeze and Excitation Networks}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{2D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed. If no value is provided the default behaviour will be to select a piramidal value
starting from \sphinxcode{\sphinxupquote{0.1}} and reaching \sphinxcode{\sphinxupquote{0.3}} value.

\item {} 
\sphinxstylestrong{spatial\_dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use spatial dropout instead of the \sphinxtitleref{normal} dropout.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Make batch normalization.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{unet}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}

\index{squeeze\_excite\_block() (in module models.se\_unet\_2d)@\spxentry{squeeze\_excite\_block()}\spxextra{in module models.se\_unet\_2d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/se_unet_2d:models.se_unet_2d.squeeze_excite_block}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.se\_unet\_2d.}}\sphinxbfcode{\sphinxupquote{squeeze\_excite\_block}}}{\emph{\DUrole{n}{input}}, \emph{\DUrole{n}{ratio}\DUrole{o}{=}\DUrole{default_value}{16}}}{}
Create a channel\sphinxhyphen{}wise squeeze\sphinxhyphen{}excite block.

Code fully extracted from \sphinxhref{https://github.com/titu1994/keras-squeeze-excite-network}{keras\sphinxhyphen{}squeeze\sphinxhyphen{}excite\sphinxhyphen{}network}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{input} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input Keras layer

\item {} 
\sphinxstylestrong{ratio} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Reduction fatio. See the paper for more info.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} The last layer after applayng the SE block

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras tensor}}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{3D U\sphinxhyphen{}Net}
\label{\detokenize{models/unet3d:d-u-net}}\label{\detokenize{models/unet3d::doc}}

\subsubsection{3D U\sphinxhyphen{}Net}
\label{\detokenize{models/unet_3d:module-models.unet_3d}}\label{\detokenize{models/unet_3d:d-u-net}}\label{\detokenize{models/unet_3d::doc}}\index{module@\spxentry{module}!models.unet\_3d@\spxentry{models.unet\_3d}}\index{models.unet\_3d@\spxentry{models.unet\_3d}!module@\spxentry{module}}\index{U\_Net\_3D() (in module models.unet\_3d)@\spxentry{U\_Net\_3D()}\spxextra{in module models.unet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/unet_3d:models.unet_3d.U_Net_3D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.unet\_3d.}}\sphinxbfcode{\sphinxupquote{U\_Net\_3D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}32, 64, 128, 256{]}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.1, 0.1{]}}}, \emph{\DUrole{n}{spatial\_dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{z\_down}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 3D U\sphinxhyphen{}Net.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{3D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{spatial\_dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use spatial dropout instead of the \sphinxtitleref{normal} dropout.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Make batch normalization.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{z\_down} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Downsampling used in z dimension. Set it to \sphinxcode{\sphinxupquote{1}} if the dataset is not isotropic.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{unet_3d}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}



\subsubsection{3D Residual U\sphinxhyphen{}Net}
\label{\detokenize{models/resunet_3d:module-models.resunet_3d}}\label{\detokenize{models/resunet_3d:d-residual-u-net}}\label{\detokenize{models/resunet_3d::doc}}\index{module@\spxentry{module}!models.resunet\_3d@\spxentry{models.resunet\_3d}}\index{models.resunet\_3d@\spxentry{models.resunet\_3d}!module@\spxentry{module}}\index{ResUNet\_3D() (in module models.resunet\_3d)@\spxentry{ResUNet\_3D()}\spxextra{in module models.resunet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/resunet_3d:models.resunet_3d.ResUNet_3D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.resunet\_3d.}}\sphinxbfcode{\sphinxupquote{ResUNet\_3D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.1, 0.1, 0.1{]}}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}16, 32, 64, 128, 256{]}}}, \emph{\DUrole{n}{z\_down}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 3D Residual\_U\sphinxhyphen{}Net.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{3D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available kernel initializer type.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use batch normalization.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{z\_down} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Downsampling used in z dimension. Set it to \sphinxcode{\sphinxupquote{1}} if the dataset is not isotropic.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{Model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{resunet_3d}.png}\hspace*{\fill}}

Where each green layer represents a residual block as the following:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.450\linewidth]{{res_block}.png}\hspace*{\fill}}

Images created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}

\index{level\_block() (in module models.resunet\_3d)@\spxentry{level\_block()}\spxextra{in module models.resunet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/resunet_3d:models.resunet_3d.level_block}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.resunet\_3d.}}\sphinxbfcode{\sphinxupquote{level\_block}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{depth}}, \emph{\DUrole{n}{f\_maps}}, \emph{\DUrole{n}{filter\_size}}, \emph{\DUrole{n}{activation}}, \emph{\DUrole{n}{k\_init}}, \emph{\DUrole{n}{drop\_values}}, \emph{\DUrole{n}{batch\_norm}}, \emph{\DUrole{n}{first\_block}}}{}
Produces a level of the network. It calls itself recursively.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer of the block.

\item {} 
\sphinxstylestrong{depth} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Depth of the network. This value determines how many times the function will be called recursively.

\item {} 
\sphinxstylestrong{f\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}) \textendash{} Feature maps to use.

\item {} 
\sphinxstylestrong{filter\_size} (\sphinxcode{\sphinxupquote{3 int tuple}}) \textendash{} Height, width and depth of the convolution window.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available kernel initializer type.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{floats}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use batch normalization.

\item {} 
\sphinxstylestrong{first\_block} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} To advice the function that it is the first residual block of the network, which avoids Full Pre\sphinxhyphen{}Activation
layers (more info of Full Pre\sphinxhyphen{}Activation in \sphinxhref{https://arxiv.org/pdf/1603.05027.pdf}{Identity Mappings in Deep Residual Networks}).

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} last layer of the levels.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}

\index{residual\_block() (in module models.resunet\_3d)@\spxentry{residual\_block()}\spxextra{in module models.resunet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/resunet_3d:models.resunet_3d.residual_block}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.resunet\_3d.}}\sphinxbfcode{\sphinxupquote{residual\_block}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{f\_maps}}, \emph{\DUrole{n}{filter\_size}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{drop\_value}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{bn}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{first\_block}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Residual block.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer of the block.

\item {} 
\sphinxstylestrong{f\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}) \textendash{} Feature maps to use.

\item {} 
\sphinxstylestrong{filter\_size} (\sphinxcode{\sphinxupquote{3 int tuple}}) \textendash{} Height, width and depth of the convolution window.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available kernel initializer type.

\item {} 
\sphinxstylestrong{drop\_value} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{bn} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use batch normalization.

\item {} 
\sphinxstylestrong{first\_block} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} To advice the function that it is the first residual block of the network, which avoids Full Pre\sphinxhyphen{}Activation
layers (more info of Full Pre\sphinxhyphen{}Activation in \sphinxhref{https://arxiv.org/pdf/1603.05027.pdf}{Identity Mappings in Deep Residual Networks}).

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} Last layer of the block.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{3D Attention U\sphinxhyphen{}Net}
\label{\detokenize{models/att_unet_3d:module-models.attention_unet_3d}}\label{\detokenize{models/att_unet_3d:d-attention-u-net}}\label{\detokenize{models/att_unet_3d::doc}}\index{module@\spxentry{module}!models.attention\_unet\_3d@\spxentry{models.attention\_unet\_3d}}\index{models.attention\_unet\_3d@\spxentry{models.attention\_unet\_3d}!module@\spxentry{module}}\index{Attention\_U\_Net\_3D() (in module models.attention\_unet\_3d)@\spxentry{Attention\_U\_Net\_3D()}\spxextra{in module models.attention\_unet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/att_unet_3d:models.attention_unet_3d.Attention_U_Net_3D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.attention\_unet\_3d.}}\sphinxbfcode{\sphinxupquote{Attention\_U\_Net\_3D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}32, 64, 128, 256{]}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.1, 0.1{]}}}, \emph{\DUrole{n}{spatial\_dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{z\_down}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 3D U\sphinxhyphen{}Net with Attention blocks.

Based on \sphinxhref{https://arxiv.org/abs/1804.03999}{Attention U\sphinxhyphen{}Net: Learning Where to Look for the Pancreas}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{3D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{spatial\_dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use spatial dropout instead of the \sphinxtitleref{normal} dropout.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Make batch normalization.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{z\_down} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Downsampling used in z dimension. Set it to \sphinxcode{\sphinxupquote{1}} if the dataset is not isotropic.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the Attention U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:
\subsubsection*{Example}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{unet_3d}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

That networks incorporates in skip connecions Attention Gates (AG), which can be seen as follows:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{attention_gate}.png}\hspace*{\fill}}

Image extracted from \sphinxhref{https://arxiv.org/abs/1804.03999}{Attention U\sphinxhyphen{}Net: Learning Where to Look for the Pancreas}.

\end{fulllineitems}

\index{AttentionBlock() (in module models.attention\_unet\_3d)@\spxentry{AttentionBlock()}\spxextra{in module models.attention\_unet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/att_unet_3d:models.attention_unet_3d.AttentionBlock}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.attention\_unet\_3d.}}\sphinxbfcode{\sphinxupquote{AttentionBlock}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{shortcut}}, \emph{\DUrole{n}{filters}}, \emph{\DUrole{n}{batch\_norm}}}{}
Attention block.

Extracted from \sphinxhref{https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/64367}{Kaggle}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer.

\item {} 
\sphinxstylestrong{shortcut} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input skip connection.

\item {} 
\sphinxstylestrong{filters} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Feature maps to define on the Conv layers.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To use batch normalization.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Last layer of the Attention block.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{3D SE U\sphinxhyphen{}Net}
\label{\detokenize{models/se_unet_3d:module-models.se_unet_3d}}\label{\detokenize{models/se_unet_3d:d-se-u-net}}\label{\detokenize{models/se_unet_3d::doc}}\index{module@\spxentry{module}!models.se\_unet\_3d@\spxentry{models.se\_unet\_3d}}\index{models.se\_unet\_3d@\spxentry{models.se\_unet\_3d}!module@\spxentry{module}}\index{SE\_U\_Net\_3D() (in module models.se\_unet\_3d)@\spxentry{SE\_U\_Net\_3D()}\spxextra{in module models.se\_unet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/se_unet_3d:models.se_unet_3d.SE_U_Net_3D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.se\_unet\_3d.}}\sphinxbfcode{\sphinxupquote{SE\_U\_Net\_3D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}elu\textquotesingle{}}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}32, 64, 128, 256{]}}}, \emph{\DUrole{n}{drop\_values}\DUrole{o}{=}\DUrole{default_value}{{[}0.1, 0.1, 0.1, 0.1{]}}}, \emph{\DUrole{n}{spatial\_dropout}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{batch\_norm}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create 3D U\sphinxhyphen{}Net with squeeze\sphinxhyphen{}excite blocks.

Reference \sphinxhref{https://arxiv.org/abs/1709.01507}{Squeeze and Excitation Networks}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{3D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{drop\_values} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout value to be fixed.

\item {} 
\sphinxstylestrong{spatial\_dropout} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Use spatial dropout instead of the \sphinxtitleref{normal} dropout.

\item {} 
\sphinxstylestrong{batch\_norm} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Make batch normalization.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following
network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{unet_3d}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}

\index{squeeze\_excite\_block() (in module models.se\_unet\_3d)@\spxentry{squeeze\_excite\_block()}\spxextra{in module models.se\_unet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/se_unet_3d:models.se_unet_3d.squeeze_excite_block}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.se\_unet\_3d.}}\sphinxbfcode{\sphinxupquote{squeeze\_excite\_block}}}{\emph{\DUrole{n}{input}}, \emph{\DUrole{n}{ratio}\DUrole{o}{=}\DUrole{default_value}{16}}}{}
Create a channel\sphinxhyphen{}wise squeeze\sphinxhyphen{}excite block.

Code fully extracted from \sphinxhref{https://github.com/titu1994/keras-squeeze-excite-network}{keras\sphinxhyphen{}squeeze\sphinxhyphen{}excite\sphinxhyphen{}network}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{input} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input Keras layer

\item {} 
\sphinxstylestrong{ratio} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Reduction fatio. See the paper for more info.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} The last layer after applayng the SE block

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras tensor}}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{3D Vanilla U\sphinxhyphen{}Net}
\label{\detokenize{models/vanilla_unet_3d:module-models.vanilla_unet_3d}}\label{\detokenize{models/vanilla_unet_3d:d-vanilla-u-net}}\label{\detokenize{models/vanilla_unet_3d::doc}}\index{module@\spxentry{module}!models.vanilla\_unet\_3d@\spxentry{models.vanilla\_unet\_3d}}\index{models.vanilla\_unet\_3d@\spxentry{models.vanilla\_unet\_3d}!module@\spxentry{module}}\index{Vanilla\_U\_Net\_3D() (in module models.vanilla\_unet\_3d)@\spxentry{Vanilla\_U\_Net\_3D()}\spxextra{in module models.vanilla\_unet\_3d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/vanilla_unet_3d:models.vanilla_unet_3d.Vanilla_U_Net_3D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.vanilla\_unet\_3d.}}\sphinxbfcode{\sphinxupquote{Vanilla\_U\_Net\_3D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}relu\textquotesingle{}}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{{[}32, 64, 128, 256, 512{]}}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create Vanilla 3D U\sphinxhyphen{}Net.

Based on \sphinxhref{https://arxiv.org/abs/1606.06650}{U\sphinxhyphen{}Net 3D}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{3D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Keras available activation type.

\item {} 
\sphinxstylestrong{feature\_maps} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to use on each level.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{vanilla_unet_3d}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}



\subsection{FCN}
\label{\detokenize{models/fcn:module-models.fcn_vgg}}\label{\detokenize{models/fcn:fcn}}\label{\detokenize{models/fcn::doc}}\index{module@\spxentry{module}!models.fcn\_vgg@\spxentry{models.fcn\_vgg}}\index{models.fcn\_vgg@\spxentry{models.fcn\_vgg}!module@\spxentry{module}}\index{FCN32\_VGG16() (in module models.fcn\_vgg)@\spxentry{FCN32\_VGG16()}\spxextra{in module models.fcn\_vgg}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/fcn:models.fcn_vgg.FCN32_VGG16}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.fcn\_vgg.}}\sphinxbfcode{\sphinxupquote{FCN32\_VGG16}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
Create FCN32 network based on a VGG16.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{2D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the FCN32.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{fcn32}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}

\index{FCN8\_VGG16() (in module models.fcn\_vgg)@\spxentry{FCN8\_VGG16()}\spxextra{in module models.fcn\_vgg}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/fcn:models.fcn_vgg.FCN8_VGG16}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.fcn\_vgg.}}\sphinxbfcode{\sphinxupquote{FCN8\_VGG16}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
Create FCN8 network based on a VGG16.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{2D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the FCN8.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

Calling this function with its default parameters returns the following network:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{fcn8}.png}\hspace*{\fill}}

Image created with \sphinxhref{https://github.com/HarisIqbal88/PlotNeuralNet}{PlotNeuralNet}.

\end{fulllineitems}



\subsection{nnU\sphinxhyphen{}Net}
\label{\detokenize{models/nnunet:module-sota_implementations.nnUNet_2018.nnUNet_2d}}\label{\detokenize{models/nnunet:nnu-net}}\label{\detokenize{models/nnunet::doc}}\index{module@\spxentry{module}!sota\_implementations.nnUNet\_2018.nnUNet\_2d@\spxentry{sota\_implementations.nnUNet\_2018.nnUNet\_2d}}\index{sota\_implementations.nnUNet\_2018.nnUNet\_2d@\spxentry{sota\_implementations.nnUNet\_2018.nnUNet\_2d}!module@\spxentry{module}}\index{nnUNet\_2D() (in module sota\_implementations.nnUNet\_2018.nnUNet\_2d)@\spxentry{nnUNet\_2D()}\spxextra{in module sota\_implementations.nnUNet\_2018.nnUNet\_2d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/nnunet:sota_implementations.nnUNet_2018.nnUNet_2d.nnUNet_2D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{sota\_implementations.nnUNet\_2018.nnUNet\_2d.}}\sphinxbfcode{\sphinxupquote{nnUNet\_2D}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{feature\_maps}\DUrole{o}{=}\DUrole{default_value}{32}}, \emph{\DUrole{n}{max\_fa}\DUrole{o}{=}\DUrole{default_value}{480}}, \emph{\DUrole{n}{num\_pool}\DUrole{o}{=}\DUrole{default_value}{8}}, \emph{\DUrole{n}{k\_init}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}he\_normal\textquotesingle{}}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Create nnU\sphinxhyphen{}Net 2D. This implementations tries to be a Keras version of the original nnU\sphinxhyphen{}Net 2D presented in
\sphinxhref{https://github.com/MIC-DKFZ/nnUNet}{nnU\sphinxhyphen{}Net Github}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{2D tuple}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{feature\_map} (\sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Feature maps to start with in the first level of the U\sphinxhyphen{}Net (will be duplicated on each level).

\item {} 
\sphinxstylestrong{max\_fa} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of maximum feature maps allowed to used in conv layers.

\item {} 
\sphinxstylestrong{num\_pool} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} number of pooling (downsampling) operations to do.

\item {} 
\sphinxstylestrong{k\_init} (\sphinxcode{\sphinxupquote{string}}, \sphinxstyleemphasis{optional}) \textendash{} Kernel initialization for convolutional layers.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the U\sphinxhyphen{}Net.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

\end{fulllineitems}

\index{StackedConvLayers() (in module sota\_implementations.nnUNet\_2018.nnUNet\_2d)@\spxentry{StackedConvLayers()}\spxextra{in module sota\_implementations.nnUNet\_2018.nnUNet\_2d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/nnunet:sota_implementations.nnUNet_2018.nnUNet_2d.StackedConvLayers}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{sota\_implementations.nnUNet\_2018.nnUNet\_2d.}}\sphinxbfcode{\sphinxupquote{StackedConvLayers}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{feature\_maps}}, \emph{\DUrole{n}{k\_init}}, \emph{\DUrole{n}{first\_conv\_stride}\DUrole{o}{=}\DUrole{default_value}{2}}}{}~
\end{fulllineitems}

\index{ConvDropoutNormNonlin() (in module sota\_implementations.nnUNet\_2018.nnUNet\_2d)@\spxentry{ConvDropoutNormNonlin()}\spxextra{in module sota\_implementations.nnUNet\_2018.nnUNet\_2d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/nnunet:sota_implementations.nnUNet_2018.nnUNet_2d.ConvDropoutNormNonlin}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{sota\_implementations.nnUNet\_2018.nnUNet\_2d.}}\sphinxbfcode{\sphinxupquote{ConvDropoutNormNonlin}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{feature\_maps}}, \emph{\DUrole{n}{k\_init}}, \emph{\DUrole{n}{first\_conv\_stride}\DUrole{o}{=}\DUrole{default_value}{1}}}{}~
\end{fulllineitems}



\subsection{MultiResUNet}
\label{\detokenize{models/multiresunet:module-models.multiresunet}}\label{\detokenize{models/multiresunet:multiresunet}}\label{\detokenize{models/multiresunet::doc}}\index{module@\spxentry{module}!models.multiresunet@\spxentry{models.multiresunet}}\index{models.multiresunet@\spxentry{models.multiresunet}!module@\spxentry{module}}
Code fully extracted from \sphinxhref{https://github.com/nibtehaz/MultiResUNet}{MultiResUNet}.
\index{conv2d\_bn() (in module models.multiresunet)@\spxentry{conv2d\_bn()}\spxextra{in module models.multiresunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/multiresunet:models.multiresunet.conv2d_bn}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.multiresunet.}}\sphinxbfcode{\sphinxupquote{conv2d\_bn}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{filters}}, \emph{\DUrole{n}{num\_row}}, \emph{\DUrole{n}{num\_col}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}same\textquotesingle{}}}, \emph{\DUrole{n}{strides}\DUrole{o}{=}\DUrole{default_value}{1, 1}}, \emph{\DUrole{n}{activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}relu\textquotesingle{}}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
2D Convolutional layers.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer.

\item {} 
\sphinxstylestrong{filters} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of filters.

\item {} 
\sphinxstylestrong{num\_row} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of rows in filters.

\item {} 
\sphinxstylestrong{num\_col} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of columns in filters.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Mode of padding.

\item {} 
\sphinxstylestrong{strides} (\sphinxcode{\sphinxupquote{tuple}}, \sphinxstyleemphasis{optional}) \textendash{} Stride of convolution operation.

\item {} 
\sphinxstylestrong{activation} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Activation function.

\item {} 
\sphinxstylestrong{name} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Name of the layer.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} Output layer.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}

\index{trans\_conv2d\_bn() (in module models.multiresunet)@\spxentry{trans\_conv2d\_bn()}\spxextra{in module models.multiresunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/multiresunet:models.multiresunet.trans_conv2d_bn}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.multiresunet.}}\sphinxbfcode{\sphinxupquote{trans\_conv2d\_bn}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{filters}}, \emph{\DUrole{n}{num\_row}}, \emph{\DUrole{n}{num\_col}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}same\textquotesingle{}}}, \emph{\DUrole{n}{strides}\DUrole{o}{=}\DUrole{default_value}{2, 2}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
2D Transposed Convolutional layers.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{x} (\sphinxcode{\sphinxupquote{keras layer}}) \textendash{} Input layer.

\item {} 
\sphinxstylestrong{filters} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of filters.

\item {} 
\sphinxstylestrong{num\_row} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of rows in filters.

\item {} 
\sphinxstylestrong{num\_col} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of columns in filters.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Mode of padding.

\item {} 
\sphinxstylestrong{strides} (\sphinxcode{\sphinxupquote{tuple}}, \sphinxstyleemphasis{optional}) \textendash{} Stride of convolution operation.

\item {} 
\sphinxstylestrong{name} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Name of the layer.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} Output layer.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}

\index{MultiResBlock() (in module models.multiresunet)@\spxentry{MultiResBlock()}\spxextra{in module models.multiresunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/multiresunet:models.multiresunet.MultiResBlock}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.multiresunet.}}\sphinxbfcode{\sphinxupquote{MultiResBlock}}}{\emph{\DUrole{n}{U}}, \emph{\DUrole{n}{inp}}, \emph{\DUrole{n}{alpha}\DUrole{o}{=}\DUrole{default_value}{1.67}}}{}
MultiRes Block.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{U} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of filters in a corrsponding UNet stage.

\item {} 
\sphinxstylestrong{inp} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Output layer.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}

\index{ResPath() (in module models.multiresunet)@\spxentry{ResPath()}\spxextra{in module models.multiresunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/multiresunet:models.multiresunet.ResPath}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.multiresunet.}}\sphinxbfcode{\sphinxupquote{ResPath}}}{\emph{\DUrole{n}{filters}}, \emph{\DUrole{n}{length}}, \emph{\DUrole{n}{inp}}}{}
ResPath.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{filters} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Description.

\item {} 
\sphinxstylestrong{length} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Length of ResPath.

\item {} 
\sphinxstylestrong{inp} (\sphinxcode{\sphinxupquote{Keras layer}}) \textendash{} Input layer.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{out} \textendash{} Output layer.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras layer}}

\end{description}\end{quote}

\end{fulllineitems}

\index{MultiResUnet() (in module models.multiresunet)@\spxentry{MultiResUnet()}\spxextra{in module models.multiresunet}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/multiresunet:models.multiresunet.MultiResUnet}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.multiresunet.}}\sphinxbfcode{\sphinxupquote{MultiResUnet}}}{\emph{\DUrole{n}{height}}, \emph{\DUrole{n}{width}}, \emph{\DUrole{n}{n\_channels}}}{}
MultiResUNet.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{height} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Height of image.

\item {} 
\sphinxstylestrong{width} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Width of image.

\item {} 
\sphinxstylestrong{n\_channels} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of channels in image.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} MultiResUNet model.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Tiramisu (FC\sphinxhyphen{}DenseNet103)}
\label{\detokenize{models/tiramisu:module-models.tiramisu}}\label{\detokenize{models/tiramisu:tiramisu-fc-densenet103}}\label{\detokenize{models/tiramisu::doc}}\index{module@\spxentry{module}!models.tiramisu@\spxentry{models.tiramisu}}\index{models.tiramisu@\spxentry{models.tiramisu}!module@\spxentry{module}}\index{FC\_DenseNet103() (in module models.tiramisu)@\spxentry{FC\_DenseNet103()}\spxextra{in module models.tiramisu}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/tiramisu:models.tiramisu.FC_DenseNet103}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.tiramisu.}}\sphinxbfcode{\sphinxupquote{FC\_DenseNet103}}}{\emph{\DUrole{n}{image\_shape}}, \emph{\DUrole{n}{n\_filters\_first\_conv}\DUrole{o}{=}\DUrole{default_value}{48}}, \emph{\DUrole{n}{n\_pool}\DUrole{o}{=}\DUrole{default_value}{4}}, \emph{\DUrole{n}{growth\_rate}\DUrole{o}{=}\DUrole{default_value}{12}}, \emph{\DUrole{n}{n\_layers\_per\_block}\DUrole{o}{=}\DUrole{default_value}{5}}, \emph{\DUrole{n}{dropout\_p}\DUrole{o}{=}\DUrole{default_value}{0.2}}}{}
Create FC\sphinxhyphen{}DenseNet103 (Tiramisu network) proposed in \sphinxhref{https://arxiv.org/pdf/1611.09326.pdf}{The One Hundred Layers Tiramisu: Fully Convolutional
DenseNets for Semantic Segmentation} . Code copied from \sphinxhref{https://github.com/SimJeg/FC-DenseNet/blob/master/FC-DenseNet.py}{FC\sphinxhyphen{}DenseNet103} and just adapted from Lasagne to Keras.

The network consist of a downsampling path, where dense blocks and transition down are applied, followed by an
upsampling path where transition up and dense blocks are applied. Skip connections are used between the
downsampling path and the upsampling path Each layer is a composite function of BN \sphinxhyphen{} ReLU \sphinxhyphen{} Conv and the last
layer is a softmax layer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{image\_shape} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{3 int}}) \textendash{} Dimensions of the input image.

\item {} 
\sphinxstylestrong{n\_filters\_first\_conv} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of filters for the first convolution applied.

\item {} 
\sphinxstylestrong{n\_pool} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of pooling layers = number of transition down = number of transition up.

\item {} 
\sphinxstylestrong{growth\_rate} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of new feature maps created by each layer in a dense block.

\item {} 
\sphinxstylestrong{n\_layers\_per\_block} (\sphinxcode{\sphinxupquote{array}} of \sphinxcode{\sphinxupquote{ints}}, \sphinxstyleemphasis{optional}) \textendash{} Number of layers per block. Can be an int or a list of size \sphinxcode{\sphinxupquote{(2*n\_pool)+1}}.

\item {} 
\sphinxstylestrong{dropout\_p} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Dropout rate applied after each convolution (\sphinxcode{\sphinxupquote{0.0}} for not using).

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{model} \textendash{} Model containing the FC\_DenseNet103.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Keras model}}

\end{description}\end{quote}

\end{fulllineitems}

\index{BN\_ReLU\_Conv() (in module models.tiramisu)@\spxentry{BN\_ReLU\_Conv()}\spxextra{in module models.tiramisu}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/tiramisu:models.tiramisu.BN_ReLU_Conv}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.tiramisu.}}\sphinxbfcode{\sphinxupquote{BN\_ReLU\_Conv}}}{\emph{\DUrole{n}{inputs}}, \emph{\DUrole{n}{n\_filters}}, \emph{\DUrole{n}{filter\_size}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{dropout\_p}\DUrole{o}{=}\DUrole{default_value}{0.2}}}{}
Apply successivly BatchNormalization, ReLu nonlinearity, Convolution and Dropout (if dropout\_p \textgreater{} 0) on the inputs.

\end{fulllineitems}

\index{TransitionDown() (in module models.tiramisu)@\spxentry{TransitionDown()}\spxextra{in module models.tiramisu}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/tiramisu:models.tiramisu.TransitionDown}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.tiramisu.}}\sphinxbfcode{\sphinxupquote{TransitionDown}}}{\emph{\DUrole{n}{inputs}}, \emph{\DUrole{n}{n\_filters}}, \emph{\DUrole{n}{dropout\_p}\DUrole{o}{=}\DUrole{default_value}{0.2}}}{}
Apply first a BN\_ReLu\_conv layer with filter size = 1, and a max pooling with a factor 2.

\end{fulllineitems}

\index{TransitionUp() (in module models.tiramisu)@\spxentry{TransitionUp()}\spxextra{in module models.tiramisu}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{models/tiramisu:models.tiramisu.TransitionUp}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{models.tiramisu.}}\sphinxbfcode{\sphinxupquote{TransitionUp}}}{\emph{\DUrole{n}{skip\_connection}}, \emph{\DUrole{n}{block\_to\_upsample}}, \emph{\DUrole{n}{n\_filters\_keep}}}{}
Performs upsampling on block\_to\_upsample by a factor 2 and concatenates it with the skip\_connection.

\end{fulllineitems}



\section{sota\_implementations}
\label{\detokenize{sota_implementations/sota_implementations:sota-implementations}}\label{\detokenize{sota_implementations/sota_implementations::doc}}

\subsection{Casser et al.}
\label{\detokenize{sota_implementations/casser_2018/casser:casser-et-al}}\label{\detokenize{sota_implementations/casser_2018/casser::doc}}
As part of our paper we try to reproduce other state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art approaches for EM semantic segmentation
that do not provide code. In this case the following paper has been reproduced:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Vincent Casser, Kai Kang, Hanspeter Pfister, and Daniel Haehn, \PYG{l+s+s2}{\PYGZdq{}Fast mitochondria}
\PYG{l+s+s2}{segmentation for connectomics\PYGZdq{}}, arXiv preprint arXiv:1812.06024 \PYG{o}{(}\PYG{l+m}{2018}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxhref{https://arxiv.org/abs/1812.06024}{{[}Paper{]}} \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/casser\_2018}{{[}Our code{]}}

We have prepared two templates:
\begin{itemize}
\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/casser\_2018/casser\_template\_V0.py}{casser\_template\_V0.py} : exact parameters and training workflow as described in the paper.

\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/casser\_2018/casser\_template\_V1.py}{casser\_template\_V1.py} : changes made respect to V0 with which we have achieved better results.

\end{itemize}
\begin{description}
\item[{The implementation is based in one file:}] \leavevmode\begin{itemize}
\item {} 
\sphinxhref{casser\_network.html}{2D U\sphinxhyphen{}Net}: proposed 2D U\sphinxhyphen{}Net (recently submitted by the authors \sphinxhref{https://github.com/mpsych/mitochondria}{here}).

\end{itemize}

\end{description}

Here is a picture of the network extracted from the original paper:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=1.000\linewidth]{{casser_network}.png}\hspace*{\fill}}


\subsection{Cheng et al.}
\label{\detokenize{sota_implementations/cheng_2017/cheng:cheng-et-al}}\label{\detokenize{sota_implementations/cheng_2017/cheng::doc}}
As part of our paper we try to reproduce other state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art approaches for EM semantic segmentation
that do not provide code. In this case the following paper has been reproduced:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
H. Cheng and A. Varshney, \PYG{l+s+s2}{\PYGZdq{}Volume segmentation using convolutional neural networks with}
\PYG{l+s+s2}{limited training data\PYGZdq{}}, \PYG{l+m}{2017} IEEE International Conference on Image Processing \PYG{o}{(}ICIP\PYG{o}{)},
Beijing, \PYG{l+m}{2017}, pp. \PYG{l+m}{590}\PYGZhy{}594.
\end{sphinxVerbatim}

\sphinxhref{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8296349\&casa\_token=5b69S99XYcYAAAAA:1-kW8nB6nLKm8Fc0adC-i2OFA9CIrW-DD2dcjcIJGcDfzKYfxMv4j2-5COjyyQJ6vIjE818clA\&tag=1}{{[}Paper{]}} \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/cheng\_2017}{{[}Our code{]}}

We have prepared three templates:
\begin{itemize}
\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/cheng\_2017/cheng\_2D\_template\_V0.py}{cheng\_2D\_template\_V0.py} : exact parameters and training workflow as described in the paper.

\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/cheng\_2017/cheng\_2D\_template\_V1.py}{cheng\_2D\_template\_V1.py} : changes made respect to V0 with which we have achieved better results.

\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/cheng\_2017/cheng\_3D\_template\_V0.py}{cheng\_3D\_template\_V0.py} : exact parameters and training workflow as described in the paper.

\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/cheng\_2017/cheng\_3D\_template\_V1.py}{cheng\_3D\_template\_V1.py} : changes made respect to V0 with which we have achieved better results.

\end{itemize}
\begin{description}
\item[{The implementation is based in one file:}] \leavevmode\begin{itemize}
\item {} 
\sphinxhref{cheng\_network.html}{2D network} : proposed 2D network.

\item {} 
\sphinxhref{cheng\_3d\_network.html}{3D network} : proposed 3D network.

\item {} 
\sphinxhref{cheng\_loss.html}{loss} : jaccard based loss proposed in the paper.

\item {} 
\sphinxhref{cheng\_sto2D.html}{2D stochastic downsampling} : new layer proposed by the authors to make feature level augmentation.

\item {} 
\sphinxhref{cheng\_sto2D.html}{3D stochastic downsampling} : 3D version of the previous layer.

\end{itemize}

\end{description}


\subsection{Fu et. al (MNet)}
\label{\detokenize{sota_implementations/MNet_Fu_2018/MNet_Fu_2018:fu-et-al-mnet}}\label{\detokenize{sota_implementations/MNet_Fu_2018/MNet_Fu_2018::doc}}

\subsection{Oztel et al.}
\label{\detokenize{sota_implementations/oztel_2017/oztel:oztel-et-al}}\label{\detokenize{sota_implementations/oztel_2017/oztel::doc}}
As part of our paper we try to reproduce other state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art approaches for EM semantic segmentation
that do not provide code. In this case the following paper has been reproduced:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ismail Oztel, Gozde Yolcu, Ilker Ersoy, Tommi White, and Filiz Bunyak, \PYG{l+s+s2}{\PYGZdq{}Mitochondria}
\PYG{l+s+s2}{segmentation in electron microscopy volumes using deep convolutional neural network\PYGZdq{}},
\PYG{l+m}{2017} IEEE International Conference on Bioinformatics and Biomedicine \PYG{o}{(}BIBM\PYG{o}{)}, IEEE,
\PYG{l+m}{2017}, pp. \PYG{l+m}{1195}\PYGZhy{}1200.
\end{sphinxVerbatim}

\sphinxhref{https://ieeexplore.ieee.org/document/8217827}{{[}Paper{]}} \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/oztel\_2017}{{[}Our code{]}}

We have prepared one template:
\begin{itemize}
\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/oztel\_2017/oztel\_template\_V0.py}{oztel\_template\_V0.py} : exact parameters and training workflow as described in the paper.

\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/oztel\_2017/oztel\_template\_V1.py}{oztel\_template\_V1.py} : own changes made V0 to achieve better results.

\end{itemize}
\begin{description}
\item[{The implementation is based in one file:}] \leavevmode\begin{itemize}
\item {} 
\sphinxhref{oztel\_network.html}{Oztel CNN} : proposed network by the authors together with our proposed V1.

\item {} 
\sphinxhref{oztel\_utils.html}{Utils} : post\sphinxhyphen{}processing methods proposed by the authors and other needed functions.

\end{itemize}

\end{description}


\subsection{Xiao et al.}
\label{\detokenize{sota_implementations/xiao_2018/xiao:xiao-et-al}}\label{\detokenize{sota_implementations/xiao_2018/xiao::doc}}
As part of our paper we try to reproduce other state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art approaches for EM semantic segmentation
that do not provide code. In this case the following paper has been reproduced:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Chi Xiao, Xi Chen, Weifu Li, Linlin Li, Lu Wang, Qiwei Xie, and Hua Han, \PYG{l+s+s2}{\PYGZdq{}Automatic}
\PYG{l+s+s2}{mitochondria segmentation for em data using a 3d supervised convolutional network\PYGZdq{}},
Frontiers in Neuroanatomy \PYG{l+m}{12} \PYG{o}{(}\PYG{l+m}{2018}\PYG{o}{)}, \PYG{l+m}{92}.
\end{sphinxVerbatim}

\sphinxhref{https://www.frontiersin.org/articles/10.3389/fnana.2018.00092/full}{{[}Paper{]}} \sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/xiao\_2018}{{[}Our code{]}}

We have prepared two templates:
\begin{itemize}
\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/xiao\_2018/xiao\_template\_V0.py}{xiao\_template\_V0.py} : exact parameters and training workflow as described in the paper.

\item {} 
\sphinxhref{https://github.com/danifranco/EM\_Image\_Segmentation/tree/v1.0/sota\_implementations/xiao\_2018/xiao\_template\_V1.py}{xiao\_template\_V1.py} : changes made respect to V0 with which we have achieved better results.

\end{itemize}
\begin{description}
\item[{The implementation is based in one file:}] \leavevmode\begin{itemize}
\item {} 
\sphinxhref{xiao\_network.html}{3D network} : proposed 3D network based on 3D U\sphinxhyphen{}Net.

\end{itemize}

\end{description}


\section{utils}
\label{\detokenize{utils/utils:utils}}\label{\detokenize{utils/utils::doc}}

\subsection{Adabound}
\label{\detokenize{utils/adabound:module-utils.adabound}}\label{\detokenize{utils/adabound:adabound}}\label{\detokenize{utils/adabound::doc}}\index{module@\spxentry{module}!utils.adabound@\spxentry{utils.adabound}}\index{utils.adabound@\spxentry{utils.adabound}!module@\spxentry{module}}
Adabound optmizer. Code fully stracted from: \sphinxurl{https://github.com/Luolc/AdaBound}.
\index{AdaBound (class in utils.adabound)@\spxentry{AdaBound}\spxextra{class in utils.adabound}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/adabound:utils.adabound.AdaBound}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{utils.adabound.}}\sphinxbfcode{\sphinxupquote{AdaBound}}}{\emph{\DUrole{n}{lr}\DUrole{o}{=}\DUrole{default_value}{0.001}}, \emph{\DUrole{n}{final\_lr}\DUrole{o}{=}\DUrole{default_value}{0.1}}, \emph{\DUrole{n}{beta\_1}\DUrole{o}{=}\DUrole{default_value}{0.9}}, \emph{\DUrole{n}{beta\_2}\DUrole{o}{=}\DUrole{default_value}{0.999}}, \emph{\DUrole{n}{gamma}\DUrole{o}{=}\DUrole{default_value}{0.001}}, \emph{\DUrole{n}{epsilon}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{decay}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{n}{amsbound}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{weight\_decay}\DUrole{o}{=}\DUrole{default_value}{0.0}}, \emph{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.optimizer\_v2.optimizer\_v2.OptimizerV2}}

AdaBound optimizer.
Default parameters follow those provided in the original paper.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{lr} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Must be \sphinxcode{\sphinxupquote{\textgreater{}= 0}}. Learning rate.

\item {} 
\sphinxstylestrong{final\_lr} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Must be \sphinxcode{\sphinxupquote{\textgreater{}= 0}}. Final learning rate.

\item {} 
\sphinxstylestrong{beta\_1} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Must be float, \sphinxcode{\sphinxupquote{0 \textless{} beta \textless{} 1}}. Generally close to \sphinxcode{\sphinxupquote{1}}.

\item {} 
\sphinxstylestrong{beta\_2} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Must be \sphinxcode{\sphinxupquote{0 \textless{} beta \textless{} 1}}. Generally close to \sphinxcode{\sphinxupquote{1}}.

\item {} 
\sphinxstylestrong{gamma} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Must be \sphinxcode{\sphinxupquote{float \textgreater{}= 0}}. Convergence speed of the bound function.

\item {} 
\sphinxstylestrong{epsilon} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Must be \sphinxcode{\sphinxupquote{\textgreater{}= 0}}. Fuzz factor. If \sphinxcode{\sphinxupquote{None}}, defaults to \sphinxcode{\sphinxupquote{K.epsilon()}}.

\item {} 
\sphinxstylestrong{decay} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Must be \sphinxcode{\sphinxupquote{\textgreater{}= 0}}. Learning rate decay over each update.

\item {} 
\sphinxstylestrong{weight\_decay} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Weight decay weight.

\item {} 
\sphinxstylestrong{amsbound} (\sphinxcode{\sphinxupquote{boolean}}, \sphinxstyleemphasis{optional}) \textendash{} Whether to apply the AMSBound variant of this algorithm.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Notes}
\begin{itemize}
\item {} 
Adaptive Gradient Methods with Dynamic Bound of Learning Rate (\sphinxurl{https://openreview.net/forum?id=Bkg3g2R9FX})

\item {} 
Adam \sphinxhyphen{} A Method for Stochastic Optimization{]} (\sphinxurl{https://arxiv.org/abs/1412.6980v8})

\item {} 
On the Convergence of Adam and Beyond (\sphinxurl{https://openreview.net/forum?id=ryQu7f-RZ})

\end{itemize}
\begin{quote}\begin{description}
\item[{Attributes}] \leavevmode\begin{description}
\item[{\sphinxcode{\sphinxupquote{iterations}}}] \leavevmode
Variable.

\item[{\sphinxcode{\sphinxupquote{weights}}}] \leavevmode
Returns variables of this Optimizer based on the order created.

\end{description}

\end{description}\end{quote}
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxcode{\sphinxupquote{add\_slot}}(var, slot\_name{[}, initializer{]})
&
Add a new slot variable for \sphinxtitleref{var}.
\\
\hline
\sphinxcode{\sphinxupquote{apply\_gradients}}(grads\_and\_vars{[}, name{]})
&
Apply gradients to variables.
\\
\hline
\sphinxcode{\sphinxupquote{from\_config}}(config{[}, custom\_objects{]})
&
Creates an optimizer from its config.
\\
\hline
{\hyperref[\detokenize{utils/adabound:utils.adabound.AdaBound.get_config}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{get\_config}}}}}()
&
Returns the config of the optimimizer.
\\
\hline
\sphinxcode{\sphinxupquote{get\_gradients}}(loss, params)
&
Returns gradients of \sphinxtitleref{loss} with respect to \sphinxtitleref{params}.
\\
\hline
\sphinxcode{\sphinxupquote{get\_slot\_names}}()
&
A list of names for this optimizer’s slots.
\\
\hline
\sphinxcode{\sphinxupquote{minimize}}(loss, var\_list{[}, grad\_loss, name{]})
&
Minimize \sphinxtitleref{loss} by updating \sphinxtitleref{var\_list}.
\\
\hline
\sphinxcode{\sphinxupquote{set\_weights}}(weights)
&

\\
\hline
\sphinxcode{\sphinxupquote{variables}}()
&
Returns variables of this Optimizer based on the order created.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{add\_weight}
&\\
\hline
\sphinxstylestrong{get\_slot}
&\\
\hline
\sphinxstylestrong{get\_updates}
&\\
\hline
\sphinxstylestrong{get\_weights}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\index{get\_updates() (utils.adabound.AdaBound method)@\spxentry{get\_updates()}\spxextra{utils.adabound.AdaBound method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/adabound:utils.adabound.AdaBound.get_updates}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_updates}}}{\emph{\DUrole{n}{loss}}, \emph{\DUrole{n}{params}}}{}~
\end{fulllineitems}

\index{get\_config() (utils.adabound.AdaBound method)@\spxentry{get\_config()}\spxextra{utils.adabound.AdaBound method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/adabound:utils.adabound.AdaBound.get_config}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_config}}}{}{}
Returns the config of the optimimizer.

An optimizer config is a Python dictionary (serializable)
containing the configuration of an optimizer.
The same optimizer can be reinstantiated later
(without any saved state) from this configuration.
\begin{description}
\item[{Returns:}] \leavevmode
Python dictionary.

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\subsection{Callbacks}
\label{\detokenize{utils/callbacks:module-utils.callbacks}}\label{\detokenize{utils/callbacks:callbacks}}\label{\detokenize{utils/callbacks::doc}}\index{module@\spxentry{module}!utils.callbacks@\spxentry{utils.callbacks}}\index{utils.callbacks@\spxentry{utils.callbacks}!module@\spxentry{module}}
Code copied from \sphinxhref{https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/callbacks.py\#L1057}{Tensorflow/keras/callbacks.py} just inserting a few lines on the prints to avoid this \sphinxhref{https://github.com/tensorflow/tensorflow/issues/35100}{error}.
\index{ModelCheckpoint (class in utils.callbacks)@\spxentry{ModelCheckpoint}\spxextra{class in utils.callbacks}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/callbacks:utils.callbacks.ModelCheckpoint}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{utils.callbacks.}}\sphinxbfcode{\sphinxupquote{ModelCheckpoint}}}{\emph{\DUrole{n}{filepath}}, \emph{\DUrole{n}{monitor}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}val\_loss\textquotesingle{}}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{save\_best\_only}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{save\_weights\_only}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{mode}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}auto\textquotesingle{}}}, \emph{\DUrole{n}{period}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.callbacks.Callback}}

Save the model after every epochimport tensorflow.keras.callbacks.Callback .
\sphinxtitleref{filepath} can contain named formatting options,
which will be filled with the values of \sphinxtitleref{epoch} and
keys in \sphinxtitleref{logs} (passed in \sphinxtitleref{on\_epoch\_end}).
For example: if \sphinxtitleref{filepath} is \sphinxtitleref{weights.\{epoch:02d\}\sphinxhyphen{}\{val\_loss:.2f\}.hdf5},
then the model checkpoints will be saved with the epoch number and
the validation loss in the filename.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{filepath} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to save the model file.

\item {} 
\sphinxstylestrong{monitor} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Quantity to monitor.

\item {} 
\sphinxstylestrong{verbose} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Verbosity mode, 0 or 1.

\item {} 
\sphinxstylestrong{save\_best\_only} (\sphinxcode{\sphinxupquote{bool}}) \textendash{} If \sphinxcode{\sphinxupquote{save\_best\_only=True}}, the latest best model according to the
quantity monitored will not be overwritten.

\item {} 
\sphinxstylestrong{save\_weights\_only} (\sphinxcode{\sphinxupquote{bool}}) \textendash{} If \sphinxcode{\sphinxupquote{True}}, then only the model’s weights will be saved
(\sphinxcode{\sphinxupquote{model.save\_weights(filepath)}}), else the full model is saved
(\sphinxcode{\sphinxupquote{model.save(filepath)}}).

\item {} 
\sphinxstylestrong{mode} (\sphinxcode{\sphinxupquote{str}}) \textendash{} One of \sphinxcode{\sphinxupquote{\{auto, min, max\}}}. If \sphinxcode{\sphinxupquote{save\_best\_only=True}}, the decision
to overwrite the current save file is made based on either the
maximization or the minimization of the monitored quantity. For
\sphinxcode{\sphinxupquote{val\_acc}}, this should be \sphinxcode{\sphinxupquote{max}}, for \sphinxcode{\sphinxupquote{val\_loss}} this should
be \sphinxcode{\sphinxupquote{min}}, etc. In \sphinxcode{\sphinxupquote{auto}} mode, the direction is automatically
inferred from the name of the monitored quantity.

\item {} 
\sphinxstylestrong{period} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Interval (number of epochs) between checkpoints.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxcode{\sphinxupquote{on\_batch\_begin}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_begin}.
\\
\hline
\sphinxcode{\sphinxupquote{on\_batch\_end}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_end}.
\\
\hline
\sphinxcode{\sphinxupquote{on\_epoch\_begin}}(epoch{[}, logs{]})
&
Called at the start of an epoch.
\\
\hline
{\hyperref[\detokenize{utils/callbacks:utils.callbacks.ModelCheckpoint.on_epoch_end}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_epoch\_end}}}}}(epoch{[}, logs{]})
&
Called at the end of an epoch.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_begin}}({[}logs{]})
&
Called at the beginning of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_end}}({[}logs{]})
&
Called at the end of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_begin}}({[}logs{]})
&
Called at the beginning of evaluation or validation.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_end}}({[}logs{]})
&
Called at the end of evaluation or validation.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_begin}}({[}logs{]})
&
Called at the beginning of training.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_end}}({[}logs{]})
&
Called at the end of training.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{set\_model}
&\\
\hline
\sphinxstylestrong{set\_params}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\index{on\_epoch\_end() (utils.callbacks.ModelCheckpoint method)@\spxentry{on\_epoch\_end()}\spxextra{utils.callbacks.ModelCheckpoint method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/callbacks:utils.callbacks.ModelCheckpoint.on_epoch_end}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_epoch\_end}}}{\emph{\DUrole{n}{epoch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Called at the end of an epoch.

Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.
\begin{description}
\item[{Arguments:}] \leavevmode
epoch: integer, index of epoch.
logs: dict, metric results for this training epoch, and for the
\begin{quote}

validation epoch if validation is performed. Validation result keys
are prefixed with \sphinxtitleref{val\_}.
\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{TimeHistory (class in utils.callbacks)@\spxentry{TimeHistory}\spxextra{class in utils.callbacks}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/callbacks:utils.callbacks.TimeHistory}}\pysigline{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{utils.callbacks.}}\sphinxbfcode{\sphinxupquote{TimeHistory}}}
Bases: \sphinxcode{\sphinxupquote{tensorflow.python.keras.callbacks.Callback}}

Class to record each epoch time.
\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxcode{\sphinxupquote{on\_batch\_begin}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_begin}.
\\
\hline
\sphinxcode{\sphinxupquote{on\_batch\_end}}(batch{[}, logs{]})
&
A backwards compatibility alias for \sphinxtitleref{on\_train\_batch\_end}.
\\
\hline
{\hyperref[\detokenize{utils/callbacks:utils.callbacks.TimeHistory.on_epoch_begin}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_epoch\_begin}}}}}(batch{[}, logs{]})
&
Called at the start of an epoch.
\\
\hline
{\hyperref[\detokenize{utils/callbacks:utils.callbacks.TimeHistory.on_epoch_end}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_epoch\_end}}}}}(batch{[}, logs{]})
&
Called at the end of an epoch.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{predict} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_begin}}({[}logs{]})
&
Called at the beginning of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_predict\_end}}({[}logs{]})
&
Called at the end of prediction.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a batch in \sphinxtitleref{evaluate} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_begin}}({[}logs{]})
&
Called at the beginning of evaluation or validation.
\\
\hline
\sphinxcode{\sphinxupquote{on\_test\_end}}({[}logs{]})
&
Called at the end of evaluation or validation.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_batch\_begin}}(batch{[}, logs{]})
&
Called at the beginning of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_batch\_end}}(batch{[}, logs{]})
&
Called at the end of a training batch in \sphinxtitleref{fit} methods.
\\
\hline
{\hyperref[\detokenize{utils/callbacks:utils.callbacks.TimeHistory.on_train_begin}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{on\_train\_begin}}}}}({[}logs{]})
&
Called at the beginning of training.
\\
\hline
\sphinxcode{\sphinxupquote{on\_train\_end}}({[}logs{]})
&
Called at the end of training.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{set\_model}
&\\
\hline
\sphinxstylestrong{set\_params}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\index{on\_train\_begin() (utils.callbacks.TimeHistory method)@\spxentry{on\_train\_begin()}\spxextra{utils.callbacks.TimeHistory method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/callbacks:utils.callbacks.TimeHistory.on_train_begin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_train\_begin}}}{\emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{\{\}}}}{}
Called at the beginning of training.

Subclasses should override for any actions to run.
\begin{description}
\item[{Arguments:}] \leavevmode\begin{description}
\item[{logs: dict. Currently no data is passed to this argument for this method}] \leavevmode
but that may change in the future.

\end{description}

\end{description}

\end{fulllineitems}

\index{on\_epoch\_begin() (utils.callbacks.TimeHistory method)@\spxentry{on\_epoch\_begin()}\spxextra{utils.callbacks.TimeHistory method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/callbacks:utils.callbacks.TimeHistory.on_epoch_begin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_epoch\_begin}}}{\emph{\DUrole{n}{batch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{\{\}}}}{}
Called at the start of an epoch.

Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.
\begin{description}
\item[{Arguments:}] \leavevmode
epoch: integer, index of epoch.
logs: dict. Currently no data is passed to this argument for this method
\begin{quote}

but that may change in the future.
\end{quote}

\end{description}

\end{fulllineitems}

\index{on\_epoch\_end() (utils.callbacks.TimeHistory method)@\spxentry{on\_epoch\_end()}\spxextra{utils.callbacks.TimeHistory method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/callbacks:utils.callbacks.TimeHistory.on_epoch_end}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{on\_epoch\_end}}}{\emph{\DUrole{n}{batch}}, \emph{\DUrole{n}{logs}\DUrole{o}{=}\DUrole{default_value}{\{\}}}}{}
Called at the end of an epoch.

Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.
\begin{description}
\item[{Arguments:}] \leavevmode
epoch: integer, index of epoch.
logs: dict, metric results for this training epoch, and for the
\begin{quote}

validation epoch if validation is performed. Validation result keys
are prefixed with \sphinxtitleref{val\_}.
\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\subsection{Grad\sphinxhyphen{}CAM}
\label{\detokenize{utils/grad_cam:module-utils.grad_cam}}\label{\detokenize{utils/grad_cam:grad-cam}}\label{\detokenize{utils/grad_cam::doc}}\index{module@\spxentry{module}!utils.grad\_cam@\spxentry{utils.grad\_cam}}\index{utils.grad\_cam@\spxentry{utils.grad\_cam}!module@\spxentry{module}}
Code extracted from \sphinxurl{https://github.com/jacobgil/keras-grad-cam}
\index{grad\_cam\_sample() (in module utils.grad\_cam)@\spxentry{grad\_cam\_sample()}\spxextra{in module utils.grad\_cam}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/grad_cam:utils.grad_cam.grad_cam_sample}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.grad\_cam.}}\sphinxbfcode{\sphinxupquote{grad\_cam\_sample}}}{\emph{\DUrole{n}{input\_model}}, \emph{\DUrole{n}{image}}, \emph{\DUrole{n}{predicted\_class}}, \emph{\DUrole{n}{layer\_name}}, \emph{\DUrole{n}{out\_dir}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
Generates an image with the activation maps in charge of the class decision on a specific layer.

For a more detailed information refer to the paper: \sphinxhref{https://arxiv.org/abs/1610.02391}{Grad\sphinxhyphen{}CAM: Visual Explanations from Deep Networks via
Gradient\sphinxhyphen{}based Localization}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{input\_model} (\sphinxcode{\sphinxupquote{Keras model}}) \textendash{} Model.

\item {} 
\sphinxstylestrong{image} (\sphinxcode{\sphinxupquote{2D Numpy array}}) \textendash{} Image to visualize the heatmap from. E. g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{predicted\_class} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Number of the class predicted.

\item {} 
\sphinxstylestrong{layer\_name} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Keras layer name to extract the features from.

\item {} 
\sphinxstylestrong{out\_dir} (\sphinxcode{\sphinxupquote{str}} or \sphinxcode{\sphinxupquote{Path}}) \textendash{} Path to save the image on.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Total number of classes.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Extract the activation maps responsive of selecting the foreground class (1) in a binary segmentation task}
\PYG{c+c1}{\PYGZsh{} on the layer \PYGZsq{}conv2d\PYGZus{}16\PYGZsq{}. The image should be any image one could predict() on. Notice that the number of}
\PYG{c+c1}{\PYGZsh{} classes is 2, which should correspond to setting n\PYGZus{}classes=2 on the provided templates}
\PYG{n}{grad\PYGZus{}cam\PYGZus{}sample}\PYG{p}{(}\PYG{n}{unet\PYGZus{}model}\PYG{p}{,} \PYG{n}{img}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{conv2d\PYGZus{}16}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{out\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{)}
\end{sphinxVerbatim}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{FIBSEM_test_03}.png}
\sphinxfigcaption{Input image}\label{\detokenize{utils/grad_cam:id1}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{out_gradcam_conv2d_16}.png}
\sphinxfigcaption{Output of Grad\sphinxhyphen{}CAM}\label{\detokenize{utils/grad_cam:id2}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Notice that, if you select the activation maps of the last layer of the network, for example, \PYGZsq{}conv2d\PYGZus{}18\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{} in 2D U\PYGZhy{}Net implementation of this project, the output should be the same as the prediction on the}
\PYG{c+c1}{\PYGZsh{} complete image}
\PYG{n}{grad\PYGZus{}cam\PYGZus{}sample}\PYG{p}{(}\PYG{n}{unet\PYGZus{}model}\PYG{p}{,} \PYG{n}{img}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{conv2d\PYGZus{}18}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{out\PYGZus{}dir}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{)}
\end{sphinxVerbatim}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{gradcam_pred}.png}
\sphinxfigcaption{Network prediction}\label{\detokenize{utils/grad_cam:id3}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{out_gradcam_conv2d_18}.png}
\sphinxfigcaption{Output of Grad\sphinxhyphen{}CAM}\label{\detokenize{utils/grad_cam:id4}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\end{fulllineitems}

\index{target\_category\_loss() (in module utils.grad\_cam)@\spxentry{target\_category\_loss()}\spxextra{in module utils.grad\_cam}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/grad_cam:utils.grad_cam.target_category_loss}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.grad\_cam.}}\sphinxbfcode{\sphinxupquote{target\_category\_loss}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{predicted\_class}}, \emph{\DUrole{n}{n\_classes}}}{}~
\end{fulllineitems}

\index{target\_category\_loss\_output\_shape() (in module utils.grad\_cam)@\spxentry{target\_category\_loss\_output\_shape()}\spxextra{in module utils.grad\_cam}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/grad_cam:utils.grad_cam.target_category_loss_output_shape}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.grad\_cam.}}\sphinxbfcode{\sphinxupquote{target\_category\_loss\_output\_shape}}}{\emph{\DUrole{n}{input\_shape}}}{}~
\end{fulllineitems}

\index{normalize() (in module utils.grad\_cam)@\spxentry{normalize()}\spxextra{in module utils.grad\_cam}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/grad_cam:utils.grad_cam.normalize}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.grad\_cam.}}\sphinxbfcode{\sphinxupquote{normalize}}}{\emph{\DUrole{n}{x}}}{}~
\end{fulllineitems}



\subsection{Util}
\label{\detokenize{utils/util:module-utils.util}}\label{\detokenize{utils/util:util}}\label{\detokenize{utils/util::doc}}\index{module@\spxentry{module}!utils.util@\spxentry{utils.util}}\index{utils.util@\spxentry{utils.util}!module@\spxentry{module}}\index{limit\_threads() (in module utils.util)@\spxentry{limit\_threads()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.limit_threads}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{limit\_threads}}}{\emph{\DUrole{n}{threads\_number}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}1\textquotesingle{}}}}{}
Limits the number of threads for a python process.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{threads\_number} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of threads.

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_seed() (in module utils.util)@\spxentry{set\_seed()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.set_seed}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{set\_seed}}}{\emph{\DUrole{n}{seedValue}\DUrole{o}{=}\DUrole{default_value}{42}}, \emph{\DUrole{n}{determinism}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Sets the seed on multiple python modules to obtain results as reproducible as possible.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{seedValue} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Seed value.

\item {} 
\sphinxstylestrong{determinism} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To force determism.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_plots() (in module utils.util)@\spxentry{create\_plots()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.create_plots}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{create\_plots}}}{\emph{\DUrole{n}{results}}, \emph{\DUrole{n}{job\_id}}, \emph{\DUrole{n}{chartOutDir}}, \emph{\DUrole{n}{metric}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}jaccard\_index\textquotesingle{}}}}{}
Create loss and main metric plots with the given results.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{results} (\sphinxcode{\sphinxupquote{Keras History object}}) \textendash{} Record of training loss values and metrics values at successive epochs. History object is returned by Keras
\sphinxhref{https://keras.io/api/models/model\_training\_apis/\#fit-method}{fit()} method.

\item {} 
\sphinxstylestrong{job\_id} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Jod identifier.

\item {} 
\sphinxstylestrong{chartOutDir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path where the charts will be stored into.

\item {} 
\sphinxstylestrong{metric} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Metric used.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Examples}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{chart_loss}.png}
\sphinxfigcaption{Loss values on each epoch}\label{\detokenize{utils/util:id2}}\end{sphinxfigure-in-table}\relax
&\begin{sphinxfigure-in-table}
\centering
\capstart
\noindent\sphinxincludegraphics[width=0.800\linewidth]{{chart_jaccard_index}.png}
\sphinxfigcaption{Jaccard index values on each epoch}\label{\detokenize{utils/util:id3}}\end{sphinxfigure-in-table}\relax
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\end{fulllineitems}

\index{threshold\_plots() (in module utils.util)@\spxentry{threshold\_plots()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.threshold_plots}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{threshold\_plots}}}{\emph{\DUrole{n}{preds\_test}}, \emph{\DUrole{n}{Y\_test}}, \emph{\DUrole{n}{det\_eval\_ge\_path}}, \emph{\DUrole{n}{det\_eval\_path}}, \emph{\DUrole{n}{det\_bin}}, \emph{\DUrole{n}{n\_dig}}, \emph{\DUrole{n}{job\_id}}, \emph{\DUrole{n}{job\_file}}, \emph{\DUrole{n}{char\_dir}}, \emph{\DUrole{n}{r\_val}\DUrole{o}{=}\DUrole{default_value}{0.5}}}{}
Create a plot with the different metric values binarizing the prediction with different thresholds, from \sphinxcode{\sphinxupquote{0.1}}
to \sphinxcode{\sphinxupquote{0.9}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{preds\_test} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Predictions made by the model. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y\_test} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Ground truth of the data. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{det\_eval\_ge\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path where the ground truth is stored for the DET calculation.

\item {} 
\sphinxstylestrong{det\_eval\_path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path where the evaluation of the metric will be done.

\item {} 
\sphinxstylestrong{det\_bin} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to the DET binary.

\item {} 
\sphinxstylestrong{n\_dig} (\sphinxcode{\sphinxupquote{int}}) \textendash{} The number of digits used for encoding temporal indices (e.g. \sphinxcode{\sphinxupquote{3}}). Used by the DET calculation binary.

\item {} 
\sphinxstylestrong{job\_id} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Id of the job.

\item {} 
\sphinxstylestrong{job\_file} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Id and run number of the job.

\item {} 
\sphinxstylestrong{char\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to store the charts generated.

\item {} 
\sphinxstylestrong{r\_val} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Threshold values to return.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{t\_jac} (\sphinxcode{\sphinxupquote{float}}) \textendash{} Value of the Jaccard index when the threshold is \sphinxcode{\sphinxupquote{r\_val}}.

\item {} 
\sphinxstylestrong{t\_voc} (\sphinxcode{\sphinxupquote{float}}) \textendash{} Value of VOC when the threshold is \sphinxcode{\sphinxupquote{r\_val}}.

\item {} 
\sphinxstylestrong{t\_det} (\sphinxcode{\sphinxupquote{float}}) \textendash{} Value of DET when the threshold is \sphinxcode{\sphinxupquote{r\_val}}.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{jac}\PYG{p}{,} \PYG{n}{voc}\PYG{p}{,} \PYG{n}{det} \PYG{o}{=} \PYG{n}{threshold\PYGZus{}plots}\PYG{p}{(}
    \PYG{n}{preds\PYGZus{}test}\PYG{p}{,} \PYG{n}{Y\PYGZus{}test}\PYG{p}{,} \PYG{n}{det\PYGZus{}eval\PYGZus{}ge\PYGZus{}path}\PYG{p}{,} \PYG{n}{det\PYGZus{}eval\PYGZus{}path}\PYG{p}{,} \PYG{n}{det\PYGZus{}bin}\PYG{p}{,}
    \PYG{n}{n\PYGZus{}dig}\PYG{p}{,} \PYG{n}{args}\PYG{o}{.}\PYG{n}{job\PYGZus{}id}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{278\PYGZus{}3}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{char\PYGZus{}dir}\PYG{p}{)}
\end{sphinxVerbatim}

Will generate 3 charts, one per each metric: IoU, VOC and DET. In the x axis represents the 9 different
thresholds applied, that is: \sphinxcode{\sphinxupquote{0.1, 0.2, 0.3, ..., 0.9}}. The y axis is the value of the metric in each chart. For
instance, the Jaccard/IoU chart will look like this:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.600\linewidth]{{278_3_threshold_Jaccard}.png}\hspace*{\fill}}

In this example, the best value, \sphinxcode{\sphinxupquote{0.868}}, is obtained with a threshold of \sphinxcode{\sphinxupquote{0.4}}.

\end{fulllineitems}

\index{array\_to\_img() (in module utils.util)@\spxentry{array\_to\_img()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.array_to_img}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{array\_to\_img}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{data\_format}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}channels\_last\textquotesingle{}}}, \emph{\DUrole{n}{scale}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{dtype}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}float32\textquotesingle{}}}}{}
Converts a 3D Numpy array to a PIL Image instance.

As the Keras array\_to\_img function in:
\begin{quote}

\sphinxhref{https://github.com/keras-team/keras-preprocessing/blob/28b8c9a57703b60ea7d23a196c59da1edf987ca0/keras\_preprocessing/image/utils.py\#L230}{keras\_preprocessing/image/utils.py}
\end{quote}

\end{fulllineitems}

\index{img\_to\_array() (in module utils.util)@\spxentry{img\_to\_array()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.img_to_array}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{img\_to\_array}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{data\_format}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}channels\_last\textquotesingle{}}}, \emph{\DUrole{n}{dtype}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}float32\textquotesingle{}}}}{}
Converts a PIL Image instance to a Numpy array.

It’s a copy of the function \sphinxhref{https://github.com/keras-team/keras-preprocessing/blob/28b8c9a57703b60ea7d23a196c59da1edf987ca0/keras\_preprocessing/image/utils.py\#L288}{keras\_preprocessing/image/utils.py}.

\end{fulllineitems}

\index{save\_tif() (in module utils.util)@\spxentry{save\_tif()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.save_tif}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{save\_tif}}}{\emph{\DUrole{n}{X}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{data\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{filenames}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
Save images in the given directory.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D/5D numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Data to save as images. The first dimension must be the number of images. E.g.
\sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}} or \sphinxcode{\sphinxupquote{(num\_of\_images, z, x, y, channels)}}.

\item {} 
\sphinxstylestrong{data\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to store X images.

\item {} 
\sphinxstylestrong{filenames} (\sphinxcode{\sphinxupquote{List}}, \sphinxstyleemphasis{optional}) \textendash{} Filenames that should be used when saving each image.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{save\_img() (in module utils.util)@\spxentry{save\_img()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.save_img}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{save\_img}}}{\emph{\DUrole{n}{X}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{data\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{Y}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{mask\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{scale\_mask}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{prefix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{extension}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}.png\textquotesingle{}}}, \emph{\DUrole{n}{filenames}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Save images in the given directory.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Data to save as images. The first dimension must be the number of images. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{data\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to store X images.

\item {} 
\sphinxstylestrong{Y} (\sphinxcode{\sphinxupquote{4D numpy array}}, \sphinxstyleemphasis{optional}) \textendash{} Masks to save as images. The first dimension must be the number of images. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{scale\_mask} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} To allow mask be multiplied by 255.

\item {} 
\sphinxstylestrong{mask\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to store Y images.

\item {} 
\sphinxstylestrong{prefix} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to store generated charts.

\item {} 
\sphinxstylestrong{filenames} (\sphinxcode{\sphinxupquote{list}}, \sphinxstyleemphasis{optional}) \textendash{} Filenames that should be used when saving each image. If any provided each image should be named as:
\sphinxcode{\sphinxupquote{prefix + "\_x\_" + image\_number + extension}} when \sphinxcode{\sphinxupquote{X.ndim \textless{} 4}} and \sphinxcode{\sphinxupquote{prefix + "\_x\_" + image\_number +
"\_" + slice\_numger + extension}} otherwise. E.g. \sphinxcode{\sphinxupquote{prefix\_x\_000.png}} when \sphinxcode{\sphinxupquote{X.ndim \textless{} 4}} or
\sphinxcode{\sphinxupquote{prefix\_x\_000\_000.png}} when \sphinxcode{\sphinxupquote{X.ndim \textgreater{}= 4}}.  The same applies to \sphinxcode{\sphinxupquote{Y}}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{make\_weight\_map() (in module utils.util)@\spxentry{make\_weight\_map()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.make_weight_map}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{make\_weight\_map}}}{\emph{\DUrole{n}{label}}, \emph{\DUrole{n}{binary}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{w0}\DUrole{o}{=}\DUrole{default_value}{10}}, \emph{\DUrole{n}{sigma}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
Generates a weight map in order to make the U\sphinxhyphen{}Net learn better the borders of cells and distinguish individual
cells that are tightly packed. These weight maps follow the methodology of the original U\sphinxhyphen{}Net paper.

Based on \sphinxhref{https://github.com/deepimagej/python4deepimagej/blob/499955a264e1b66c4ed2c014cb139289be0e98a4/unet/py\_files/helpers.py}{unet/py\_files/helpers.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{label} (\sphinxcode{\sphinxupquote{3D numpy array}}) \textendash{} Corresponds to a label image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{binary} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Corresponds to whether or not the labels are binary.

\item {} 
\sphinxstylestrong{w0} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Controls for the importance of separating tightly associated entities.

\item {} 
\sphinxstylestrong{sigma} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Represents the standard deviation of the Gaussian used for the weight map.

\end{itemize}

\end{description}\end{quote}
\subsubsection*{Example}

Notice that weight has been defined where the objects are almost touching
each other.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=650\sphinxpxdimen]{{weight_map}.png}\hspace*{\fill}}

\end{fulllineitems}

\index{do\_save\_wm() (in module utils.util)@\spxentry{do\_save\_wm()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.do_save_wm}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{do\_save\_wm}}}{\emph{\DUrole{n}{labels}}, \emph{\DUrole{n}{path}}, \emph{\DUrole{n}{binary}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{w0}\DUrole{o}{=}\DUrole{default_value}{10}}, \emph{\DUrole{n}{sigma}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
Retrieves the label images, applies the weight\sphinxhyphen{}map algorithm and save the weight maps in a folder. Uses
internally \sphinxcode{\sphinxupquote{util.make\_weight\_map()}}.

Based on \sphinxhref{https://github.com/deepimagej/python4deepimagej/blob/499955a264e1b66c4ed2c014cb139289be0e98a4/unet/py\_files/helpers.py}{deepimagejunet/py\_files/helpers.py}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{labels} (\sphinxcode{\sphinxupquote{4D numpy array}}) \textendash{} Corresponds to given label images. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Refers to the path where the weight maps should be saved.

\item {} 
\sphinxstylestrong{binary} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Corresponds to whether or not the labels are binary.

\item {} 
\sphinxstylestrong{w0} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Controls for the importance of separating tightly associated entities.

\item {} 
\sphinxstylestrong{sigma} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Represents the standard deviation of the Gaussian used for the weight
map.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{foreground\_percentage() (in module utils.util)@\spxentry{foreground\_percentage()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.foreground_percentage}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{foreground\_percentage}}}{\emph{\DUrole{n}{mask}}, \emph{\DUrole{n}{class\_tag}}}{}
Percentage of pixels that corresponds to the class in the given image.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{mask} (\sphinxcode{\sphinxupquote{2D Numpy array}}) \textendash{} Image mask to analize.

\item {} 
\sphinxstylestrong{class\_tag} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Class to find in the image.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{x} \textendash{} Percentage of pixels that corresponds to the class. Value between \sphinxcode{\sphinxupquote{0}}
and \sphinxcode{\sphinxupquote{1}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{float}}

\end{description}\end{quote}

\end{fulllineitems}

\index{divide\_images\_on\_classes() (in module utils.util)@\spxentry{divide\_images\_on\_classes()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.divide_images_on_classes}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{divide\_images\_on\_classes}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{data\_mask}}, \emph{\DUrole{n}{out\_dir}}, \emph{\DUrole{n}{num\_classes}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{th}\DUrole{o}{=}\DUrole{default_value}{0.8}}}{}
Create a folder for each class where the images that have more pixels labeled as the class (in percentage) than
the given threshold will be stored.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D numpy array}}) \textendash{} Data to save as images. The first dimension must be the number of images. E. g.\textasciigrave{}\textasciigrave{}(num\_of\_images, x, y, channels)\textasciigrave{}\textasciigrave{}.

\item {} 
\sphinxstylestrong{data\_mask} (\sphinxcode{\sphinxupquote{4D numpy array}}) \textendash{} Data mask to save as images.  The first dimension must be the number of images. E. g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{out\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to save the images.

\item {} 
\sphinxstylestrong{num\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes.

\item {} 
\sphinxstylestrong{th} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Percentage of the pixels that must be labeled as a class to save it inside that class folder.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{save\_filters\_of\_convlayer() (in module utils.util)@\spxentry{save\_filters\_of\_convlayer()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.save_filters_of_convlayer}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{save\_filters\_of\_convlayer}}}{\emph{\DUrole{n}{model}}, \emph{\DUrole{n}{out\_dir}}, \emph{\DUrole{n}{l\_num}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{prefix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{img\_per\_row}\DUrole{o}{=}\DUrole{default_value}{8}}}{}
Create an image of the filters learned by a convolutional layer. One can identify the layer with \sphinxcode{\sphinxupquote{l\_num}} or
\sphinxcode{\sphinxupquote{name}} args. If both are passed \sphinxcode{\sphinxupquote{name}} will be prioritized.

Inspired by \sphinxurl{https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{model} (\sphinxcode{\sphinxupquote{Keras Model}}) \textendash{} Model where the layers are stored.

\item {} 
\sphinxstylestrong{out\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path where the image will be stored.

\item {} 
\sphinxstylestrong{l\_num} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of the layer to extract filters from.

\item {} 
\sphinxstylestrong{name} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Name of the layer to extract filters from.

\item {} 
\sphinxstylestrong{prefix} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Prefix to add to the output image name.

\item {} 
\sphinxstylestrong{img\_per\_row} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Filters per row on the image.

\end{itemize}

\item[{Raises}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} if \sphinxcode{\sphinxupquote{l\_num}} and \sphinxcode{\sphinxupquote{name}} not provided.

\end{description}\end{quote}
\subsubsection*{Examples}

To save the filters learned by the layer called \sphinxcode{\sphinxupquote{conv1}} one can call
the function as follows

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{save\PYGZus{}filters\PYGZus{}of\PYGZus{}convlayer}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{char\PYGZus{}dir}\PYG{p}{,} \PYG{n}{name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{conv1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{prefix}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

That will save in \sphinxcode{\sphinxupquote{out\_dir}} an image like this:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.600\linewidth]{{save_filters}.png}\hspace*{\fill}}

\end{fulllineitems}

\index{calculate\_2D\_volume\_prob\_map() (in module utils.util)@\spxentry{calculate\_2D\_volume\_prob\_map()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.calculate_2D_volume_prob_map}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{calculate\_2D\_volume\_prob\_map}}}{\emph{\DUrole{n}{Y}}, \emph{\DUrole{n}{Y\_path}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{w\_foreground}\DUrole{o}{=}\DUrole{default_value}{0.94}}, \emph{\DUrole{n}{w\_background}\DUrole{o}{=}\DUrole{default_value}{0.06}}, \emph{\DUrole{n}{save\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Calculate the probability map of the given 2D data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{Y} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to calculate the probability map from. E. g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channel)}}

\item {} 
\sphinxstylestrong{Y\_path} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to load the data from in case \sphinxcode{\sphinxupquote{Y=None}}.

\item {} 
\sphinxstylestrong{w\_foreground} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Weight of the foreground. This value plus \sphinxcode{\sphinxupquote{w\_background}} must be equal \sphinxcode{\sphinxupquote{1}}.

\item {} 
\sphinxstylestrong{w\_background} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Weight of the background. This value plus \sphinxcode{\sphinxupquote{w\_foreground}} must be equal \sphinxcode{\sphinxupquote{1}}.

\item {} 
\sphinxstylestrong{save\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to the file where the probability map will be stored.

\end{itemize}

\item[{Raises}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} if \sphinxcode{\sphinxupquote{Y}} does not have 4 dimensions.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} if \sphinxcode{\sphinxupquote{w\_foreground + w\_background \textgreater{} 1}}.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{Array} \textendash{} Path where the probability map/s is/are stored if \sphinxcode{\sphinxupquote{Y\_path}} was given and there are images of different
shapes. Otherwise, an array that represents the probability map of \sphinxcode{\sphinxupquote{Y}} or all loaded data files from
\sphinxcode{\sphinxupquote{Y\_path}} will be returned.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Str}} or \sphinxcode{\sphinxupquote{4D Numpy array}}

\end{description}\end{quote}

\end{fulllineitems}

\index{calculate\_3D\_volume\_prob\_map() (in module utils.util)@\spxentry{calculate\_3D\_volume\_prob\_map()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.calculate_3D_volume_prob_map}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{calculate\_3D\_volume\_prob\_map}}}{\emph{\DUrole{n}{Y}}, \emph{\DUrole{n}{Y\_path}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{w\_foreground}\DUrole{o}{=}\DUrole{default_value}{0.94}}, \emph{\DUrole{n}{w\_background}\DUrole{o}{=}\DUrole{default_value}{0.06}}, \emph{\DUrole{n}{save\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Calculate the probability map of the given 3D data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{Y} (\sphinxcode{\sphinxupquote{5D Numpy array}}) \textendash{} Data to calculate the probability map from. E. g. \sphinxcode{\sphinxupquote{(num\_subvolumes, x, y, z, channel)}}

\item {} 
\sphinxstylestrong{Y\_path} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to load the data from in case \sphinxcode{\sphinxupquote{Y=None}}.

\item {} 
\sphinxstylestrong{w\_foreground} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Weight of the foreground. This value plus \sphinxcode{\sphinxupquote{w\_background}} must be equal \sphinxcode{\sphinxupquote{1}}.

\item {} 
\sphinxstylestrong{w\_background} (\sphinxcode{\sphinxupquote{float}}, \sphinxstyleemphasis{optional}) \textendash{} Weight of the background. This value plus \sphinxcode{\sphinxupquote{w\_foreground}} must be equal \sphinxcode{\sphinxupquote{1}}.

\item {} 
\sphinxstylestrong{save\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to the directory where the probability map will be stored.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{Array} \textendash{} Path where the probability map/s is/are stored if \sphinxcode{\sphinxupquote{Y\_path}} was given and there are images of different
shapes. Otherwise, an array that represents the probability map of \sphinxcode{\sphinxupquote{Y}} or all loaded data files from
\sphinxcode{\sphinxupquote{Y\_path}} will be returned.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Str}} or \sphinxcode{\sphinxupquote{5D Numpy array}}

\item[{Raises}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} if \sphinxcode{\sphinxupquote{Y}} does not have 5 dimensions.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} if \sphinxcode{\sphinxupquote{w\_foreground + w\_background \textgreater{} 1}}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{grayscale\_2D\_image\_to\_3D() (in module utils.util)@\spxentry{grayscale\_2D\_image\_to\_3D()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.grayscale_2D_image_to_3D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{grayscale\_2D\_image\_to\_3D}}}{\emph{\DUrole{n}{X}}, \emph{\DUrole{n}{Y}}, \emph{\DUrole{n}{th}\DUrole{o}{=}\DUrole{default_value}{127}}}{}
Creates 3D surface from each image in X based on the grayscale of each image.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D numpy array}}) \textendash{} Data that contains the images to create the surfaces from. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Y} (\sphinxcode{\sphinxupquote{4D numpy array}}) \textendash{} Data mask of the same shape of X that will be converted into 3D volume, stacking multiple times each image.
Useful if you need the two data arrays to be of the same shape. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, channels)}}.

\item {} 
\sphinxstylestrong{th} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Values to ommit when creating the surfaces. Useful to reduce the amount of data in z to be created and
reduce computational time.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{Array} (\sphinxcode{\sphinxupquote{5D numpy array}}) \textendash{} 3D surface of each image provided. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, z, x, y, channels)}}.

\item {} 
\sphinxstylestrong{Array} (\sphinxcode{\sphinxupquote{5D numpy array}}) \textendash{} 3D stack of each mask provided. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, z, x, y, channels)}}.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{check\_masks() (in module utils.util)@\spxentry{check\_masks()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.check_masks}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{check\_masks}}}{\emph{\DUrole{n}{path}}, \emph{\DUrole{n}{n\_classes}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
Check wheter the data masks have the correct labels inspection a few random images of the given path. If the
function gives no error one should assume that the masks are correct.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{path} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to the data mask.

\item {} 
\sphinxstylestrong{n\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Maximum classes that the masks must contain.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{img\_to\_onehot\_encoding() (in module utils.util)@\spxentry{img\_to\_onehot\_encoding()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.img_to_onehot_encoding}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{img\_to\_onehot\_encoding}}}{\emph{\DUrole{n}{img}}, \emph{\DUrole{n}{num\_classes}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
Converts image given into one\sphinxhyphen{}hot encode format.

The opposite function is {\hyperref[\detokenize{utils/util:utils.util.onehot_encoding_to_img}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{onehot\_encoding\_to\_img()}}}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{img} (\sphinxcode{\sphinxupquote{Numpy 3D/4D array}}) \textendash{} Image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}} or \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{num\_classes} (\sphinxcode{\sphinxupquote{int}}, \sphinxstyleemphasis{optional}) \textendash{} Number of classes to distinguish.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{one\_hot\_labels} \textendash{} Data one\sphinxhyphen{}hot encoded. E.g. \sphinxcode{\sphinxupquote{(x, y, num\_classes)}} or \sphinxcode{\sphinxupquote{(x, y, z, num\_classes)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Numpy 3D/4D array}}

\end{description}\end{quote}

\end{fulllineitems}

\index{onehot\_encoding\_to\_img() (in module utils.util)@\spxentry{onehot\_encoding\_to\_img()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.onehot_encoding_to_img}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{onehot\_encoding\_to\_img}}}{\emph{\DUrole{n}{encoded\_image}}}{}
Converts one\sphinxhyphen{}hot encode image into an image with jus tone channel and all the classes represented by an integer.

The opposite function is {\hyperref[\detokenize{utils/util:utils.util.img_to_onehot_encoding}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{img\_to\_onehot\_encoding()}}}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{encoded\_image} (\sphinxcode{\sphinxupquote{Numpy 3D/4D array}}) \textendash{} Image. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}} or \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item[{Returns}] \leavevmode
\sphinxstylestrong{img} \textendash{} Data one\sphinxhyphen{}hot encoded. E.g. \sphinxcode{\sphinxupquote{(x, y, z, num\_classes)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{Numpy 3D/4D array}}

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_data\_from\_dir() (in module utils.util)@\spxentry{load\_data\_from\_dir()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.load_data_from_dir}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{load\_data\_from\_dir}}}{\emph{\DUrole{n}{data\_dir}}, \emph{\DUrole{n}{crop}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{crop\_shape}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{overlap}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0}}, \emph{\DUrole{n}{return\_filenames}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Load data from a directory. If \sphinxcode{\sphinxupquote{crop=False}} all the data is suposed to have the same shape.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to read the data from.

\item {} 
\sphinxstylestrong{crop} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Crop each image into desired shape pointed by \sphinxcode{\sphinxupquote{crop\_shape}}.

\item {} 
\sphinxstylestrong{crop\_shape} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{3 ints}}, \sphinxstyleemphasis{optional}) \textendash{} Shape of the crop to be made. E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\item {} 
\sphinxstylestrong{overlap} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{2 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x and y dimensions. The values must  be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}} or
\sphinxcode{\sphinxupquote{99\%}} of overlap. E. g. \sphinxcode{\sphinxupquote{(x, y)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{2 ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24)}}.

\item {} 
\sphinxstylestrong{return\_filenames} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Return a list with the loaded filenames. Useful when you need to save them afterwards with the same names as
the original ones.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{4D Numpy array}} or \sphinxcode{\sphinxupquote{list}} of \sphinxcode{\sphinxupquote{3D Numpy arrays}}) \textendash{} Data loaded. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, channels)}} if all files have same shape, otherwise a list of
\sphinxcode{\sphinxupquote{(y, x, channels)}} arrays will be returned.

\item {} 
\sphinxstylestrong{data\_shape} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{tuples}}) \textendash{} Shapes of all 3D images readed. Useful to reconstruct the original images together with \sphinxcode{\sphinxupquote{crop\_shape}}.

\item {} 
\sphinxstylestrong{crop\_shape} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{tuples}}) \textendash{} Shape of the loaded 3D images after cropping. Useful to reconstruct the original images together with
\sphinxcode{\sphinxupquote{data\_shape}}.

\item {} 
\sphinxstylestrong{filenames} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Loaded filenames.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Case where we need to load 165 images of shape (1024, 768)}
\PYG{n}{data\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/x}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{n}{load\PYGZus{}data\PYGZus{}from\PYGZus{}dir}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} The function will print the shape of the created array. In this example:}
\PYG{c+c1}{\PYGZsh{}     *** Loaded data shape is (165, 768, 1024, 1)}
\PYG{c+c1}{\PYGZsh{} Notice height and width swap because of Numpy ndarray terminology}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} Case where we need to load 165 images of shape (1024, 768) but}
\PYG{c+c1}{\PYGZsh{} cropping them into (256, 256, 1) patches}
\PYG{n}{data\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/x}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{crop\PYGZus{}shape} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{n}{load\PYGZus{}data\PYGZus{}from\PYGZus{}dir}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{p}{,} \PYG{n}{crop}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{crop\PYGZus{}shape}\PYG{o}{=}\PYG{n}{crop\PYGZus{}shape}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} The function will print the shape of the created array. In this example:}
\PYG{c+c1}{\PYGZsh{}     *** Loaded data shape is (1980, 256, 256, 1)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{load\_ct\_data\_from\_dir() (in module utils.util)@\spxentry{load\_ct\_data\_from\_dir()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.load_ct_data_from_dir}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{load\_ct\_data\_from\_dir}}}{\emph{\DUrole{n}{data\_dir}}, \emph{\DUrole{n}{shape}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Load CT data from a directory.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to read the data from.

\item {} 
\sphinxstylestrong{shape} (\sphinxcode{\sphinxupquote{3D int tuple}}, \sphinxstyleemphasis{optional}) \textendash{} Shape of the data to load. If is not provided the shape is calculated automatically looping over all data
files and it will be  the maximum value found per axis. So, given the value the process should be faster.
E.g. \sphinxcode{\sphinxupquote{(x, y, channels)}}.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{data} \textendash{} Data loaded. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, y, x, channels)}}.

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{4D Numpy array}}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Case where we need to load 165 images of shape (1024, 768)}
\PYG{n}{data\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/x}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{data\PYGZus{}shape} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{1024}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{n}{load\PYGZus{}data\PYGZus{}from\PYGZus{}dir}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{p}{,} \PYG{n}{data\PYGZus{}shape}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print list\PYGZsq{}s first position array\PYGZsq{}s shape. In this example:}
\PYG{c+c1}{\PYGZsh{}     *** Loaded data[0] shape is (165, 768, 1024, 1)}
\PYG{c+c1}{\PYGZsh{} Notice height and width swap because of Numpy ndarray terminology}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{load\_3d\_images\_from\_dir() (in module utils.util)@\spxentry{load\_3d\_images\_from\_dir()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.load_3d_images_from_dir}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{load\_3d\_images\_from\_dir}}}{\emph{\DUrole{n}{data\_dir}}, \emph{\DUrole{n}{crop}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{crop\_shape}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{crop\_verb}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{overlap}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}, \emph{\DUrole{n}{padding}\DUrole{o}{=}\DUrole{default_value}{0, 0, 0}}, \emph{\DUrole{n}{median\_padding}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{return\_filenames}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
Load data from a directory.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data\_dir} (\sphinxcode{\sphinxupquote{str}}) \textendash{} Path to read the data from.

\item {} 
\sphinxstylestrong{crop} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Crop each 3D image when readed.

\item {} 
\sphinxstylestrong{crop\_shape} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{4 ints}}, \sphinxstyleemphasis{optional}) \textendash{} Shape of the subvolumes to create when cropping.  E.g. \sphinxcode{\sphinxupquote{(x, y, z, channels)}}.

\item {} 
\sphinxstylestrong{crop\_verb} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Wheter to use verbose mode on crop.

\item {} 
\sphinxstylestrong{overlap} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{3 floats}}, \sphinxstyleemphasis{optional}) \textendash{} Amount of minimum overlap on x, y and z dimensions. The values must be on range \sphinxcode{\sphinxupquote{{[}0, 1)}}, that is, \sphinxcode{\sphinxupquote{0\%}}
or \sphinxcode{\sphinxupquote{99\%}} of overlap. E.g. \sphinxcode{\sphinxupquote{(x, y, z)}}.

\item {} 
\sphinxstylestrong{padding} (\sphinxcode{\sphinxupquote{Tuple}} of \sphinxcode{\sphinxupquote{3 ints}}, \sphinxstyleemphasis{optional}) \textendash{} Size of padding to be added on each axis \sphinxcode{\sphinxupquote{(x, y, z)}}. E.g. \sphinxcode{\sphinxupquote{(24, 24, 24)}}.

\item {} 
\sphinxstylestrong{median\_padding} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} If \sphinxcode{\sphinxupquote{True}} the padding value is the median value. If \sphinxcode{\sphinxupquote{False}}, the added values are zeroes.

\item {} 
\sphinxstylestrong{return\_filenames} (\sphinxcode{\sphinxupquote{bool}}, \sphinxstyleemphasis{optional}) \textendash{} Return a list with the loaded filenames. Useful when you need to save them afterwards with the same names as
the original ones.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{data} (\sphinxcode{\sphinxupquote{5D Numpy array}} or \sphinxcode{\sphinxupquote{list}} of \sphinxcode{\sphinxupquote{4D Numpy arrays}}) \textendash{} Data loaded. E.g. \sphinxcode{\sphinxupquote{(num\_of\_images, x, y, z, channels)}} if all files have same shape, otherwise a list of
\sphinxcode{\sphinxupquote{(1, x, y, z, channels)}} arrays will be returned.

\item {} 
\sphinxstylestrong{data\_shape} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{tuples}}) \textendash{} Shapes of all 3D images readed. Useful to reconstruct the original images together with \sphinxcode{\sphinxupquote{crop\_shape}}.

\item {} 
\sphinxstylestrong{crop\_shape} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{tuples}}) \textendash{} Shape of the loaded 3D images after cropping. Useful to reconstruct the original images together with
\sphinxcode{\sphinxupquote{data\_shape}}.

\item {} 
\sphinxstylestrong{filenames} (\sphinxcode{\sphinxupquote{List}} of \sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Loaded filenames.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} EXAMPLE 1}
\PYG{c+c1}{\PYGZsh{} Case where we need to load 20 images of shape (1024, 1024, 91, 1)}
\PYG{n}{data\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/x}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{n}{data} \PYG{o}{=} \PYG{n}{load\PYGZus{}data\PYGZus{}from\PYGZus{}dir}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} The function will print list\PYGZsq{}s first position array\PYGZsq{}s shape. In this example:}
\PYG{c+c1}{\PYGZsh{}     *** Loaded data[0] shape is (20, 91, 1024, 1024, 1)}
\PYG{c+c1}{\PYGZsh{} Notice height, width and depth swap as skimage.io imread function}
\PYG{c+c1}{\PYGZsh{} is used to load images}

\PYG{c+c1}{\PYGZsh{} EXAMPLE 2}
\PYG{c+c1}{\PYGZsh{} Same as example 1 but with unknown shape, cropping them into (256, 256, 40, 1) subvolumes with minimum}
\PYG{c+c1}{\PYGZsh{} overlap and storing filenames.}
\PYG{n}{data\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data/train/x}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{n}{X\PYGZus{}test}\PYG{p}{,} \PYG{n}{orig\PYGZus{}test\PYGZus{}img\PYGZus{}shapes}\PYG{p}{,}            \PYG{n}{crop\PYGZus{}test\PYGZus{}img\PYGZus{}shapes}\PYG{p}{,} \PYG{n}{te\PYGZus{}filenames} \PYG{o}{=} \PYG{n}{load\PYGZus{}3d\PYGZus{}images\PYGZus{}from\PYGZus{}dir}\PYG{p}{(}
    \PYG{n}{test\PYGZus{}path}\PYG{p}{,} \PYG{n}{crop}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{crop\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{40}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{overlap}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n}{return\PYGZus{}filenames}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The function will print the shape of the created array which its size is the concatenation in 0 axis of all}
\PYG{c+c1}{\PYGZsh{} subvolumes created for each 3D image in the given path. For example:}
\PYG{c+c1}{\PYGZsh{}     *** Loaded data shape is (350, 256, 256, 40, 1)}
\PYG{c+c1}{\PYGZsh{} Notice height, width and depth swap as skimage.io imread function is used to load images.}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{labels\_into\_bcd() (in module utils.util)@\spxentry{labels\_into\_bcd()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.labels_into_bcd}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{labels\_into\_bcd}}}{\emph{\DUrole{n}{data\_mask}}, \emph{\DUrole{n}{mode}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}BCD\textquotesingle{}}}, \emph{\DUrole{n}{fb\_mode}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}outer\textquotesingle{}}}, \emph{\DUrole{n}{save\_dir}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
Create an array with 3 channels given semantic or instance segmentation data masks. These 3 channels are:
semantic mask, contours and distance map.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{data\_mask} (\sphinxcode{\sphinxupquote{5D Numpy array}}) \textendash{} Data mask to create the new array from. It is expected to have just one channel. E.g. \sphinxcode{\sphinxupquote{(10, 1000, 1000, 200, 1)}}

\item {} 
\sphinxstylestrong{mode} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Operation mode. Possible values: \sphinxcode{\sphinxupquote{BC}} and \sphinxcode{\sphinxupquote{BCD}}.  \sphinxcode{\sphinxupquote{BC}} corresponds to use binary segmentation+contour.
\sphinxcode{\sphinxupquote{BCD}} stands for binary segmentation+contour+distances.

\item {} 
\sphinxstylestrong{fb\_mode} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Mode of the find\_boundaries function from \sphinxcode{\sphinxupquote{scikit\sphinxhyphen{}image}}. More info in:
\sphinxhref{https://scikit-image.org/docs/stable/api/skimage.segmentation.html\#skimage.segmentation.find\_boundaries}{find\_boundaries()}.

\item {} 
\sphinxstylestrong{save\_dir} (\sphinxcode{\sphinxupquote{str}}, \sphinxstyleemphasis{optional}) \textendash{} Path to store samples of the created array just to debug it is correct.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{new\_mask} \textendash{} 5D array with 3 channels instead of one. E.g. \sphinxcode{\sphinxupquote{(10, 1000, 1000, 200, 3)}}

\item[{Return type}] \leavevmode
\sphinxcode{\sphinxupquote{5D Numpy array}}

\end{description}\end{quote}

\end{fulllineitems}

\index{check\_downsample\_division() (in module utils.util)@\spxentry{check\_downsample\_division()}\spxextra{in module utils.util}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{utils/util:utils.util.check_downsample_division}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utils.util.}}\sphinxbfcode{\sphinxupquote{check\_downsample\_division}}}{\emph{\DUrole{n}{X}}, \emph{\DUrole{n}{d\_levels}}}{}
Ensures \sphinxcode{\sphinxupquote{X}} shape is divisible by \sphinxcode{\sphinxupquote{2}} times \sphinxcode{\sphinxupquote{d\_levels}} adding padding if necessary.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data to check if its shape.  E.g. \sphinxcode{\sphinxupquote{(10, 1000, 1000, 1)}}.

\item {} 
\sphinxstylestrong{d\_levels} (\sphinxcode{\sphinxupquote{int}}) \textendash{} Levels of downsampling by \sphinxcode{\sphinxupquote{2}}.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{X} (\sphinxcode{\sphinxupquote{4D Numpy array}}) \textendash{} Data divisible by 2 \sphinxcode{\sphinxupquote{d\_levels}} times.

\item {} 
\sphinxstylestrong{o\_shape} (\sphinxcode{\sphinxupquote{4 int tuple}}) \textendash{} Original shape of \sphinxcode{\sphinxupquote{X}}. E.g. \sphinxcode{\sphinxupquote{(10, 1000, 1000, 1)}}.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\section{Bibliography}
\label{\detokenize{bibliography:bibliography}}\label{\detokenize{bibliography::doc}}


\begin{sphinxthebibliography}{LWP+21}
\bibitem[LWP+21]{bibliography:id2}
Zudi Lin, Donglai Wei, Mariela D. Petkova, Yuelong Wu, Zergham Ahmed, Krishna Swaroop K, Silin Zou, Nils Wendt, Jonathan Boulanger\sphinxhyphen{}Weill, Xueying Wang, Nagaraju Dhanyasi, Ignacio Arganda\sphinxhyphen{}Carreras, Florian Engert, Jeff Lichtman, and Hanspeter Pfister. Nucmm dataset: 3d neuronal nuclei instance segmentation at sub\sphinxhyphen{}cubic millimeter scale. 2021. \sphinxhref{https://arxiv.org/abs/2107.05840}{arXiv:2107.05840}.
\end{sphinxthebibliography}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{c}
\item\relax\sphinxstyleindexentry{config.config}\sphinxstyleindexpageref{config/config:\detokenize{module-config.config}}
\indexspace
\bigletter{d}
\item\relax\sphinxstyleindexentry{data}\sphinxstyleindexpageref{data/init:\detokenize{module-data}}
\item\relax\sphinxstyleindexentry{data.data\_2D\_manipulation}\sphinxstyleindexpageref{data/data_2d_manipulation:\detokenize{module-data.data_2D_manipulation}}
\item\relax\sphinxstyleindexentry{data.data\_3D\_manipulation}\sphinxstyleindexpageref{data/data_3d_manipulation:\detokenize{module-data.data_3D_manipulation}}
\item\relax\sphinxstyleindexentry{data.generators}\sphinxstyleindexpageref{data/generators/init:\detokenize{module-data.generators}}
\item\relax\sphinxstyleindexentry{data.generators.augmentors}\sphinxstyleindexpageref{data/generators/augmentors:\detokenize{module-data.generators.augmentors}}
\item\relax\sphinxstyleindexentry{data.generators.data\_2D\_generator}\sphinxstyleindexpageref{data/generators/2d_generator:\detokenize{module-data.generators.data_2D_generator}}
\item\relax\sphinxstyleindexentry{data.generators.data\_3D\_generator}\sphinxstyleindexpageref{data/generators/3d_generator:\detokenize{module-data.generators.data_3D_generator}}
\item\relax\sphinxstyleindexentry{data.generators.simple\_data\_generators}\sphinxstyleindexpageref{data/generators/simple_generator:\detokenize{module-data.generators.simple_data_generators}}
\item\relax\sphinxstyleindexentry{data.post\_processing}\sphinxstyleindexpageref{data/post_processing/init:\detokenize{module-data.post_processing}}
\item\relax\sphinxstyleindexentry{data.post\_processing.post\_processing}\sphinxstyleindexpageref{data/post_processing/post_processing:\detokenize{module-data.post_processing.post_processing}}
\item\relax\sphinxstyleindexentry{data.post\_processing.smooth\_tiled\_predictions}\sphinxstyleindexpageref{data/post_processing/smooth_tiled_predictions:\detokenize{module-data.post_processing.smooth_tiled_predictions}}
\indexspace
\bigletter{e}
\item\relax\sphinxstyleindexentry{engine}\sphinxstyleindexpageref{engine/init:\detokenize{module-engine}}
\item\relax\sphinxstyleindexentry{engine.metrics}\sphinxstyleindexpageref{engine/metrics:\detokenize{module-engine.metrics}}
\item\relax\sphinxstyleindexentry{engine.schedulers.cosine\_decay}\sphinxstyleindexpageref{engine/schedulers/cosine_decay:\detokenize{module-engine.schedulers.cosine_decay}}
\item\relax\sphinxstyleindexentry{engine.schedulers.one\_cycle}\sphinxstyleindexpageref{engine/schedulers/one_cycle:\detokenize{module-engine.schedulers.one_cycle}}
\item\relax\sphinxstyleindexentry{engine.trainer}\sphinxstyleindexpageref{engine/trainer:\detokenize{module-engine.trainer}}
\indexspace
\bigletter{m}
\item\relax\sphinxstyleindexentry{models}\sphinxstyleindexpageref{models/init:\detokenize{module-models}}
\item\relax\sphinxstyleindexentry{models.attention\_unet}\sphinxstyleindexpageref{models/att_unet_2d:\detokenize{module-models.attention_unet}}
\item\relax\sphinxstyleindexentry{models.attention\_unet\_3d}\sphinxstyleindexpageref{models/att_unet_3d:\detokenize{module-models.attention_unet_3d}}
\item\relax\sphinxstyleindexentry{models.fcn\_vgg}\sphinxstyleindexpageref{models/fcn:\detokenize{module-models.fcn_vgg}}
\item\relax\sphinxstyleindexentry{models.multiresunet}\sphinxstyleindexpageref{models/multiresunet:\detokenize{module-models.multiresunet}}
\item\relax\sphinxstyleindexentry{models.resunet}\sphinxstyleindexpageref{models/resunet:\detokenize{module-models.resunet}}
\item\relax\sphinxstyleindexentry{models.resunet\_3d}\sphinxstyleindexpageref{models/resunet_3d:\detokenize{module-models.resunet_3d}}
\item\relax\sphinxstyleindexentry{models.se\_unet\_2d}\sphinxstyleindexpageref{models/se_unet_2d:\detokenize{module-models.se_unet_2d}}
\item\relax\sphinxstyleindexentry{models.se\_unet\_3d}\sphinxstyleindexpageref{models/se_unet_3d:\detokenize{module-models.se_unet_3d}}
\item\relax\sphinxstyleindexentry{models.tiramisu}\sphinxstyleindexpageref{models/tiramisu:\detokenize{module-models.tiramisu}}
\item\relax\sphinxstyleindexentry{models.unet}\sphinxstyleindexpageref{models/unet:\detokenize{module-models.unet}}
\item\relax\sphinxstyleindexentry{models.unet\_3d}\sphinxstyleindexpageref{models/unet_3d:\detokenize{module-models.unet_3d}}
\item\relax\sphinxstyleindexentry{models.vanilla\_unet\_3d}\sphinxstyleindexpageref{models/vanilla_unet_3d:\detokenize{module-models.vanilla_unet_3d}}
\indexspace
\bigletter{s}
\item\relax\sphinxstyleindexentry{sota\_implementations.nnUNet\_2018.nnUNet\_2d}\sphinxstyleindexpageref{models/nnunet:\detokenize{module-sota_implementations.nnUNet_2018.nnUNet_2d}}
\indexspace
\bigletter{u}
\item\relax\sphinxstyleindexentry{utils.adabound}\sphinxstyleindexpageref{utils/adabound:\detokenize{module-utils.adabound}}
\item\relax\sphinxstyleindexentry{utils.callbacks}\sphinxstyleindexpageref{utils/callbacks:\detokenize{module-utils.callbacks}}
\item\relax\sphinxstyleindexentry{utils.grad\_cam}\sphinxstyleindexpageref{utils/grad_cam:\detokenize{module-utils.grad_cam}}
\item\relax\sphinxstyleindexentry{utils.util}\sphinxstyleindexpageref{utils/util:\detokenize{module-utils.util}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}